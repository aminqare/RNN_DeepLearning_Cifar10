{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3dfkASG_UPXf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input, concatenate\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from classification_models.tfkeras import Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NzQKBOioMl5",
        "outputId": "a020dcfd-8d1f-46f9-ac15-b05c26a00974"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-dv976blj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/qubvel/classification_models.git /tmp/pip-req-build-dv976blj\n",
            "  Resolved https://github.com/qubvel/classification_models.git to commit a0f006e05485a34ccf871c421279864b0ccd220b\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras_applications<=1.0.8,>=1.0.7 (from image_classifiers==1.0.0)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image_classifiers==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image_classifiers==1.0.0) (3.11.0)\n",
            "Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: image_classifiers\n",
            "  Building wheel for image_classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image_classifiers: filename=image_classifiers-1.0.0-py3-none-any.whl size=20030 sha256=548192265506a7cc13a620543abe4bf1d9f8067afd71f6d0946f7c8ce727618f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z0zpaexo/wheels/f5/13/cb/b1dbd79043c5a389742e422859b0b663adcd7b5c220928c339\n",
            "Successfully built image_classifiers\n",
            "Installing collected packages: keras_applications, image_classifiers\n",
            "Successfully installed image_classifiers-1.0.0 keras_applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWtyNEq0V0Il",
        "outputId": "4286a214-40d4-4e30-8d28-7a8d4f2e77df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "YqKQWpgZWRMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51d75ec-8b6f-4dd9-b7c3-f0819f85dc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XTdmv5stZnik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hvU7cSKZq3z",
        "outputId": "638be350-9f30-4629-fc45-d93d0903f44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.3080 - loss: 1.9378 - val_accuracy: 0.4054 - val_loss: 1.6781\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.3647 - loss: 1.7859 - val_accuracy: 0.4240 - val_loss: 1.6397\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.3729 - loss: 1.7676 - val_accuracy: 0.4307 - val_loss: 1.6151\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3787 - loss: 1.7483 - val_accuracy: 0.4339 - val_loss: 1.6027\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3845 - loss: 1.7381 - val_accuracy: 0.4366 - val_loss: 1.6113\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.3888 - loss: 1.7270 - val_accuracy: 0.4414 - val_loss: 1.5948\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3889 - loss: 1.7195 - val_accuracy: 0.4368 - val_loss: 1.5975\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.3901 - loss: 1.7218 - val_accuracy: 0.4443 - val_loss: 1.5768\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3949 - loss: 1.7133 - val_accuracy: 0.4398 - val_loss: 1.5803\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.3948 - loss: 1.7137 - val_accuracy: 0.4435 - val_loss: 1.5726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "DswYBoIiec8L",
        "outputId": "46dd8189-dc08-4947-90c2-7724d13b86ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_pad (\u001b[38;5;33mZeroPadding2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_conv (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m9,472\u001b[0m │ conv1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_bn                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv1_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_relu (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pool1_pad (\u001b[38;5;33mZeroPadding2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv1_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pool1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ pool1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │          \u001b[38;5;34m4,160\u001b[0m │ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2_block1_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,928\u001b[0m │ conv2_block1_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2_block1_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_0_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m16,640\u001b[0m │ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m16,640\u001b[0m │ conv2_block1_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_0_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2_block1_0_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2_block1_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_0_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                           │                        │                │ conv2_block1_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m16,448\u001b[0m │ conv2_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2_block2_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,928\u001b[0m │ conv2_block2_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2_block2_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m16,640\u001b[0m │ conv2_block2_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2_block2_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv2_block2_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m16,448\u001b[0m │ conv2_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2_block3_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv2_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,928\u001b[0m │ conv2_block3_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2_block3_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv2_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m16,640\u001b[0m │ conv2_block3_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2_block3_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv2_block3_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv2_block3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m32,896\u001b[0m │ conv2_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv3_block1_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ conv3_block1_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv3_block1_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_0_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │        \u001b[38;5;34m131,584\u001b[0m │ conv2_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m66,048\u001b[0m │ conv3_block1_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_0_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block1_0_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block1_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_0_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                           │                        │                │ conv3_block1_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m65,664\u001b[0m │ conv3_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv3_block2_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ conv3_block2_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv3_block2_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m66,048\u001b[0m │ conv3_block2_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block2_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv3_block2_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m65,664\u001b[0m │ conv3_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv3_block3_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ conv3_block3_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv3_block3_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m66,048\u001b[0m │ conv3_block3_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block3_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv3_block3_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m65,664\u001b[0m │ conv3_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv3_block4_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block4_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ conv3_block4_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv3_block4_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block4_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m66,048\u001b[0m │ conv3_block4_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block4_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv3_block4_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv3_block4_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m131,328\u001b[0m │ conv3_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block1_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m590,080\u001b[0m │ conv4_block1_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block1_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_0_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │        \u001b[38;5;34m525,312\u001b[0m │ conv3_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block1_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_0_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block1_0_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block1_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_0_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                           │                        │                │ conv4_block1_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m262,400\u001b[0m │ conv4_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block2_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m590,080\u001b[0m │ conv4_block2_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block2_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block2_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block2_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block2_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m262,400\u001b[0m │ conv4_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block3_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m590,080\u001b[0m │ conv4_block3_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block3_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block3_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block3_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block3_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m262,400\u001b[0m │ conv4_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block4_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m590,080\u001b[0m │ conv4_block4_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block4_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block4_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block4_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block4_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m262,400\u001b[0m │ conv4_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block5_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m590,080\u001b[0m │ conv4_block5_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block5_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block5_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block5_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block5_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m262,400\u001b[0m │ conv4_block5_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block6_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block6_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m590,080\u001b[0m │ conv4_block6_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block6_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block6_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block6_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block6_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block6_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block6_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │        \u001b[38;5;34m524,800\u001b[0m │ conv4_block6_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block1_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m2,359,808\u001b[0m │ conv5_block1_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block1_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_0_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │      \u001b[38;5;34m2,099,200\u001b[0m │ conv4_block6_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │      \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block1_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_0_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │          \u001b[38;5;34m8,192\u001b[0m │ conv5_block1_0_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │          \u001b[38;5;34m8,192\u001b[0m │ conv5_block1_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_0_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                           │                        │                │ conv5_block1_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m1,049,088\u001b[0m │ conv5_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block2_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m2,359,808\u001b[0m │ conv5_block2_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block2_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │      \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block2_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │          \u001b[38;5;34m8,192\u001b[0m │ conv5_block2_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv5_block2_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m1,049,088\u001b[0m │ conv5_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block3_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m2,359,808\u001b[0m │ conv5_block3_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block3_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │      \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block3_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_3_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │          \u001b[38;5;34m8,192\u001b[0m │ conv5_block3_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_add (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv5_block3_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_out          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ conv5_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │          \u001b[38;5;34m8,192\u001b[0m │ global_average_poolin… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m524,544\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │          \u001b[38;5;34m2,570\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_pad (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ conv1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_bn                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pool1_pad (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pool1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pool1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_0_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_0_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_0_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                           │                        │                │ conv2_block1_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ conv2_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv2_block2_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ conv2_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv2_block3_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ conv2_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv3_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_0_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ conv2_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_0_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_0_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                           │                        │                │ conv3_block1_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ conv3_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv3_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv3_block2_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ conv3_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv3_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv3_block3_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ conv3_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block4_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv3_block4_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block4_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block4_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block4_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv3_block4_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ conv3_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv4_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_0_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ conv3_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_0_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_0_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                           │                        │                │ conv4_block1_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ conv4_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv4_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block2_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ conv4_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv4_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block3_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ conv4_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block4_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv4_block4_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block4_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block4_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block4_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block4_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ conv4_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block5_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv4_block5_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block5_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block5_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block5_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block5_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ conv4_block5_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block6_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv4_block6_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block6_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block6_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block6_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block6_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ conv4_block6_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv5_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_0_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ conv4_block6_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_0_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_0_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                           │                        │                │ conv5_block1_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │ conv5_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv5_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv5_block2_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │ conv5_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv5_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_3_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv5_block3_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_out          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ global_average_poolin… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,185,440\u001b[0m (96.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,185,440</span> (96.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,210\u001b[0m (2.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,210</span> (2.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,591,808\u001b[0m (90.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,591,808</span> (90.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,062,422\u001b[0m (4.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,062,422</span> (4.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8e80CdEal1o",
        "outputId": "9ec397ce-97f0-42bc-90c8-d3d25e455aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4392 - loss: 1.5710\n",
            "Test accuracy: 0.44350001215934753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part B**"
      ],
      "metadata": {
        "id": "xMkBSclnl7fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "vC8ALwo_mCWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_targets = model.predict(x_train)\n",
        "soft_targets_val = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682HBXz5mGsT",
        "outputId": "965929fc-0b1e-4c8d-f590-8516811b85fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet18, _ = Classifiers.get('resnet18')\n",
        "\n",
        "student_model = ResNet18(input_shape=(32, 32, 3), weights=None, include_top=False)\n",
        "x = student_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "student_predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "student_model = Model(inputs=student_model.input, outputs=student_predictions)\n",
        "\n",
        "student_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "p1KYc3v2mL4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(y_true, y_pred, teacher_logits, alpha, temperature):\n",
        "\n",
        "    soft_targets = tf.nn.softmax(teacher_logits / temperature)\n",
        "    student_soft = tf.nn.softmax(y_pred / temperature)\n",
        "\n",
        "    distillation_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(soft_targets, student_soft, from_logits=False))\n",
        "\n",
        "    classification_loss = tf.keras.losses.categorical_crossentropy(y_true, tf.nn.softmax(y_pred), from_logits=False)\n",
        "\n",
        "    return (1 - alpha) * classification_loss + alpha * distillation_loss\n"
      ],
      "metadata": {
        "id": "Lblk0cuvqyWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for step in range(len(x_train) // batch_size):\n",
        "        x_batch = x_train[step * batch_size:(step + 1) * batch_size]\n",
        "        y_batch = y_train[step * batch_size:(step + 1) * batch_size]\n",
        "        soft_batch = soft_targets[step * batch_size:(step + 1) * batch_size]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = student_model(x_batch, training=True)\n",
        "            loss_value = distillation_loss(y_batch, logits, soft_batch, alpha=0.5, temperature=3.0)\n",
        "\n",
        "\n",
        "        grads = tape.gradient(loss_value, student_model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss_value.numpy()}\")\n",
        "\n",
        "\n",
        "    val_loss, val_acc = student_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLdwD7jOrM0e",
        "outputId": "d4bffde3-b8f6-4779-cdf3-89978b42c669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Step 0, Loss: [2.2799149 2.298647  2.1694627 2.3117614 2.297699  2.2892213 2.3273644\n",
            " 2.3037    2.3296137 2.3330383 2.2746263 2.3412304 2.3325949 2.3381715\n",
            " 2.2609668 2.2708156 2.2772353 2.343784  2.3219426 2.3096528 2.322557\n",
            " 2.3388085 2.290963  2.283947  2.3036108 2.329687  2.3371227 2.3048499\n",
            " 2.2867322 2.3549075 2.333856  2.196577  2.282762  2.3357573 2.2360754\n",
            " 2.3433614 2.336392  2.3187978 2.3507211 2.3469515 2.313612  2.2893462\n",
            " 2.2900095 2.3238235 2.305522  2.3145738 2.1840575 2.3332734 2.2518625\n",
            " 2.3515105 2.2841673 2.2994237 2.3012066 2.2179413 2.303209  2.2591581\n",
            " 2.274715  2.2913296 2.2858849 2.3427103 2.1089945 2.2608275 2.3207564\n",
            " 2.3317442 2.2675061 2.32552   2.3114634 2.2513037 2.3155184 2.2992265\n",
            " 2.2832873 2.092741  2.3304036 2.3246546 2.3472552 2.2295752 2.2466702\n",
            " 2.3218575 2.3434372 2.3119173 2.338322  2.2931104 2.3016052 2.2644851\n",
            " 2.3395371 2.325976  2.2838264 2.3425262 2.2645907 2.3050323 2.3291616\n",
            " 2.339591  2.3003147 2.325589  2.3037734 2.326693  2.2905025 2.3189101\n",
            " 2.249625  2.323204  2.3189125 2.3247495 2.1785426 2.2773862 2.3207288\n",
            " 2.3189216 2.3028963 2.1706665 2.3360295 2.2965775 2.3045387 2.3228774\n",
            " 2.3176992 2.299394  2.1873326 2.3485956 2.2849464 2.2951317 2.2285\n",
            " 2.3498302 2.3164506 2.3128257 2.2587376 2.3092387 2.2777338 2.340877\n",
            " 2.3261633 2.215551 ]\n",
            "Step 100, Loss: [2.3832026 1.9353242 2.3832006 2.3807802 1.8832026 2.3714824 2.3598154\n",
            " 2.324545  2.3832026 1.9146128 2.3746622 2.373441  2.355968  2.1502633\n",
            " 2.3831964 2.3689034 2.3283875 2.3832018 2.3595526 1.8995628 2.0278747\n",
            " 2.3823254 1.8832715 2.0702038 1.8832092 2.3621385 2.3475425 1.8832074\n",
            " 2.358279  1.8927578 1.8832026 2.3828778 2.3831968 1.8879381 1.8832027\n",
            " 2.3830717 2.3823907 2.0703392 2.381888  1.8988116 1.8832028 2.3831954\n",
            " 1.8832047 2.3577247 2.3660467 1.8832033 2.194606  2.3638594 1.8850952\n",
            " 2.3831625 1.8832235 1.9019904 1.8832037 2.0386868 2.3832026 2.383197\n",
            " 2.3832016 2.36588   2.3544989 2.379251  2.3598459 1.8832027 2.3437023\n",
            " 1.8832456 2.368298  2.3831677 1.8832469 2.3550653 1.8851013 1.9622719\n",
            " 2.2084193 2.3727071 2.191531  2.378518  1.8832033 2.3657773 1.9195936\n",
            " 2.3831913 2.3647509 2.3819013 2.3659582 2.3831816 2.3784482 2.3823724\n",
            " 2.3823907 1.8832266 2.3076696 1.8879889 1.8900555 1.8832119 2.3831577\n",
            " 2.0911884 2.3830771 1.9496982 2.3831866 2.3322463 2.365829  2.375478\n",
            " 2.3308318 2.374936  2.0066936 1.8940946 1.8832026 2.3832026 2.3824334\n",
            " 1.8848002 2.3777897 2.3824077 2.3600214 2.376242  2.3832023 2.3822975\n",
            " 2.3779426 1.9465394 2.3814363 2.3623724 1.961169  2.3675542 2.3818216\n",
            " 2.3831706 1.8832026 2.2699265 2.383202  2.3832006 1.8967714 2.3662229\n",
            " 2.3687027 2.3648171]\n",
            "Step 200, Loss: [1.8849257 1.8832657 2.3564153 2.370927  2.3832014 2.37127   2.2440596\n",
            " 2.3784552 2.383206  2.383206  2.0080826 1.8843213 2.3781972 1.8832059\n",
            " 2.383206  1.8835249 2.254478  1.8832061 1.8832071 1.8832103 2.381649\n",
            " 1.8877542 2.3715966 2.3826046 2.1633708 2.383206  2.3832018 2.3768299\n",
            " 1.9976288 1.8857758 2.3831644 1.8832505 1.8832059 2.361894  2.383206\n",
            " 2.3826506 1.9841317 2.3522637 1.8832061 2.3430557 2.3645656 1.8862433\n",
            " 1.9926511 2.372848  1.9233099 1.8832078 2.372285  1.8832059 1.8835886\n",
            " 2.3831606 2.2488995 2.383206  2.383206  1.8832698 1.8832059 1.885551\n",
            " 2.1506143 2.374198  2.383205  2.3767912 2.383206  2.3802822 2.3827758\n",
            " 2.3495822 2.0284457 2.367661  2.3011174 2.2081423 2.383205  1.8844998\n",
            " 2.3688843 2.381487  1.9082325 2.381248  2.3820243 2.1993985 2.2972417\n",
            " 2.3176565 1.8832059 2.0769203 2.167769  1.8832059 1.8832059 2.383186\n",
            " 1.9713668 2.3832033 2.3829517 2.379976  2.3750596 1.8832059 2.3814158\n",
            " 1.8832064 2.1217775 1.9631963 1.8832064 2.101405  1.8864306 2.215968\n",
            " 2.3690982 2.3832011 1.8832145 2.3671825 2.383197  2.3809457 1.9729996\n",
            " 2.383191  2.072193  2.3831878 1.8832059 1.8832059 1.8832059 2.350655\n",
            " 2.282393  2.3674319 2.3832045 1.9028019 2.3047643 2.1278822 1.8832059\n",
            " 2.3832054 2.1919577 1.8832059 2.3832057 2.3639925 1.8939383 2.373654\n",
            " 2.3813381 2.3098311]\n",
            "Step 300, Loss: [2.3831902 1.8832169 2.383216  2.3602705 2.367106  1.8832166 2.38028\n",
            " 2.382216  2.3605695 2.382719  1.9703047 2.3735962 1.8832417 1.8832402\n",
            " 2.3832166 1.8832825 2.380878  2.2786167 2.3195794 1.9169986 1.9993734\n",
            " 2.3831298 2.3774061 2.373536  2.3773026 2.3832166 2.3832166 2.3645642\n",
            " 2.3004422 2.3616266 2.3451235 2.383215  2.3645372 2.3832166 2.288156\n",
            " 2.3832166 1.8832166 2.3781815 1.8836184 2.3829842 2.3832102 2.3700686\n",
            " 1.983664  2.3831053 2.2455194 2.3831983 2.3832114 1.8832468 2.3831081\n",
            " 2.357507  1.8832563 2.3832166 1.8832169 1.8838191 2.382456  2.381909\n",
            " 2.1723142 2.3649604 2.3756294 2.3624535 1.8988588 1.8832285 1.8832183\n",
            " 1.8832166 2.3832166 1.9045943 2.370481  2.3832166 2.380794  2.3832164\n",
            " 2.3832166 1.8871288 1.9366608 1.8832169 1.9130852 2.349422  1.9356363\n",
            " 2.0675342 2.354095  2.3832166 2.3821974 1.8832166 1.8832166 1.8832166\n",
            " 2.3828166 2.1702185 2.3123    2.3832166 2.2643456 1.8832166 2.3832068\n",
            " 1.8832166 2.36789   2.3832166 1.8832166 2.372788  2.29873   2.1101425\n",
            " 2.0744665 1.8832166 1.9095746 1.9175258 2.3830419 2.3769016 2.171546\n",
            " 1.8838739 2.3832166 1.883219  1.9963031 2.3806643 1.8940232 2.3830543\n",
            " 1.9549787 1.8832238 1.8832166 2.3713424 2.3832002 1.8837357 2.382801\n",
            " 2.381075  2.383213  1.9184563 2.3692465 2.3832166 2.3710375 1.8834813\n",
            " 1.9193275 2.383216 ]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3685 - loss: 13.8897\n",
            "Validation loss: 13.934479713439941, Validation accuracy: 0.36570000648498535\n",
            "Epoch 2/10\n",
            "Step 0, Loss: [2.361916  2.3826432 1.8833802 2.3833795 2.3833795 2.3833795 2.373858\n",
            " 1.8833795 2.3833795 2.354196  2.383366  1.8833795 1.9369411 2.3833795\n",
            " 1.8834097 2.3833795 1.8833795 2.1068916 2.3649065 1.8848106 2.3511627\n",
            " 2.382958  1.8833797 1.8834476 2.1947377 2.3746443 2.0119734 2.2896814\n",
            " 2.383275  2.3833773 2.293571  2.3833513 1.8833795 2.363724  2.3734128\n",
            " 2.3833795 2.3681793 2.3568528 2.3176446 2.3654175 1.8850386 2.383351\n",
            " 2.011839  1.8833795 2.3833694 2.382221  1.8839798 2.3820105 2.108984\n",
            " 2.3824015 2.3565197 2.192647  2.3828182 2.3833792 1.915185  2.3793786\n",
            " 2.3832424 2.3833728 2.382495  2.3833795 1.8833795 2.3564098 1.8833795\n",
            " 2.0049741 1.8833895 2.3833728 1.8981931 1.8833795 1.8833795 1.8834462\n",
            " 2.3828847 1.8843912 2.3833795 2.3629284 2.3682156 1.8834869 2.2566004\n",
            " 1.8835537 2.382462  2.3753932 2.3833795 2.3722663 1.9428558 2.2875133\n",
            " 2.3645802 2.3832083 1.8859756 2.2164454 1.8834362 2.2943044 2.3831816\n",
            " 2.3714774 1.8833795 1.8833797 2.3706732 1.8833797 1.8833795 2.383379\n",
            " 2.382864  2.383379  1.8833795 2.2541194 1.8833795 1.8833895 1.8833795\n",
            " 2.3833795 1.8833795 2.3779492 2.380538  2.3833559 1.8834667 2.3833795\n",
            " 2.3798587 1.8833797 1.8833822 1.8833795 2.3782892 1.88338   2.3833551\n",
            " 2.3833752 1.9552643 2.0010948 2.2527642 2.3599143 1.8833795 2.3833795\n",
            " 2.3833795 2.3833706]\n",
            "Step 100, Loss: [2.3832927 1.8833065 2.3832932 2.147882  1.8832932 2.3822594 1.8832932\n",
            " 2.3832874 1.8847836 1.8832932 2.3817956 2.383232  2.367937  1.8834049\n",
            " 1.8833009 2.1194644 2.383292  2.3832932 2.3818204 2.0785625 1.8832945\n",
            " 1.9075937 1.8832932 1.908011  1.8832932 2.3794966 2.3800163 1.8834343\n",
            " 2.1214232 1.8835318 1.8832932 1.8832933 2.3802972 1.8832979 1.8832932\n",
            " 2.3785906 2.3832932 1.9444697 1.883318  1.883346  1.8876746 2.3832927\n",
            " 1.8832932 2.3573604 1.8832946 1.8832932 1.9017615 2.3819394 1.8832937\n",
            " 1.8832932 1.8832932 1.8833148 1.8832934 1.897757  2.383293  2.3832932\n",
            " 1.8832932 2.3831542 1.8914864 2.3832932 2.3832865 1.8832932 2.3339677\n",
            " 2.3832932 1.8834052 2.3832927 2.3652067 1.8833237 1.8832932 2.3832932\n",
            " 1.9224105 2.3814354 2.079603  2.0336418 2.2989843 2.364391  2.3832488\n",
            " 2.3832924 2.3240638 2.3755684 1.8833025 2.383285  1.8918135 1.9121215\n",
            " 2.3832932 1.8832932 2.1288052 1.9931775 1.8832932 1.8832932 2.3786182\n",
            " 1.8902764 2.3832922 1.8832932 2.3832927 2.338853  2.3504033 1.8833756\n",
            " 2.3810303 2.3751476 1.8832934 1.8833127 2.3832932 2.3832932 2.2176871\n",
            " 1.8832932 2.3819563 1.8832932 2.3720343 1.9276695 2.3832932 2.3832927\n",
            " 2.3832927 1.885335  1.8832932 2.3832922 1.8832932 2.3832922 1.8832932\n",
            " 2.3832932 1.8832932 1.9437325 2.3832927 2.3832927 1.8854334 2.2975774\n",
            " 1.883424  2.38199  ]\n",
            "Step 200, Loss: [1.8832569 2.3831549 2.3614898 2.2901547 2.382823  2.3774204 1.8839041\n",
            " 2.3132966 2.3825293 2.3831973 2.0108728 1.883243  1.8832431 1.8832428\n",
            " 2.3832426 1.8832428 1.8832428 1.8832428 1.8832428 1.8832428 2.3776946\n",
            " 2.2467003 2.3831515 1.8912516 1.8832428 1.8832428 2.3832426 2.1445699\n",
            " 2.3633704 2.3460903 2.3832426 1.8832428 1.8832853 1.8963333 2.383216\n",
            " 2.3832388 1.8996122 2.3832006 1.8835309 1.9032393 2.2107959 1.8862447\n",
            " 1.8922306 2.3825216 1.8832428 1.8834951 1.8864467 1.8832428 1.8832431\n",
            " 2.3520503 2.3222022 2.3819575 1.8832428 1.8878736 1.8832428 1.9165912\n",
            " 2.3686652 2.3831959 1.8833743 1.8832428 2.3566284 1.9010427 2.3744204\n",
            " 2.383078  1.9341813 2.37609   2.3832407 2.3828459 2.3832426 1.8949251\n",
            " 2.3832407 2.3831854 2.1709142 1.892107  2.3832426 2.3389997 2.361878\n",
            " 2.3832426 1.8832428 1.8832428 1.8832644 1.8832428 1.8832428 2.1750205\n",
            " 1.8891821 1.9124329 2.3563557 2.3547091 2.3830307 2.3644395 2.3831568\n",
            " 1.8832428 2.363515  2.2918596 2.2943711 1.8833342 1.8832428 1.8832428\n",
            " 2.3420627 2.3824797 2.3832407 2.374351  2.3832378 2.362568  1.8832645\n",
            " 2.377676  2.3809266 2.3831882 1.8832428 1.8832452 1.8832428 2.3024359\n",
            " 1.8832428 1.9711721 1.8836122 2.3817995 2.3832417 1.8832448 1.8832428\n",
            " 2.383213  2.365982  1.883273  2.3829312 2.3829308 2.369299  2.3832426\n",
            " 2.3355541 2.375877 ]\n",
            "Step 300, Loss: [2.1045039 1.8833127 2.3831553 2.3806887 2.3816538 1.8833125 2.382289\n",
            " 2.3831587 1.8834152 1.8833125 2.383294  1.9347456 1.8985784 2.3833115\n",
            " 2.3833122 1.8833125 1.9210494 1.8833249 2.3699405 1.8841276 2.3833098\n",
            " 2.3817954 2.38241   2.365005  2.365706  2.3833122 1.9516091 1.8846647\n",
            " 2.3253107 1.8925719 2.3610067 2.3833122 2.028     2.3817434 2.3833113\n",
            " 1.8835914 1.8833125 1.9480131 2.372285  2.3685331 2.3532953 2.3807917\n",
            " 1.8857502 2.3820777 2.366489  2.3518114 2.3832488 1.8833385 2.3833122\n",
            " 1.8890777 1.8875849 2.3833122 1.8850511 1.8833125 2.3833122 2.3833075\n",
            " 1.8834882 2.383308  1.8842614 2.3833065 1.8833125 1.8833125 1.8833132\n",
            " 1.8833125 2.3831184 2.3832245 2.3833122 1.8833125 2.3820224 2.363944\n",
            " 1.8837161 1.8833768 2.1151211 1.8912787 1.9793928 1.8833699 1.8880087\n",
            " 1.8833125 1.8833125 2.362722  2.37685   1.8833125 1.8833125 1.8833125\n",
            " 2.3806553 1.8839355 2.3783536 2.3833122 2.0732124 1.8833126 2.3832688\n",
            " 1.8833127 2.3833113 1.8833125 1.8835547 1.8833656 2.162013  2.3625202\n",
            " 1.8842758 1.8833125 1.8833125 1.885314  1.8992097 2.3663747 1.890801\n",
            " 1.8833125 2.3832831 1.8833177 1.8833125 1.8870995 1.8833134 2.3832526\n",
            " 2.3832016 2.0219622 1.8833125 2.3780823 1.8833864 2.3832493 2.383312\n",
            " 2.3812816 2.378419  2.383277  2.3794022 1.8833125 2.3833113 2.3831346\n",
            " 1.887402  2.364248 ]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4187 - loss: 8.2113\n",
            "Validation loss: 8.047940254211426, Validation accuracy: 0.4226999878883362\n",
            "Epoch 3/10\n",
            "Step 0, Loss: [2.3833504 2.3833175 2.379951  2.3832617 2.383351  1.8833511 2.3833432\n",
            " 1.8833511 1.8833511 2.383351  1.8835744 1.8833511 2.383351  2.383351\n",
            " 1.8833512 2.383351  1.9104353 2.3107696 2.3831139 1.8838494 2.354328\n",
            " 2.3831716 1.8833511 1.8833787 2.2885904 2.3801203 1.8846371 2.3833508\n",
            " 2.3803618 2.333233  1.8854718 1.8833511 1.8833511 2.3833396 2.3832614\n",
            " 2.3833508 1.898499  1.8833535 2.2759008 2.35646   2.3597512 2.3833396\n",
            " 1.8836929 1.8833511 2.3830955 1.8833511 1.8833511 2.3829708 1.8833704\n",
            " 2.3833508 2.383099  2.379722  1.8836262 2.383351  1.8837714 1.8962369\n",
            " 2.369097  2.3655403 1.8893653 2.3832815 2.3616025 2.3672059 1.8833511\n",
            " 1.8858588 1.8833511 1.8833511 2.3833063 1.8974788 1.8833511 2.383351\n",
            " 2.3833475 1.8833511 2.37923   2.3819861 2.380905  2.3720086 2.3833227\n",
            " 1.8833524 2.382864  2.3816452 2.3833468 2.3821647 2.3807547 2.3773923\n",
            " 2.3716345 2.3797154 2.3832693 1.8884611 2.383351  2.382915  2.359227\n",
            " 2.355392  1.8833511 1.8833511 2.3832352 1.8990302 1.8833511 1.9585414\n",
            " 1.8839535 1.8833511 2.3832304 2.3819757 1.8833556 2.3726704 2.2851276\n",
            " 1.8833511 1.8833511 1.8833536 1.8937371 2.383351  2.383351  2.3833508\n",
            " 1.883393  2.3833137 1.8833514 1.8833511 2.37635   1.8883629 2.3829346\n",
            " 2.3833504 1.8969581 1.8833914 1.8833511 2.3785965 1.8833524 2.3831344\n",
            " 2.383351  2.383316 ]\n",
            "Step 100, Loss: [1.8833756 1.8833804 2.3773212 2.3833694 1.8833756 2.2775245 1.9316597\n",
            " 1.8833756 2.341615  1.8833756 1.8950841 2.249545  2.3816118 2.3833702\n",
            " 2.383308  2.3255892 2.3820658 2.3833756 2.3818908 1.9243197 1.8833756\n",
            " 1.8838573 1.8833756 2.2664146 1.8833756 2.3642292 2.1796498 2.3833756\n",
            " 1.8833756 1.8833842 1.8833756 1.8838325 1.8875277 1.8833756 1.8833756\n",
            " 2.3833756 2.0885859 2.383165  1.883661  1.8834031 2.383232  2.3833754\n",
            " 1.8833756 2.383338  1.8833756 1.8833756 1.8839593 2.3822684 2.381788\n",
            " 1.8833756 1.883408  1.8833756 1.8833756 2.3833575 2.3833628 2.3833756\n",
            " 1.8833756 2.3833747 1.8836267 2.372128  1.8945773 1.8833756 1.9394903\n",
            " 2.3833756 2.383142  2.3833756 1.8833756 2.38105   1.8833756 2.192677\n",
            " 2.3832202 2.3831334 1.8850739 2.3682737 1.883899  2.381184  1.8833756\n",
            " 2.3833745 1.8884232 2.3689713 2.3308377 2.3833756 2.111562  1.8833756\n",
            " 2.3833756 2.3420262 2.1375065 1.8833821 1.8833756 1.8833756 2.3828185\n",
            " 2.3825293 1.968467  1.8833756 2.383373  2.359783  1.8846211 2.3831117\n",
            " 2.383347  2.3832328 1.8886864 2.3527548 2.3833756 2.3833745 1.9591151\n",
            " 1.8833756 1.9168737 1.8833759 2.3833294 2.3445802 2.3764522 2.3670526\n",
            " 2.3759148 1.8833768 1.8833756 2.3833733 1.8833756 2.3833213 2.3833756\n",
            " 1.8833756 1.8833756 1.8834877 2.3833745 2.3833756 1.8991355 2.3829217\n",
            " 2.3493686 2.3833752]\n",
            "Step 200, Loss: [1.8832073 1.8832064 2.365808  2.3644123 2.383197  2.3831627 1.8832289\n",
            " 2.3778572 1.8832064 2.3832064 1.9216309 2.3831372 1.8832064 1.8832064\n",
            " 2.3832064 1.8832064 1.8832064 1.8832083 1.8832064 2.3831375 2.3832064\n",
            " 1.8832068 2.3636713 2.3827834 1.8832064 1.8832064 2.3832064 2.3826017\n",
            " 2.3816674 2.3832061 2.3831642 1.8832064 1.8832148 1.892748  2.3832064\n",
            " 2.3831496 1.8858733 1.8865362 1.8832272 1.9179623 2.3824158 1.8967566\n",
            " 2.1330569 2.3705692 1.8832064 1.8851311 2.3832064 2.3832064 1.8832064\n",
            " 2.3683865 2.383205  2.3573833 1.8832064 1.8832064 1.8832064 1.8835794\n",
            " 2.2844834 2.3830676 1.8832066 1.8832065 1.8832073 2.3650186 2.36152\n",
            " 2.3832054 2.299349  1.8969471 2.3797636 2.3831298 2.3831587 1.8832139\n",
            " 1.9079449 2.383175  1.8847275 2.3042793 1.9733741 2.3252077 2.3823934\n",
            " 2.3832064 1.8832064 1.8832064 1.8915422 1.8832064 1.8832064 2.379358\n",
            " 2.2696881 2.3832064 2.3572292 2.3692093 2.3811536 2.3832061 2.3498998\n",
            " 1.8832084 2.0569324 2.3831067 1.8832064 1.8832067 1.8832064 1.8832064\n",
            " 2.383206  2.3794127 1.8832064 2.3831935 2.35997   2.354031  1.8832066\n",
            " 2.3753672 2.3832064 2.3639798 1.8832064 1.8832104 1.8832138 2.3679543\n",
            " 1.8832064 2.2097983 1.8832065 1.88485   2.3832064 1.8832064 1.8832064\n",
            " 2.3812313 1.9112942 1.8832064 2.3832064 2.365441  1.887048  2.3830988\n",
            " 2.3831844 1.891333 ]\n",
            "Step 300, Loss: [1.9089327 1.8833162 1.8833015 2.3832736 2.3661184 1.8833015 2.3833015\n",
            " 2.3832965 2.3653336 1.883302  1.8833015 1.8850797 1.8833015 1.8833016\n",
            " 2.3833013 1.8833015 1.8833015 2.108712  2.3825872 1.8833015 2.3833008\n",
            " 2.383286  2.3831768 2.3832765 2.3832977 2.3833008 2.3833003 1.8998339\n",
            " 2.0448575 2.3757524 2.3833015 2.3831668 2.3829553 2.3832946 2.3655915\n",
            " 2.3832974 1.8833015 2.3114386 2.2747111 2.382977  1.9521894 1.8876995\n",
            " 1.8837538 2.3832974 2.173355  2.2763348 2.3572183 1.8940063 2.3832936\n",
            " 1.8838017 1.9464182 2.152282  1.8833458 1.8833016 2.3833015 2.3832355\n",
            " 1.8833015 2.3833015 1.9297321 2.3608534 1.8833015 1.8833015 1.8833015\n",
            " 1.8833015 1.8833015 2.3833015 2.3833015 2.3833015 2.375751  2.3637993\n",
            " 1.8868022 1.8833456 1.898995  1.8833015 1.8833015 2.1381996 1.8834543\n",
            " 1.8833015 1.883311  2.3817208 2.3833015 1.8833015 1.8833015 1.8833015\n",
            " 1.883302  1.894435  2.3823428 2.3833015 1.883321  1.8833023 2.3833015\n",
            " 1.8833015 2.377068  1.8833015 2.3833015 2.3751726 1.9198272 2.378859\n",
            " 1.8835851 1.8833015 1.8833015 1.8833015 1.9561574 2.3651528 1.895079\n",
            " 1.8833015 1.8833015 1.8833015 1.8833015 1.8834012 1.8833015 2.3832965\n",
            " 2.3822017 1.8834821 1.8833015 2.3832998 2.0981812 2.3833015 2.3833005\n",
            " 2.3820157 2.3685856 1.9087393 2.3814838 1.8833016 1.8833025 1.8836098\n",
            " 2.2989228 2.3832912]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4487 - loss: 11.2486\n",
            "Validation loss: 11.36268138885498, Validation accuracy: 0.44699999690055847\n",
            "Epoch 4/10\n",
            "Step 0, Loss: [2.3833103 2.3833122 1.8839846 1.8833202 1.8833265 2.3735552 2.3833122\n",
            " 1.8833122 1.8833122 2.3833113 1.8833268 1.8833122 1.8833122 2.3833122\n",
            " 1.8849094 2.3833122 1.8833122 1.8953353 2.3833122 1.8833122 2.382797\n",
            " 1.9107196 1.8833122 1.8833135 2.35503   1.8898647 1.8835365 2.3263867\n",
            " 2.3667536 2.3833122 1.8833227 2.3833115 1.8833122 1.9141214 2.3589118\n",
            " 2.3833122 1.8853877 2.3619075 2.3828022 2.3830621 2.373619  2.3833122\n",
            " 1.8841815 1.8833122 1.8833122 1.8833122 1.8833122 2.3833122 1.8833137\n",
            " 1.883348  2.381678  2.3728535 2.369468  2.335946  1.8833396 2.3832493\n",
            " 2.3514898 2.3832498 2.3684473 2.3833122 1.8833122 1.8834523 1.8833122\n",
            " 1.8864777 2.299077  1.8833122 1.8846037 1.8833122 1.8833125 1.8833122\n",
            " 2.3639557 1.8833447 2.383193  2.1995258 2.3815904 2.348002  1.883435\n",
            " 1.8833122 2.2422295 2.383311  2.3827105 2.3826969 1.8833123 2.3234887\n",
            " 2.362664  2.3833077 1.8915422 2.3604856 2.3833122 1.9944344 2.3553326\n",
            " 2.382594  1.8833122 1.8833122 2.379703  1.8833122 1.8833122 2.377967\n",
            " 1.8833134 2.382701  2.2909687 1.8905361 1.8895909 2.2012644 1.8833122\n",
            " 1.8833122 1.8833122 2.366902  2.354793  2.121949  2.3833122 2.383311\n",
            " 1.927174  1.8833127 2.3833122 1.8833122 2.3833115 1.8833122 1.8839678\n",
            " 1.8833122 1.8836496 1.8833151 1.8833122 2.3736358 1.8833122 1.8833134\n",
            " 2.3833044 2.3831215]\n",
            "Step 100, Loss: [2.3833108 1.883311  2.377792  2.3255422 1.883311  2.0316296 2.3663502\n",
            " 1.883311  1.883311  1.8833153 2.2418966 2.383124  2.3822417 2.383311\n",
            " 2.383311  1.9103601 2.3833075 2.383311  2.3009405 1.8833127 2.3439608\n",
            " 2.2572072 1.8833116 1.8940167 1.8889314 2.383243  2.383297  1.883311\n",
            " 2.1432147 1.895081  1.883311  2.3833039 2.3410668 1.883311  1.883311\n",
            " 2.383311  2.383311  2.3828895 2.383311  1.8833115 1.8833113 2.3833108\n",
            " 2.3755383 1.883311  1.8833146 1.883311  2.3702664 2.3833108 2.383311\n",
            " 1.883311  1.883311  1.883311  1.883311  2.3594763 2.3669553 2.383311\n",
            " 1.883311  2.3832994 2.3786325 2.3780708 1.8833477 1.883311  1.8833296\n",
            " 1.962856  1.8856887 1.8833131 1.883311  1.8835924 1.883311  1.8833337\n",
            " 2.374054  2.383311  2.378169  1.883311  1.883311  2.3633647 2.383311\n",
            " 2.364831  2.3684015 2.3833108 1.8844013 1.883311  2.3818045 1.883311\n",
            " 2.3831959 1.8833306 2.251059  2.2343946 1.883311  1.883311  2.3559802\n",
            " 2.3833098 2.3624883 1.883311  2.383311  2.3782575 2.382432  2.3829222\n",
            " 2.3833108 2.3701975 1.885129  2.383311  2.383311  2.383311  1.8863158\n",
            " 1.883311  2.383243  1.9176345 2.3824975 2.3832707 2.383311  2.383296\n",
            " 2.3162715 1.8833425 1.883311  2.3748612 1.8834549 2.3767023 1.8834429\n",
            " 1.8933593 1.883311  2.365069  2.383311  2.3832984 1.8833113 2.3706193\n",
            " 2.3709056 2.3833044]\n",
            "Step 200, Loss: [1.8831921 1.8831921 2.2618012 2.383192  2.383192  2.3758779 1.8831924\n",
            " 2.2810874 2.383192  1.8832004 1.8833171 2.3830395 1.8908219 1.8831921\n",
            " 2.383192  1.8831921 1.8831921 2.0158653 1.8831921 1.8831921 2.3828955\n",
            " 1.8831921 2.3831878 1.8831921 1.8831921 2.383192  2.383192  2.3830862\n",
            " 2.309595  2.383192  2.3814926 1.8831921 1.8831923 1.9100988 2.383192\n",
            " 2.383145  1.8831921 2.383192  1.883364  1.9565463 2.3650866 2.3813493\n",
            " 2.3829155 2.3831902 1.8831921 2.3830657 2.383192  1.8831921 1.8831921\n",
            " 2.382966  1.9886277 2.364049  1.8831921 1.8831921 1.8831923 1.8831921\n",
            " 2.2426512 2.383192  1.8831928 1.8874946 1.8831921 2.2218032 2.3793092\n",
            " 2.383192  2.2766752 2.3703115 1.8832462 2.3831918 2.383192  1.8831921\n",
            " 2.3831701 2.383192  1.8831925 2.3824334 1.8837717 1.8831921 2.3805118\n",
            " 2.3831916 1.8831921 1.8831921 2.3813133 1.8831921 1.8831921 2.3720357\n",
            " 2.3831916 1.8997653 2.3759222 2.2585566 2.2945542 2.3831916 1.8831921\n",
            " 1.8831921 2.1342483 2.2693093 1.8831921 2.285016  1.8831921 1.8831921\n",
            " 2.337666  2.382956  1.8831921 2.3831916 2.3831918 2.3813477 1.88321\n",
            " 2.383192  2.3184338 2.3831916 1.8831921 1.8831921 1.8831921 2.3527932\n",
            " 1.8831921 2.3706994 2.383192  1.8831921 2.3831615 1.8831921 1.8831921\n",
            " 1.8860543 1.884195  1.8831921 2.383192  2.3637457 1.8831929 2.383192\n",
            " 2.3831863 2.0582294]\n",
            "Step 300, Loss: [1.8849176 1.8832815 1.9057927 2.3823729 2.3832707 1.8832815 2.3832808\n",
            " 1.8835138 1.8887382 1.8832815 2.379164  1.8834167 2.0620008 2.3832812\n",
            " 1.8832977 1.8832815 1.8832815 1.8832827 2.2472892 2.144668  2.3832812\n",
            " 2.3632493 2.3801975 2.3361049 2.3832629 2.3832803 1.8832815 1.8936303\n",
            " 1.8833523 2.3832402 2.3832812 2.1739426 2.3117602 1.8832815 2.3832812\n",
            " 1.8832921 1.8832815 2.0590658 2.0790946 2.3750508 2.3608356 2.3815598\n",
            " 1.8832972 2.3612533 2.3791811 1.9200325 2.3688421 1.8834496 2.3832812\n",
            " 1.896275  1.9737911 1.8834248 1.8832815 1.8832815 2.3832812 2.360106\n",
            " 1.8847427 2.3831668 1.8958249 2.3827257 1.8832815 1.8832827 1.8832815\n",
            " 1.8832815 2.3832812 1.884201  2.3831286 1.8832815 2.3832765 2.3822484\n",
            " 1.8832815 1.883427  1.9332898 2.3232963 2.3832812 1.8832815 1.906874\n",
            " 1.8840576 1.8832815 2.3832812 2.3832307 1.8832815 1.8832815 1.8832815\n",
            " 1.8834019 2.2707052 1.883316  2.3832812 2.3267121 1.8832815 2.3832812\n",
            " 1.8832815 1.8833349 1.8832815 1.8832815 2.3831804 2.383209  2.3812208\n",
            " 2.1567984 1.8832815 1.8832815 1.8832824 1.8836255 2.3830743 2.22288\n",
            " 2.3831306 1.8832815 1.8832815 1.8832815 2.300475  1.8832817 2.383278\n",
            " 2.3832788 1.9107034 1.8832815 1.883307  1.8832815 2.3832812 2.3456328\n",
            " 2.3830767 1.8832952 1.9189248 2.369203  1.8832815 2.3832397 2.3832254\n",
            " 1.8832815 2.2868862]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4857 - loss: 9.3025\n",
            "Validation loss: 9.26695442199707, Validation accuracy: 0.4864000082015991\n",
            "Epoch 5/10\n",
            "Step 0, Loss: [2.3833148 1.8833184 1.8833184 2.3833003 1.8833184 2.3832846 2.3832884\n",
            " 1.8833184 1.8833189 2.3833184 1.8833184 1.8833184 1.8868955 2.3833184\n",
            " 1.8833184 2.3833184 1.8833184 1.894641  2.3807497 1.8833226 2.3833184\n",
            " 2.3833046 1.8833184 1.8833187 2.3573003 2.3832986 1.8835673 2.3695188\n",
            " 2.383318  2.3801389 1.8856142 1.8833184 1.8833184 2.3833184 2.3755739\n",
            " 2.3833184 1.8899596 1.8833184 2.282434  2.3832664 2.0396473 2.3833184\n",
            " 2.0651684 1.8833184 2.3833184 1.8834466 2.3833184 2.3833184 1.8833718\n",
            " 1.8833199 2.376175  2.3774264 2.3345177 2.3833184 1.8833308 2.3786533\n",
            " 2.3642569 2.3778129 2.383229  2.3833184 1.8833184 1.8833184 1.8833184\n",
            " 2.3830929 1.8833184 1.8833184 1.908312  1.8833184 1.8833184 2.3833184\n",
            " 2.3654225 1.8833184 2.3833184 1.8844699 2.337056  2.3591661 1.8833184\n",
            " 1.8833184 2.3832679 2.3819432 2.2847495 2.3832524 2.331736  1.8880929\n",
            " 2.3598337 2.0028658 2.3833175 1.8833184 2.3833184 2.01664   2.3807468\n",
            " 2.3833039 2.3615196 1.8833184 2.3831606 1.8833184 2.3833184 1.8833821\n",
            " 1.8915089 2.3767536 2.3833184 2.3833053 1.8833184 1.8833184 1.8833184\n",
            " 1.8833184 1.8833184 1.8958819 1.8941932 2.3828883 2.3833184 1.8833187\n",
            " 2.3833184 2.383237  1.9034424 1.8833184 2.367526  1.8833191 2.3833184\n",
            " 2.3833184 1.8833406 1.8834364 1.8833373 2.378604  1.8833184 2.0515304\n",
            " 2.3833184 2.3832574]\n",
            "Step 100, Loss: [1.8834114 1.8834115 2.381721  2.3031075 1.8834114 1.9258738 2.3831024\n",
            " 1.8834114 1.8834114 1.8834114 2.3834069 2.3833547 2.37044   2.3772006\n",
            " 2.3828998 1.8871691 1.8834114 2.383411  2.3805614 1.8834114 1.8834114\n",
            " 1.8978441 1.8834114 1.8834894 1.8834114 2.381073  2.3834    1.8834114\n",
            " 1.8834118 1.9933991 1.8834114 1.8834114 2.383408  1.8834114 1.8834114\n",
            " 1.8834118 2.38341   2.3820872 1.9294981 1.8834119 1.8834114 2.3834114\n",
            " 1.8834114 1.8834114 1.8834176 1.8834114 1.883695  2.3711405 1.8834114\n",
            " 1.8834114 1.8834114 1.8834114 1.8834114 1.8834121 1.8834765 2.3834114\n",
            " 1.8834116 2.3834114 2.3833194 2.3833933 1.966351  1.8834114 2.1674252\n",
            " 1.8834114 1.8834319 2.3834114 2.3834114 2.3222342 1.8834114 1.8834115\n",
            " 1.8834143 2.3833427 2.0769696 1.8834236 1.8834114 2.367385  2.3834114\n",
            " 2.3832643 1.8834133 1.8834205 2.3831477 1.8834114 2.3812635 1.8834114\n",
            " 2.382989  1.8834201 1.9297379 1.8834114 1.883415  1.8834114 2.3659124\n",
            " 1.8834407 2.3800468 1.8834114 2.3832865 2.3834114 1.942575  1.9051912\n",
            " 2.3834114 2.3652887 1.8834163 2.3833513 2.383411  2.3834114 1.884377\n",
            " 1.8834114 1.8834114 2.3822412 2.383411  2.3804665 2.3834112 2.3834114\n",
            " 1.931605  2.3832598 1.8834114 2.382813  1.8834114 1.8834114 2.3833952\n",
            " 2.3718586 1.8834114 1.8851535 1.8834114 2.3803296 1.8834114 2.3832004\n",
            " 1.8834139 2.378359 ]\n",
            "Step 200, Loss: [1.8832195 2.3832195 2.383183  2.3832192 2.3832195 2.3810036 1.88322\n",
            " 1.8855543 1.8832195 2.3832195 1.8832686 1.8832195 1.8832195 1.8832195\n",
            " 2.3832195 1.8832195 1.8832195 2.1141956 1.8832195 1.8832195 2.3832195\n",
            " 1.8832195 2.3832192 1.8832195 1.8832198 1.8832195 1.9167105 1.9129572\n",
            " 1.9090455 1.8832195 2.383213  1.8832195 1.8832237 2.3045988 2.3832195\n",
            " 2.3832195 2.3824549 1.8841361 1.8832195 1.8833044 2.3685465 1.8834729\n",
            " 1.9269807 2.3742113 1.8832195 1.8832195 2.3832195 2.3832195 1.8832195\n",
            " 2.3793318 2.3832164 2.3831    1.8832195 1.8832195 1.8832195 1.8832195\n",
            " 2.3795848 2.3832188 1.8832197 2.3832176 2.3832135 2.3296862 1.9206818\n",
            " 2.3832195 2.3832192 1.8994449 2.383219  2.3820028 2.3826146 1.8834766\n",
            " 2.368156  2.3741136 1.8851867 1.886591  2.0546322 1.88322   2.3776631\n",
            " 2.3832195 1.8832195 1.8832197 1.883225  1.88322   1.8832195 2.3832195\n",
            " 2.3832135 1.8832195 2.0077155 2.3827062 2.3749192 1.8832195 2.2991133\n",
            " 1.8832195 2.3832116 2.3830862 1.8832195 2.0223296 1.8832195 1.8832195\n",
            " 2.38316   2.383162  1.8832197 2.3832147 2.3832126 2.3832195 2.3832195\n",
            " 2.3816462 1.8832258 2.3726757 1.8832195 1.883235  1.8846605 2.3670046\n",
            " 1.8832202 1.8849962 1.8842046 1.8832195 2.383103  1.8832195 1.8832195\n",
            " 2.3782458 1.8832574 1.8832195 2.3832195 2.382491  2.2386756 1.9962137\n",
            " 1.9712478 2.381815 ]\n",
            "Step 300, Loss: [1.883589  1.8833103 1.8833096 2.3650885 2.35808   1.920706  2.383309\n",
            " 2.383215  2.3766437 1.8833096 1.8833096 1.8833194 2.0855103 1.8833096\n",
            " 1.883311  1.8833096 1.8833096 1.8833096 2.2569258 1.8833096 1.8833572\n",
            " 2.3024695 2.3770156 2.383304  2.3748343 2.3833094 1.8833096 1.8833096\n",
            " 1.8833096 1.8840147 2.3833094 2.3833094 2.111959  1.8833098 2.3833094\n",
            " 1.8833098 1.8833096 2.3795347 1.8833096 2.3833084 2.3475714 1.8838115\n",
            " 1.8833102 2.3825293 2.3827543 2.383165  1.8833812 1.8833746 2.3832908\n",
            " 1.883313  1.8833096 1.8835144 1.8833153 1.8833096 2.3833094 2.383309\n",
            " 1.8833117 2.382826  1.8835175 2.3829765 1.8833096 1.8833098 1.8833096\n",
            " 1.8833096 1.8833096 1.883354  2.3833084 1.8833096 2.296812  2.3829527\n",
            " 1.8833096 2.3833075 2.3631117 1.9000344 1.8834007 1.8833096 1.9172319\n",
            " 1.8833096 1.8833096 2.3833094 1.8836398 1.8833096 1.8833096 1.8833096\n",
            " 2.3833094 2.383288  1.8833098 2.3833094 1.89521   1.8833096 2.3833094\n",
            " 1.8833096 2.3832898 2.3831487 1.8833096 1.8833364 2.3833046 1.8876867\n",
            " 1.8899379 1.8833096 1.8833096 1.8833096 2.3833094 2.3833084 1.9588912\n",
            " 1.8833096 1.8833096 1.8833096 1.8833096 2.119604  1.8833096 2.3833094\n",
            " 2.3833094 1.8833096 1.8833096 2.3833094 1.8833098 2.3833094 2.377798\n",
            " 2.3829427 2.369042  1.8855704 2.3833094 1.8833096 1.8833103 2.3703032\n",
            " 1.88331   1.8833096]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4128 - loss: 12.7390\n",
            "Validation loss: 12.698058128356934, Validation accuracy: 0.4106000065803528\n",
            "Epoch 6/10\n",
            "Step 0, Loss: [2.3833375 2.3830185 2.3820524 1.8834103 1.8833416 2.3833413 2.2213888\n",
            " 1.8833416 1.8833416 2.3617182 1.9395784 1.8837289 2.3833413 2.383338\n",
            " 1.8833416 2.3833396 2.3830035 2.1423402 2.3833385 1.8833418 2.3832545\n",
            " 2.383305  1.8833416 1.8833416 2.1815357 2.0782557 1.8833947 2.38334\n",
            " 2.3832765 2.3652344 2.3833413 1.9147097 1.8833416 2.382999  2.3833413\n",
            " 2.3822956 1.8834696 2.0409007 2.0979662 2.3833413 1.8843272 2.383312\n",
            " 1.883342  1.8833416 1.8833416 1.8833416 1.8833475 2.3651152 1.883342\n",
            " 2.3833132 2.3831797 2.383329  2.1803694 2.3782167 1.8833416 2.3832626\n",
            " 2.3830905 2.3830466 2.0145435 2.383341  2.3833387 1.8833416 1.8833416\n",
            " 1.8963125 1.8833737 1.8833416 2.0774553 1.8836658 1.8833416 2.3833413\n",
            " 2.3833413 1.8845115 2.3831868 2.291065  2.3811007 2.3673687 1.8833416\n",
            " 1.8833416 2.2474575 2.3831654 2.3821583 2.382967  1.8834867 2.3556302\n",
            " 2.3310328 2.3655505 2.1443572 1.8833835 2.3753128 2.0304384 2.3550231\n",
            " 2.364274  2.3831604 1.8833416 2.3787267 1.8833416 2.3833413 2.2935286\n",
            " 2.244408  1.8833416 1.8833416 1.8833628 1.8833416 2.3833394 1.8833416\n",
            " 1.8833416 1.8833416 1.8833418 2.3700795 2.3833413 2.3833413 1.8833416\n",
            " 1.8833416 2.3829045 2.3833413 1.8833416 2.357985  1.8833416 2.3833413\n",
            " 2.3833413 1.8833416 1.8833416 2.3827085 2.383327  1.8833416 1.885818\n",
            " 2.3833413 2.3752337]\n",
            "Step 100, Loss: [1.8833625 1.8833625 2.3778238 1.9203758 1.8833625 1.888858  1.8833625\n",
            " 1.8833627 1.8833625 1.8833625 2.375283  2.3833618 2.3830452 1.8833803\n",
            " 2.3833625 1.8835595 2.3663635 2.3833625 2.3752012 1.8833625 1.8833625\n",
            " 1.8833797 1.8833625 2.3793187 1.8833625 2.3516157 2.3797312 1.8833625\n",
            " 1.8833625 2.3828592 1.8833625 1.8833822 2.3195186 1.8833625 1.8833625\n",
            " 2.3833625 1.8833815 2.3833618 1.8833625 1.8833675 1.8833625 2.3833625\n",
            " 1.8833625 1.8837181 1.8834093 1.8833625 1.9725217 2.368637  2.383288\n",
            " 1.8833625 1.8833637 1.8833625 1.8840582 1.8978925 1.8833625 2.370758\n",
            " 2.3833625 2.3833625 1.8853409 2.3786013 1.8833629 1.8833625 2.2878852\n",
            " 1.8833699 1.883363  2.3576243 1.8833625 2.3747497 1.8833625 2.3833625\n",
            " 1.8833828 2.3630238 1.8834981 2.3833623 1.883379  2.2806869 1.8833625\n",
            " 2.3833597 2.3833022 1.8833725 1.8833625 2.3833475 2.3803456 1.8833625\n",
            " 2.3833625 1.8841618 1.973882  1.8833625 1.8833625 1.8833625 2.3833625\n",
            " 1.8833791 1.883363  1.8833625 2.3833623 2.359377  1.8909297 1.8848332\n",
            " 2.3833623 2.383047  1.8903878 2.374906  2.3833625 2.3833625 2.3832786\n",
            " 1.8833625 1.8835006 1.8833625 2.3245811 2.3613765 2.3719053 2.383362\n",
            " 2.3833544 1.8839335 2.3833625 2.3797092 1.8833625 1.8833625 1.8834386\n",
            " 2.3833377 1.8833625 1.8835765 2.3833625 2.3833623 1.883363  1.93782\n",
            " 1.8840376 2.3833623]\n",
            "Step 200, Loss: [2.3833685 2.3621092 2.3802798 2.3833604 2.3833222 2.3785262 1.8845032\n",
            " 2.3832874 1.8833685 1.8833685 2.339396  2.3833685 1.8833685 1.8833685\n",
            " 2.3833685 1.8833685 1.8833685 1.8860581 1.8833685 1.8833685 2.3833675\n",
            " 1.8833687 2.3704128 1.8833685 1.8833685 2.383356  1.8833871 2.3097312\n",
            " 2.3502088 1.8833728 1.8833685 1.8833685 2.383336  1.9516671 2.3694453\n",
            " 2.383368  1.8833685 1.8833807 1.8833685 1.8834265 2.3040135 1.8846843\n",
            " 2.1269412 2.382641  1.8833685 1.8833828 2.383362  1.8833685 1.8833685\n",
            " 2.382248  1.8840209 2.369709  2.3819861 1.8833685 1.8833685 1.883369\n",
            " 2.3833604 2.3833685 1.8833688 2.3833334 1.8833685 1.8834167 2.3833327\n",
            " 2.3833675 2.383098  1.8833692 1.9799159 2.3833683 1.8833685 1.8833685\n",
            " 2.3653398 2.3617733 1.8833685 2.3816395 1.8834252 1.8833685 2.3793654\n",
            " 2.3833685 1.8833685 1.8833685 1.8833685 1.8833685 1.8833685 2.3651032\n",
            " 2.3831499 1.8833685 2.3833547 2.12146   2.3833685 2.3833685 2.383361\n",
            " 1.8833685 2.3812008 2.382936  1.8833714 1.88337   1.8833685 1.8833685\n",
            " 2.3770986 2.3833046 1.8833685 2.3793707 2.3833685 2.383366  1.8833685\n",
            " 1.8833888 2.3833685 2.3829062 1.8833685 1.8833685 1.8833685 2.382175\n",
            " 1.8833685 2.3811727 1.8868272 1.8833688 2.3833685 1.8833685 1.8833685\n",
            " 1.984977  1.8912674 2.3833685 2.3833675 2.3831253 2.3638744 2.3833299\n",
            " 2.296538  1.8938861]\n",
            "Step 300, Loss: [2.3822737 1.883229  1.8832427 2.379528  2.382834  2.3726995 2.383226\n",
            " 1.8842726 1.883229  1.883229  1.8832335 1.8841227 2.3258202 1.90556\n",
            " 2.275004  1.883229  1.883229  1.8832295 2.2762415 1.9346538 1.883229\n",
            " 1.9330282 2.3632598 1.9929086 2.3832288 2.383229  1.883322  1.883716\n",
            " 1.883229  2.3830848 2.383229  2.383229  2.3607368 1.883229  2.383229\n",
            " 1.8832293 1.883229  2.3794847 2.381339  2.3227365 2.3830972 1.883229\n",
            " 1.8832325 2.3820274 2.1230237 2.381513  2.3832285 1.8832295 1.8832719\n",
            " 1.8833289 1.883229  1.8832302 1.8843784 2.383229  2.383229  2.3828576\n",
            " 1.8832312 2.383229  1.883229  2.3831673 1.883337  1.883229  1.883229\n",
            " 1.883229  1.883229  1.8836538 1.883229  1.883229  2.3832283 2.3832288\n",
            " 1.8832302 1.8832293 2.383228  1.8832291 2.3825788 1.883229  1.9040208\n",
            " 1.883229  1.883229  2.3827314 1.8972305 1.883229  1.883229  1.883229\n",
            " 1.883229  2.3670578 1.8832297 2.383229  1.8832296 1.883229  2.383229\n",
            " 1.883229  2.3830757 1.883229  1.883229  1.8832293 1.8832879 2.3530908\n",
            " 1.9122471 1.883229  1.883229  1.883229  1.8832319 2.383229  2.2673929\n",
            " 1.8832294 2.383229  1.88323   1.883229  1.8832879 1.883229  2.3832288\n",
            " 1.88323   1.907733  1.883229  2.383229  1.883229  2.356959  2.371511\n",
            " 2.382957  1.8836719 2.2091289 1.8832549 1.883229  2.0285718 2.3832283\n",
            " 1.88461   1.8850017]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5284 - loss: 6.8660\n",
            "Validation loss: 6.998432159423828, Validation accuracy: 0.5245000123977661\n",
            "Epoch 7/10\n",
            "Step 0, Loss: [2.3832586 1.8832586 1.8832586 1.8832586 1.8832586 2.383203  2.3819141\n",
            " 1.8832586 1.8832586 2.3824055 1.8833523 1.8832586 2.3832586 2.3551607\n",
            " 1.8832586 2.3832586 1.8832586 2.3830533 2.382792  1.8832586 2.3827355\n",
            " 2.1128838 1.8832586 1.8832586 1.9763184 1.8937974 1.8832669 2.3830016\n",
            " 2.3832583 2.3795004 1.8832592 1.8832586 1.8832586 2.3821595 2.382896\n",
            " 2.3832586 1.8893723 2.3827512 1.898195  2.3689969 1.9250374 1.8837771\n",
            " 1.8832586 1.8832586 2.3832455 2.3832579 1.8832586 2.3832586 1.8832586\n",
            " 2.123691  2.3751588 2.3821154 1.8832588 2.3832586 1.8832586 2.3757324\n",
            " 2.375958  2.383227  1.8838954 2.3603904 1.8832586 1.8832586 1.8832586\n",
            " 1.8873019 1.8832586 1.8832586 2.383257  1.8832586 1.8832586 2.3832574\n",
            " 2.3818328 1.8835752 2.3832586 2.3517594 2.379108  1.88326   1.8832586\n",
            " 1.8832588 2.3574343 1.883471  2.3676386 2.3832533 1.8832595 2.0410914\n",
            " 2.361815  2.3829753 1.8881477 1.8832593 1.8836321 1.8833785 2.3709679\n",
            " 2.3827968 1.8833692 2.3257885 2.3788593 1.8832586 1.8832586 1.8832586\n",
            " 1.8832629 1.8834295 1.8832586 1.8836515 1.8832755 2.3832586 1.8832586\n",
            " 1.8832586 1.8832586 2.3832135 1.9031478 2.3832579 2.3832586 1.8832586\n",
            " 1.8832586 2.3820806 2.3831842 1.8832586 2.35851   1.8832586 1.8832587\n",
            " 1.8832586 1.883259  1.8832991 1.8832586 2.378757  1.8832586 1.8843977\n",
            " 2.3832586 2.383238 ]\n",
            "Step 100, Loss: [1.8833647 1.8833647 2.3833644 1.883368  1.8833647 1.9190004 1.8833647\n",
            " 1.8833647 1.8833647 1.8833647 1.8887627 2.3180077 2.3641322 1.8833652\n",
            " 2.3833647 2.0309548 1.8833647 2.2701793 1.8833647 1.987453  1.8833647\n",
            " 2.229272  1.8835815 1.8837428 1.8833647 2.366801  2.3832364 1.8833647\n",
            " 2.0435524 1.8833652 1.9573328 1.8833647 2.3833647 1.8833647 1.8833647\n",
            " 2.3833609 1.8833647 2.383043  1.9571123 1.8833647 2.3833165 2.3833647\n",
            " 1.8833647 1.8833647 1.8833647 1.8833647 1.8833648 2.3833559 1.8840795\n",
            " 1.8833647 1.8833647 1.8833647 1.8833647 1.8833647 1.8833663 2.3833647\n",
            " 2.3833647 2.3833647 1.8833659 2.3815813 2.3833647 1.8833647 1.8855687\n",
            " 1.8833647 1.8835577 2.3833141 1.8833647 2.3081465 1.8833647 2.3833647\n",
            " 1.8833647 2.383355  2.1051354 1.8833647 2.053399  2.3815312 2.38334\n",
            " 1.9649745 2.379916  2.3833094 1.8833652 2.3833647 2.3694563 2.3139615\n",
            " 2.3833647 1.8833647 1.8833683 1.8833647 1.8907745 1.8833647 2.3833647\n",
            " 2.383364  1.8833647 1.8833647 1.8833647 2.292735  1.8910662 1.8833957\n",
            " 2.3833647 2.381814  1.8838305 2.3833647 2.3833647 2.3833647 1.8966804\n",
            " 1.8833647 2.178511  1.8833647 2.3833647 2.271366  1.8833647 2.3556852\n",
            " 2.3748395 1.8833661 1.8833647 2.383317  1.8833647 1.8833654 1.8833647\n",
            " 1.9965656 1.8833647 1.8833648 2.3833647 2.3833642 2.2368379 2.3833647\n",
            " 1.88342   2.381249 ]\n",
            "Step 200, Loss: [1.8832543 1.8832543 2.383254  2.3730717 2.3818474 2.3817143 1.8845603\n",
            " 2.382528  1.8832543 1.8832586 1.8832543 2.3811896 1.8832543 1.8832543\n",
            " 2.3832517 1.8832543 1.8832543 1.8832543 1.8832543 1.8832543 2.383254\n",
            " 1.8832543 2.3616295 1.8832543 1.8832543 2.383254  1.9092083 1.9159181\n",
            " 2.3832164 1.8832543 2.383254  1.8832543 1.8832543 2.3072095 2.3692567\n",
            " 2.383254  1.8832568 1.8832543 1.8855906 1.8834965 2.3285623 2.380774\n",
            " 1.883924  2.3829305 1.8839234 1.8832618 2.3601522 1.8832543 1.8832543\n",
            " 2.3303785 2.383254  2.383142  1.8832543 1.8832619 1.8832543 1.8832543\n",
            " 2.3587284 2.3752851 1.8832543 2.3832488 1.8834405 1.8950962 1.8883927\n",
            " 2.383254  2.0860386 1.8832695 2.383254  2.383254  1.8832543 1.8832543\n",
            " 2.3668225 2.3411365 1.8833101 1.8843112 1.8832946 1.8832546 2.380327\n",
            " 2.383254  1.8832543 1.8832543 2.2970371 1.8832543 1.8832543 2.2863035\n",
            " 2.3831637 1.8832543 2.3085496 2.374475  2.383254  1.8832543 2.3788927\n",
            " 1.8832543 2.38325   2.3807635 1.8832543 1.8832543 1.8832543 1.8832543\n",
            " 2.3789973 2.380622  1.8832543 2.3801908 1.883342  2.3657455 1.8832562\n",
            " 2.3612022 2.3088012 2.3593364 1.8832543 1.8832543 1.8832543 2.3832536\n",
            " 1.8832543 1.885602  1.8832543 1.9018612 2.383254  1.8832543 1.8832543\n",
            " 1.8842483 1.8832641 1.8832543 2.361844  2.3615546 2.378355  2.2522717\n",
            " 2.2180207 1.8832741]\n",
            "Step 300, Loss: [1.8833609 1.8832622 1.8832622 2.3598242 2.3811398 1.8832622 2.3832622\n",
            " 1.8832622 1.8833181 1.8832932 1.8832622 1.8833406 1.8832622 1.8832622\n",
            " 2.3832622 1.8832622 1.8832622 1.8832641 1.9885616 1.8832622 2.3804426\n",
            " 1.8832622 2.3745394 2.3208656 2.3832617 2.3832455 1.8832622 1.883265\n",
            " 1.8832797 1.9548488 2.3832622 2.3701732 2.3594418 1.8832636 2.383235\n",
            " 1.8832681 1.8832622 2.383262  2.3620496 2.3809977 2.3521094 1.8832629\n",
            " 1.8833947 2.281281  1.8834629 2.0164633 2.383256  1.8856566 2.3693705\n",
            " 1.8832622 1.8832622 2.382946  1.8832622 2.3832622 2.3832622 2.373763\n",
            " 1.8854384 2.3832607 1.8832622 2.383261  1.8832622 1.8832622 1.8832622\n",
            " 1.8832622 1.8832622 2.0212083 1.8832622 1.8832622 1.888732  2.3812683\n",
            " 1.8832622 1.883263  2.3832622 1.8832622 1.8832633 1.8877149 1.8834053\n",
            " 1.8832622 1.8832622 2.3832622 2.3832622 1.8832622 1.8832622 1.8832622\n",
            " 1.8832622 2.383062  1.8852074 2.3832622 1.8832688 1.8832622 2.3832622\n",
            " 1.8832622 2.3823023 1.8832622 1.8832622 1.8832622 1.8832655 2.0212114\n",
            " 2.0128157 1.8832622 1.8832622 1.8832622 2.3295617 2.3511786 1.8833406\n",
            " 1.8832622 1.8832622 1.8832622 1.8832622 2.3832622 1.8832622 2.3832622\n",
            " 1.8832622 1.8832644 1.8832622 1.8832622 1.8832622 2.383261  2.3509269\n",
            " 2.379716  2.382482  1.8833466 2.3819017 1.8832622 2.3218026 2.3825142\n",
            " 1.8832744 1.9841865]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5737 - loss: 6.5602\n",
            "Validation loss: 6.676862716674805, Validation accuracy: 0.569100022315979\n",
            "Epoch 8/10\n",
            "Step 0, Loss: [2.3833306 1.8833385 1.8833385 1.8833385 1.8833385 2.364317  2.3792834\n",
            " 1.8833385 1.8833385 2.3833385 1.8833385 1.8833385 2.3833385 2.364074\n",
            " 1.8833385 2.3833385 1.8833385 2.3345742 2.3826911 1.8833387 2.3827047\n",
            " 2.0918362 1.8833385 1.8833385 1.8953274 2.3833225 1.8833416 1.9426163\n",
            " 2.3833385 2.3833385 1.883344  1.8833385 1.8833385 1.8833461 2.3829212\n",
            " 2.3833385 2.3833382 1.8833649 2.380653  2.3678923 1.884231  1.9019537\n",
            " 2.1637568 1.8833385 2.361381  2.3833117 1.8833385 2.3833385 1.8833385\n",
            " 1.8833411 2.3697715 2.383278  2.382569  1.8833392 1.8833385 2.382614\n",
            " 2.3752303 2.3804748 2.1045752 2.3833385 1.8833385 1.8996992 1.8833385\n",
            " 2.3689086 1.8833385 1.8833387 2.0730543 1.8833385 1.8833385 2.3833385\n",
            " 2.3832998 1.8833385 2.3833385 2.3833354 2.3829043 2.3669295 1.8833385\n",
            " 1.8834414 2.345768  2.3833385 2.3833268 2.383337  1.8833385 1.8834631\n",
            " 2.3730917 2.3815808 1.8858948 1.8833385 1.8867497 2.0450072 2.383337\n",
            " 2.3833349 1.8833385 1.8833385 2.3833365 1.8833385 1.8833385 2.383034\n",
            " 1.8833386 1.8833385 2.3833385 1.8903315 1.9805474 1.8833392 1.8833385\n",
            " 1.8833385 1.8833385 2.3832965 1.8833389 2.3833385 1.8855214 2.3769274\n",
            " 2.3830614 2.3833385 2.3833385 1.8833385 2.195633  2.3780632 1.8833385\n",
            " 2.3833385 1.8833387 1.8836625 1.8833386 2.3728085 1.8833385 1.8833393\n",
            " 2.3833385 2.3833349]\n",
            "Step 100, Loss: [1.8833842 1.8833842 2.3833842 1.883385  1.8833842 1.8833954 1.8833842\n",
            " 1.8909765 1.8833842 1.8833842 1.8834221 2.0562387 2.3821814 1.8833842\n",
            " 2.3833842 1.8838081 2.3833838 1.8833842 1.8833842 1.8834133 1.883395\n",
            " 1.9630194 1.8833842 1.8849175 1.8833842 2.3815444 2.3144743 1.8833842\n",
            " 1.8833842 1.8898218 1.8833842 1.8833846 2.3833842 1.8833842 1.8833842\n",
            " 1.8833842 1.8834746 2.383184  1.8833842 1.8833845 1.8833842 1.8833842\n",
            " 1.8833842 1.8833842 1.8833842 1.8833842 1.8833898 2.3833838 2.3833842\n",
            " 1.8833842 1.8833842 1.8833842 1.8833842 1.8833842 1.8833889 2.3833842\n",
            " 2.3833842 2.3833842 1.8833871 1.8834126 1.88339   1.8833842 1.8833847\n",
            " 1.8833842 1.8833846 2.3779316 1.8833842 2.273686  1.8833842 1.8833842\n",
            " 1.8833842 2.3396177 2.259171  2.3815742 2.0882003 1.883672  2.383384\n",
            " 1.8925697 2.3833842 2.3833783 2.03106   1.8833842 1.8850939 1.8833842\n",
            " 2.3790932 2.372668  2.0687737 1.8833842 1.8833842 1.8833842 2.3819814\n",
            " 2.3833842 1.883386  1.8833842 2.3833618 2.3819711 1.8834124 1.8979483\n",
            " 2.383366  2.2477248 2.3821852 2.3833766 1.8833842 2.3833842 2.3810382\n",
            " 1.8833842 2.37677   1.8833842 2.38338   2.3833714 2.3812141 2.3833842\n",
            " 2.3833838 1.8835297 1.8875878 2.383384  1.8833842 1.8834053 1.8833842\n",
            " 1.8833842 1.8833842 1.8833852 2.3833842 2.3833842 1.8833842 2.383375\n",
            " 1.8833866 2.3809237]\n",
            "Step 200, Loss: [1.8832946 1.9113837 2.3832927 2.383282  2.3832521 2.3631282 2.0194201\n",
            " 2.3827984 2.383294  1.8832946 1.8845057 1.8832946 1.8832946 1.8832946\n",
            " 2.3832946 1.8832946 1.8832946 1.8956659 1.8832946 1.8832946 2.3832946\n",
            " 1.8836195 2.3808556 1.8832946 1.8832946 1.8832946 2.3832946 2.0330634\n",
            " 2.3619018 2.122443  1.8832946 1.8832946 1.8832953 1.8845899 2.3832946\n",
            " 2.3764095 2.3527215 2.3823504 1.8832946 1.8849351 2.3812284 2.3832462\n",
            " 1.8912929 2.3718832 1.8832946 1.8836689 2.3832946 1.8832946 1.8832946\n",
            " 1.9816229 1.8832982 2.3544457 1.8832946 1.8832946 1.8832946 1.8832946\n",
            " 2.3649793 2.3832946 2.3792915 1.8832946 1.8832946 1.8875871 2.3832946\n",
            " 2.3832946 1.883373  1.8832974 1.9313812 2.3832946 1.8833886 1.8832946\n",
            " 2.3829122 2.3829303 1.883651  1.9341362 1.883295  1.8833584 2.3655496\n",
            " 2.3832946 1.8832946 1.8832946 1.8832946 1.8837665 1.8832946 2.095614\n",
            " 2.3832915 2.3832946 2.3832898 1.8848417 2.3832946 1.8837228 1.8832946\n",
            " 1.8832946 1.9890069 1.8854378 1.8832946 1.8832946 1.8832946 1.8832946\n",
            " 2.350329  2.3804226 1.8832946 2.3714354 1.8931844 2.3702283 1.8832946\n",
            " 1.8833977 2.3832946 2.3832774 1.8832946 1.8832946 1.8832949 2.3832946\n",
            " 1.8832946 2.3832905 2.3832946 1.8832946 2.381175  1.8832946 1.8832946\n",
            " 1.8832946 1.883307  1.8832946 2.3830628 2.3832915 2.3748126 2.376633\n",
            " 1.9718595 1.9653586]\n",
            "Step 300, Loss: [1.8836775 1.8833585 1.8832815 2.3828678 2.3832757 1.8832815 2.3832815\n",
            " 1.8837459 1.8832817 1.8859932 1.8832815 1.8845887 1.8832815 2.3832767\n",
            " 2.381608  1.8832815 1.8832815 1.8848122 2.282865  2.3825889 2.3832815\n",
            " 1.8846765 2.3826213 2.3778572 2.3832815 2.3832815 1.8832815 1.8832839\n",
            " 1.8832815 2.103575  2.3832815 2.3832815 1.8833077 2.3832815 1.8832815\n",
            " 1.8832815 1.8832815 2.383274  2.383164  2.3143544 2.0457797 1.8907232\n",
            " 1.8832841 2.3349288 1.9356446 2.2351508 1.8842266 1.8833573 2.3832815\n",
            " 1.8832922 1.8832815 1.8832815 1.8832815 1.8832815 2.3832815 2.3678753\n",
            " 1.8919499 2.3832815 1.8832815 2.382617  1.8832815 1.8833025 1.8832815\n",
            " 1.8832815 2.3832815 2.3831313 2.3832607 1.8832815 2.3829694 2.3374686\n",
            " 1.8832815 1.8832817 2.1320152 1.8832815 1.8891699 1.8833544 1.8832817\n",
            " 1.8832815 1.8832815 2.3708706 2.2957354 1.8832815 1.8832815 1.8832815\n",
            " 2.3832815 2.3832688 1.8836212 2.3832815 1.8833046 1.8832815 2.3764002\n",
            " 1.8832815 1.8834167 2.383246  1.8832815 1.8832815 2.372911  2.1571364\n",
            " 1.8833098 1.8832815 1.8832815 1.8832815 1.8834717 2.38328   2.026383\n",
            " 2.3832526 2.3832815 1.8832815 1.8832815 1.8881221 1.8832815 2.383281\n",
            " 1.8832815 1.8832855 1.8832815 2.377713  1.8832815 2.38328   2.3583703\n",
            " 2.3832815 1.887996  2.301447  1.8832836 1.8832815 1.8840017 2.3624105\n",
            " 1.8832815 2.347618 ]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5839 - loss: 5.9613\n",
            "Validation loss: 6.095373630523682, Validation accuracy: 0.5796999931335449\n",
            "Epoch 9/10\n",
            "Step 0, Loss: [2.3828208 1.8834655 1.883466  1.8834655 1.8834655 1.8835204 2.2116914\n",
            " 1.8834655 1.8834655 1.9570396 1.8834655 1.8834655 2.3834655 2.3591661\n",
            " 1.8834655 2.3834653 1.8834655 1.8848494 2.3830476 1.8834658 2.3834655\n",
            " 2.3834655 1.8834655 1.8834655 1.8834658 1.8910816 1.8835167 2.3833823\n",
            " 2.3834655 2.3834233 2.3834653 1.8834655 1.8834655 1.8882847 1.8938031\n",
            " 2.3834655 1.8834667 2.3834655 2.3834598 2.3765354 1.8834661 2.3427577\n",
            " 2.3785214 1.8834655 2.3746293 1.8834655 2.3834655 2.3834653 2.3298411\n",
            " 1.8834655 2.3834655 2.3825934 2.367642  1.8834687 1.8834655 2.3834612\n",
            " 2.2618742 2.3834653 1.883466  2.3834655 1.8834655 1.8834655 1.8834655\n",
            " 1.8835199 1.8834655 1.8834655 2.3834653 1.8834655 1.8834655 2.3795056\n",
            " 2.3834648 1.8834821 2.3651724 2.3834634 2.383447  1.8856546 1.8834655\n",
            " 1.8834655 2.3830967 2.3834646 2.3329415 2.3700547 1.8834655 1.8835837\n",
            " 2.3833518 1.8846087 2.3085861 1.883503  2.3833413 1.9957635 2.3834655\n",
            " 1.8841255 1.8834655 1.8834655 2.3823242 1.8834873 2.3834655 2.360149\n",
            " 1.8834655 2.383462  1.8834655 1.8834682 2.3834655 1.8834655 1.8836058\n",
            " 1.8834655 1.8834655 1.9121665 1.8834655 2.3834655 2.3834655 1.8834655\n",
            " 1.8834655 2.3834593 2.3834653 1.8834655 2.3412664 1.8834655 1.8834655\n",
            " 1.8834655 1.8834655 1.907269  1.8834655 2.3740711 1.8834655 1.8834655\n",
            " 2.3834655 2.382735 ]\n",
            "Step 100, Loss: [1.8833017 1.8833017 2.3833017 1.8833195 1.8833017 1.8833085 1.8833017\n",
            " 2.3832917 1.8833017 1.8833017 2.3708615 2.0182323 2.1862016 1.8833017\n",
            " 2.3833017 1.8875568 2.3833017 1.8833017 2.3833017 1.9153569 1.8833017\n",
            " 1.8833215 1.8833017 2.344756  1.8833017 2.3671074 1.8835802 1.8833017\n",
            " 1.8833017 1.8964995 1.8833017 1.8833017 2.3833017 1.8833017 1.8833017\n",
            " 2.3832972 2.3832655 1.8833086 1.8833017 1.8833017 1.8833017 2.3833017\n",
            " 1.8833017 1.8833017 1.8833048 1.8833017 1.8833017 2.3833017 1.8856952\n",
            " 1.8833017 1.8833017 1.8833017 1.8833017 1.8833017 2.3200903 2.3806949\n",
            " 2.3833017 2.3833017 1.896345  2.382081  2.3712971 1.8833017 1.883323\n",
            " 1.883302  1.8833017 2.3826282 1.8833017 1.9902906 1.8833017 2.3763962\n",
            " 1.8833017 2.3754063 2.0349774 1.8833017 1.8833079 2.1268117 1.8833017\n",
            " 1.883303  2.3833017 2.3832893 1.8833017 2.373623  2.3569021 1.8833017\n",
            " 2.3833013 2.3813884 1.883303  1.8833017 1.8833017 1.8833017 2.383103\n",
            " 2.3831124 1.8833017 1.8833017 2.3833013 1.8841414 2.0690818 2.3827457\n",
            " 2.367927  2.3616161 1.8833017 2.3827636 2.3833017 2.3833017 2.1102517\n",
            " 1.8833017 1.8994366 1.8833017 2.3833017 2.383294  2.3833017 2.3833017\n",
            " 2.381115  1.8833196 1.8833017 2.383301  1.8833017 1.8833017 1.8833017\n",
            " 1.8833017 1.8833017 1.8833017 2.3833017 2.3833017 1.8833017 2.3831806\n",
            " 1.8833017 2.3502684]\n",
            "Step 200, Loss: [1.8833187 2.3792074 2.3833187 2.3667612 2.3645675 2.3829327 1.8833187\n",
            " 1.8887477 1.8833187 1.8833187 1.8833187 1.8833187 1.8833187 1.8833187\n",
            " 1.8833189 1.8833187 1.8833187 1.8833187 1.8833187 1.8833187 2.3833046\n",
            " 1.9133896 1.8833282 1.8833187 1.8833187 1.8833187 1.9404936 2.3094442\n",
            " 1.9710233 1.8833187 2.1424792 1.8833187 2.3813472 1.9699651 2.383318\n",
            " 2.3771086 2.3833113 2.2899127 1.8833187 1.8834906 2.367791  2.382877\n",
            " 1.9283302 2.35424   1.8833187 2.1689537 1.8833189 1.8833187 1.8833187\n",
            " 2.110392  2.2461202 2.3833177 1.8833187 1.8833187 1.8833187 1.8833187\n",
            " 1.88963   2.3833187 1.8833187 2.3080945 1.8833187 1.8833187 1.8840771\n",
            " 2.3833187 1.8833524 1.8833194 2.3832836 2.3830752 1.8833187 1.8833187\n",
            " 2.369351  2.3833187 1.8833437 1.8833251 1.8833187 1.8833327 2.3832674\n",
            " 2.3833187 1.8833187 1.8833187 2.3829613 1.8833187 1.8833187 2.2840962\n",
            " 1.9773995 1.8833187 2.38302   1.884199  2.3833187 1.8833203 1.8833189\n",
            " 1.8833187 2.3746781 1.8833189 1.8833187 1.8833187 1.8833187 1.8833187\n",
            " 2.3832119 2.38303   1.8833187 2.383287  2.3728204 2.3828628 1.8833187\n",
            " 2.197102  1.9196154 2.3833182 1.8833187 1.8833187 1.8833187 2.3833187\n",
            " 1.8833187 1.9256294 2.380661  2.3769999 2.3833175 1.8833187 1.8833187\n",
            " 1.8833187 2.3833187 1.8833187 2.3832827 1.8836043 2.3833182 2.382581\n",
            " 1.8894777 2.382757 ]\n",
            "Step 300, Loss: [1.8832655 1.8832906 1.8832636 2.3832612 2.382924  1.8832631 2.3832622\n",
            " 2.2153406 1.8832631 1.8832631 1.8832631 2.382453  1.8833795 1.8832631\n",
            " 2.383263  1.8832631 1.8832631 1.8832631 1.9490476 1.8832631 2.383263\n",
            " 1.8843732 2.383152  2.3715463 2.3178897 2.3832488 1.8832631 1.8832633\n",
            " 2.2659426 1.8837931 1.8832631 1.8832631 1.9086407 1.8862796 2.383263\n",
            " 2.383263  1.8832631 2.3778493 1.8832633 2.1164722 2.0097032 1.8858926\n",
            " 1.8835771 1.9490521 1.8834414 2.3741486 2.1374497 1.8832631 1.8832636\n",
            " 1.8832859 1.8832631 1.8832631 1.8832631 1.8832631 2.383263  2.3832119\n",
            " 1.8832631 2.3770318 1.8916168 2.3782501 1.8832631 1.8832631 1.8832631\n",
            " 1.8832631 2.383263  1.8832631 2.383263  1.8832631 1.949915  2.3786414\n",
            " 1.8832631 1.8832645 1.9581877 1.8832631 1.8832631 1.8832631 1.8832874\n",
            " 1.8832631 1.8832631 2.383263  2.3832512 1.8832631 1.8832631 1.8832631\n",
            " 2.383263  2.3829207 1.88329   2.383263  1.883264  1.8832631 2.383263\n",
            " 1.8832631 2.3832054 1.8832631 2.383263  1.8832631 2.070199  1.8833592\n",
            " 2.3626618 1.8832631 1.8832631 1.8832631 1.8832631 2.0751987 2.044762\n",
            " 1.8833843 2.3830898 1.883265  1.8832631 1.923765  1.8832631 2.3832629\n",
            " 1.8833632 1.8832631 1.8832631 2.3830419 1.8832631 2.3832626 2.0245569\n",
            " 2.3825793 1.9287097 1.8937129 2.3208528 1.8832631 2.383263  2.3808413\n",
            " 1.8832631 1.8832631]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5977 - loss: 7.1903\n",
            "Validation loss: 7.271501541137695, Validation accuracy: 0.5964000225067139\n",
            "Epoch 10/10\n",
            "Step 0, Loss: [2.3833375 1.8833375 1.8833375 1.8833375 1.8833375 2.3833375 1.8901491\n",
            " 1.8833375 1.8833375 2.3833375 1.8833375 1.8833375 2.3833332 2.3380039\n",
            " 1.8833456 2.3833375 1.8833375 1.912776  2.069901  1.8833375 2.363814\n",
            " 1.8841977 1.8833375 1.8833375 1.8936249 1.8833389 2.0100627 1.8835384\n",
            " 2.3833375 2.3833375 1.8833375 1.8833375 1.8833375 1.9324572 1.8834121\n",
            " 2.367988  2.2452388 1.8833375 2.3606086 2.383337  1.8835294 2.3827488\n",
            " 1.8834616 1.8833375 2.2471285 1.8833375 2.3833375 2.3833375 1.8833387\n",
            " 1.8868861 2.3799047 2.335197  2.2523751 2.380761  1.8833375 2.1885219\n",
            " 1.8833534 2.3832994 2.3795505 2.3833303 1.8833375 1.8833375 1.8833375\n",
            " 2.3771548 1.8833375 1.8833375 1.8833417 1.8833375 1.8833375 2.3833375\n",
            " 2.3721023 1.8834921 2.383337  1.8833802 2.383275  2.3833365 1.8833375\n",
            " 1.8833375 2.3829408 1.893383  2.36341   2.382382  1.8833375 2.2201219\n",
            " 2.3832889 2.38247   1.8833375 2.3833191 2.3833375 1.8849033 2.382315\n",
            " 2.370048  1.8833375 1.8833375 2.3776205 1.8833375 2.3833375 2.3793335\n",
            " 1.8833375 2.3833365 1.8833375 1.8837292 1.8833375 1.8833375 1.8833375\n",
            " 1.8833375 2.1081345 1.8833375 1.883338  2.3833375 2.3833375 1.8833375\n",
            " 1.8833375 1.8833375 2.3833375 1.8833375 1.8833375 1.8833375 1.8833375\n",
            " 1.8833375 1.8833375 2.2868938 2.383337  2.2082105 1.8833375 1.8877711\n",
            " 2.383161  2.3803759]\n",
            "Step 100, Loss: [1.8833654 1.8833654 2.3833654 1.8833654 1.8833654 1.8833659 1.8833654\n",
            " 1.8833654 1.8833654 1.8833654 1.8833845 2.339573  2.381779  1.8833654\n",
            " 2.3833117 2.290187  1.8834066 1.8833654 1.8833656 1.8833714 1.8833654\n",
            " 2.3791976 1.8833654 1.8869213 1.8833654 2.3704324 2.3833654 1.8833654\n",
            " 1.8833654 1.8834276 1.8833654 1.8833654 2.3833654 1.8833656 1.8833654\n",
            " 2.3833568 1.9461398 2.0128555 1.8833654 1.8833656 1.8833654 2.3833652\n",
            " 1.8833654 1.8833654 1.8833654 1.8833654 1.8833654 2.3833654 1.8833656\n",
            " 1.8833654 1.8833654 1.8833654 2.3827915 1.8833654 1.8833654 2.383356\n",
            " 2.3833654 2.3833654 1.8836402 1.8833656 1.895259  1.8833654 1.8833654\n",
            " 1.8833654 1.8834122 2.3833654 2.3833652 2.3833654 1.8833654 2.381985\n",
            " 1.8833654 2.3717427 2.0020318 1.8913474 1.9009166 2.1788955 1.8833654\n",
            " 1.8833835 2.3833654 1.8833661 1.8833654 1.8833654 1.887239  1.8833654\n",
            " 2.3833652 1.8835965 1.9113126 1.8833654 1.8833654 1.8833654 2.3550751\n",
            " 1.8833656 1.8833654 1.8833654 2.3833654 2.3833122 2.3831975 2.3648465\n",
            " 2.3833227 2.3826032 1.8833654 1.8833654 1.8833654 1.8833654 2.3826916\n",
            " 1.8833654 1.8833654 1.8833654 2.3833654 2.3833542 2.3833632 2.3833654\n",
            " 1.8857198 1.8833658 1.8833654 2.3833654 1.8833654 1.8833654 1.8833654\n",
            " 2.3833654 1.8833654 1.9581425 2.3833654 2.3833654 1.8833654 1.9030418\n",
            " 1.8833665 2.3558202]\n",
            "Step 200, Loss: [1.8833528 1.8833528 2.3805408 2.3833501 2.383349  2.3833528 1.8833528\n",
            " 2.3833518 1.8833528 2.324336  1.8833528 1.8833528 1.8833528 1.8833528\n",
            " 2.3833528 1.8833528 1.8833528 1.8833528 1.8833528 2.3833528 2.3833528\n",
            " 1.8833528 2.38307   2.3820157 1.8833528 1.8833528 1.8833528 2.3797736\n",
            " 1.8836424 1.8833528 2.3833525 1.8833528 1.9075215 1.8851588 2.3833528\n",
            " 2.3643055 1.9381552 1.8833528 1.8833528 1.883354  2.3833513 1.8836162\n",
            " 1.8856764 2.3832755 1.8833528 1.8833528 1.8833864 2.3833528 1.8833528\n",
            " 1.8865914 2.3796444 2.3802884 1.8833528 1.8833528 1.8833528 1.8833528\n",
            " 1.8834682 2.3833518 1.8833528 1.8833528 1.9739265 1.8834381 2.3602939\n",
            " 2.3833528 1.8833613 1.8833528 2.3833528 2.383352  1.8833528 1.8833528\n",
            " 2.383348  2.3756857 1.8833528 2.3833528 2.383346  1.8833528 2.3808122\n",
            " 2.3833528 1.8833528 1.8833528 1.8833528 1.8833528 1.8833528 2.383311\n",
            " 2.3833249 2.3833528 2.3833327 2.380386  2.3833528 1.8833528 2.3833528\n",
            " 1.8833528 2.3761725 1.8875947 1.8833528 1.8833528 1.8833528 1.8833528\n",
            " 2.3814645 2.2736275 1.8833528 2.3833528 1.8834376 2.3833528 1.8833528\n",
            " 2.3833523 2.3833094 2.3832822 1.8833528 1.8833528 1.8833528 2.3833528\n",
            " 1.8833528 2.1363082 1.883353  1.8833528 2.3831625 1.8833528 1.8833528\n",
            " 1.9075321 1.8833532 1.8833528 2.3771625 1.8923676 2.3417826 2.3802862\n",
            " 1.8869514 2.3831358]\n",
            "Step 300, Loss: [1.8832388 1.8832233 1.8832233 2.3551366 2.3832197 1.8832233 2.3832233\n",
            " 2.3831658 1.8832233 1.8832239 1.8832233 1.8833524 1.8832233 1.8832233\n",
            " 2.3832233 1.8832233 1.8832233 1.8832233 1.8832316 1.8832233 2.125845\n",
            " 1.8832233 2.370681  1.8832967 2.352295  2.3832233 1.8832233 1.8832233\n",
            " 1.8832233 2.3832233 2.3832233 1.8860104 2.3689222 2.3639493 2.383223\n",
            " 1.8832233 1.8832233 2.0760303 2.1886954 2.3328671 2.285815  1.8832505\n",
            " 1.8832235 1.8832414 2.383223  1.8833857 2.38322   1.8832233 1.8918127\n",
            " 2.016737  2.0639994 1.8832233 1.8832233 1.8832263 2.3832233 2.3831856\n",
            " 1.8834603 2.3832233 1.8832233 2.3801064 1.8832233 2.381653  1.8832233\n",
            " 1.8832233 2.383217  2.2854428 1.8832233 1.8832233 1.883327  2.3777256\n",
            " 1.8832235 1.8832233 2.0580816 1.8832233 1.8832233 1.8832233 1.8998752\n",
            " 1.8832233 1.8832233 2.383223  2.3831053 1.8832233 1.8832233 1.8832233\n",
            " 2.3832233 2.3832233 1.8833076 2.3832233 1.8832252 1.8832233 2.3832233\n",
            " 1.8832233 2.3817992 1.8832233 1.8832233 1.8832233 2.1042767 1.8861227\n",
            " 1.893384  1.8832233 1.8832233 1.8832233 1.8832233 2.38322   1.8832452\n",
            " 1.8832233 1.8838482 1.8832233 1.8832233 1.8832242 1.8832233 2.383223\n",
            " 1.8832233 1.8832233 1.8832233 1.9185603 2.3831868 1.8832233 2.3654637\n",
            " 2.3805017 1.8860106 2.0081553 2.3832211 1.8832233 1.8832233 2.379228\n",
            " 1.8832233 2.3783188]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5962 - loss: 7.0091\n",
            "Validation loss: 7.069579601287842, Validation accuracy: 0.5960000157356262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = student_model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "feE6sBD34ZPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6030b1d0-73a9-4d28-a627-8c870fd557e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 6.9982\n",
            "Test accuracy: 0.5960000157356262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for step in range(len(x_train) // batch_size):\n",
        "        x_batch = x_train[step * batch_size:(step + 1) * batch_size]\n",
        "        y_batch = y_train[step * batch_size:(step + 1) * batch_size]\n",
        "        soft_batch = soft_targets[step * batch_size:(step + 1) * batch_size]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = student_model(x_batch, training=True)\n",
        "            loss_value = distillation_loss(y_batch, logits, soft_batch, alpha=0.3, temperature=5.0)\n",
        "\n",
        "\n",
        "        grads = tape.gradient(loss_value, student_model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss_value.numpy()}\")\n",
        "\n",
        "\n",
        "    val_loss, val_acc = student_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1-OaIYP7mMY",
        "outputId": "12c1a308-5d59-4754-bb38-a93b9cef750d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Step 0, Loss: [2.4138675 1.7138866 1.7138866 1.7138866 2.4138865 2.4138854 1.7139028\n",
            " 1.7138866 1.7138866 2.2011294 1.7138866 1.7138866 2.4138865 2.3866625\n",
            " 1.7138866 2.4138865 1.7138866 2.3691106 2.4138865 1.7138885 2.4070983\n",
            " 1.71405   1.7138866 1.7138866 2.4138863 2.4046493 1.7142572 1.7929599\n",
            " 2.4138863 2.4138808 1.7138866 1.7138866 1.7138866 1.724389  2.4138865\n",
            " 2.4134982 1.8030126 1.7138867 2.4138865 2.4138854 2.3028028 1.7316555\n",
            " 1.7139567 1.7138866 2.4138865 1.7138866 2.0333228 2.4138865 1.7138866\n",
            " 1.7138866 2.4138832 2.4137022 2.3886156 2.4138858 1.7138866 2.4087446\n",
            " 2.4136252 1.8053284 2.4138863 2.4138865 1.7138866 1.7284557 1.7138866\n",
            " 2.3843122 1.7138866 2.4138865 2.358086  1.7138866 1.7138866 2.4138865\n",
            " 2.4138694 1.71389   2.4138865 1.7138869 2.3967242 1.7138866 1.7138866\n",
            " 1.7138866 2.413886  2.413611  1.8719975 2.4130788 1.7138866 2.4122095\n",
            " 2.413857  2.4138865 1.7138871 1.7138866 1.7138866 2.3731906 2.413577\n",
            " 2.4138858 1.7138866 2.3066187 2.3934293 1.7139019 1.7138866 1.7138882\n",
            " 1.7138866 1.7138866 1.7138866 1.7612405 1.7138866 1.714142  1.7138866\n",
            " 1.7138866 1.7138866 1.7139434 1.7138866 1.7138869 2.4138865 1.7138866\n",
            " 1.7138866 2.1436985 2.4138865 1.7138866 2.4138865 1.7138866 1.7139506\n",
            " 1.7138866 1.7138866 2.4138865 1.7138866 2.387045  1.7138866 1.7138866\n",
            " 2.4138842 2.413886 ]\n",
            "Step 100, Loss: [1.7138977 1.7138977 2.4138968 1.7138977 1.7138977 1.7138982 1.7138977\n",
            " 1.7138977 1.7138977 1.7138977 2.407542  2.396091  2.3784673 1.7138977\n",
            " 1.7139058 1.7138991 2.4077458 1.7138977 2.4138975 2.4136288 1.7138977\n",
            " 1.7223079 1.7138977 1.7139242 1.7138977 2.4138975 1.7228057 2.4138975\n",
            " 1.7138977 1.714016  1.7138977 1.7138977 2.4138975 1.7138977 1.7138977\n",
            " 2.4138975 1.7147396 2.4137118 1.7138977 1.7138977 2.3783858 1.7138977\n",
            " 1.7138977 1.7138977 1.7138996 1.7138977 1.7138977 2.4138975 1.7139926\n",
            " 1.7138977 1.7138977 1.7138977 1.7138977 1.7138977 1.7156668 2.3930469\n",
            " 1.9808252 2.4138975 1.7138977 1.7147622 1.7149048 1.7138977 1.7138977\n",
            " 1.7138977 1.7138977 2.413749  1.7138977 2.4138827 1.7138977 2.413896\n",
            " 1.7138977 2.4138968 1.7140181 2.413875  1.8003762 2.3993216 1.7138977\n",
            " 2.4138975 2.4138975 2.4097219 2.413779  2.4138975 2.3962924 1.7138977\n",
            " 2.4138525 1.7138977 1.714122  1.7138977 1.7138977 1.7138977 2.413881\n",
            " 1.7138977 1.7138977 1.7138977 2.4138975 1.7138977 1.7138999 1.7138977\n",
            " 2.412694  2.4119127 1.7138977 1.7828562 2.0561104 2.4138873 2.1236024\n",
            " 1.7138977 1.7139254 1.7138977 2.4138975 2.4138677 2.3931353 2.4138975\n",
            " 1.7140107 1.7138977 1.7138977 2.4138975 1.7138977 1.7138977 1.7138977\n",
            " 1.7138977 1.7138977 1.7138977 1.7139156 1.7138977 2.4016073 2.412977\n",
            " 1.7138977 2.3122466]\n",
            "Step 200, Loss: [1.7139006 1.7139006 2.4139006 2.0871692 2.4138958 2.4139006 2.4139006\n",
            " 2.4139006 1.7139006 1.7139006 1.7139006 1.7139006 1.7139006 1.7139006\n",
            " 1.7139521 1.7139006 1.7139006 2.4135072 1.7139006 1.7139006 2.4139006\n",
            " 1.7139006 1.7139032 2.1422763 1.7139006 1.7139006 2.4139006 2.413761\n",
            " 2.4138732 1.7139006 2.4139    1.7139006 1.7139006 1.7139106 2.4139006\n",
            " 2.413836  1.7139127 1.7139006 1.7139006 1.7139006 2.4133248 2.4117236\n",
            " 1.7294741 2.4136622 1.7139006 1.725255  2.4139006 1.7139006 1.7139006\n",
            " 1.713901  2.4139006 2.4100916 1.7139006 1.7139006 1.7139006 1.7139006\n",
            " 1.9977415 2.4139006 2.4137654 1.7139006 1.713901  1.7144771 2.4139001\n",
            " 2.4139006 1.7139006 1.7139006 2.4093676 2.4139001 1.7139006 1.7139006\n",
            " 2.387617  2.4112709 1.7139034 1.7149787 2.4118798 1.7139006 2.4138381\n",
            " 2.4139006 1.7139006 1.7139006 1.7139006 2.2424047 1.7139006 2.4139006\n",
            " 1.7163396 1.7139006 2.4139006 1.7356479 2.4139006 2.403443  1.8635848\n",
            " 1.7139006 2.4139006 1.7156994 1.7139008 1.7139006 1.7139006 1.7139006\n",
            " 2.4138517 1.7936621 1.7139006 2.3899407 1.7139032 2.4139006 1.7139006\n",
            " 2.2831109 1.7139015 2.4138722 1.7139006 1.7139006 1.7139006 2.4139006\n",
            " 1.7139006 1.7427311 2.4138367 2.4126377 2.4139006 1.7139006 1.7139006\n",
            " 1.7139006 2.3093114 1.7139006 2.4138393 2.388066  2.4139006 1.9555435\n",
            " 2.4138982 2.4139006]\n",
            "Step 300, Loss: [1.7138761 1.7138745 1.7138745 2.4019394 2.413711  1.7138745 2.4138744\n",
            " 1.7138745 2.4090624 1.7138745 1.7138745 1.8307922 1.7138745 1.8834934\n",
            " 2.4138684 1.7138745 1.7138745 1.7138745 1.713875  2.4138722 1.7138745\n",
            " 1.7140687 2.4061399 2.3991704 2.4138744 2.3255098 1.7138745 2.2116904\n",
            " 1.8053923 2.4132366 2.4138744 2.4138744 1.7138749 2.4138744 2.4138722\n",
            " 1.7138745 1.7138745 2.4130797 1.714925  2.396964  2.1749535 1.8003415\n",
            " 1.7138745 1.7138745 1.7138959 2.1914473 2.4134018 1.7138745 2.4138744\n",
            " 2.3951082 1.7138745 1.7138745 1.7658422 2.4138744 2.4138744 2.3909118\n",
            " 1.7138745 2.4138744 1.7138945 2.4132278 1.7138745 1.7138745 1.7138745\n",
            " 1.7138745 1.7138745 1.7138745 1.7138745 1.7138745 2.4138744 2.4137106\n",
            " 1.7138745 1.7138746 2.3880172 1.7138745 2.4138744 1.7138745 1.7138745\n",
            " 1.7138745 1.7138745 2.4138744 1.7138859 1.7138745 1.7138745 1.7138745\n",
            " 1.7138745 2.4138744 1.7138745 2.4138744 1.7138782 1.7138745 2.4138744\n",
            " 2.4018803 1.7138745 1.7138745 1.7138745 1.7138745 2.4138515 1.7227044\n",
            " 2.4137626 1.7138745 1.7138745 2.3789916 1.7138745 2.3794713 2.4040084\n",
            " 2.4138515 1.7138745 1.7138745 1.7138745 1.7173674 1.7138745 2.4138699\n",
            " 2.3623495 1.7138745 1.7138745 2.3945253 2.4128518 2.4135723 2.4138098\n",
            " 2.4138744 1.7138745 2.413666  1.7168247 1.7138745 2.4130766 1.827862\n",
            " 1.7138746 2.4093568]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5802 - loss: 10.1969\n",
            "Validation loss: 10.329967498779297, Validation accuracy: 0.5788000226020813\n",
            "Epoch 2/5\n",
            "Step 0, Loss: [2.41386   1.7138991 1.7138991 1.7138991 1.7138991 2.413899  1.7138991\n",
            " 1.7138991 1.7138991 2.3719816 1.7138991 1.7138991 2.4128084 2.4138722\n",
            " 1.7138991 2.413899  1.7138991 2.4025629 2.413899  1.7138991 2.3940163\n",
            " 1.7139857 1.7138991 1.7138991 2.413313  1.7138991 2.4133682 1.7146325\n",
            " 2.413899  2.413899  1.7138991 1.7138991 1.7138991 2.406198  2.413899\n",
            " 2.3845994 1.7139341 1.7138991 2.4034638 2.4137225 1.7149733 1.7138991\n",
            " 1.7138991 1.7138991 1.7138991 2.413899  1.7138991 2.4138975 1.7138991\n",
            " 2.4138863 2.408402  2.413899  2.4086752 2.413899  1.7138991 2.413676\n",
            " 2.4138982 2.2522671 2.413899  2.413899  1.7138991 2.4138596 1.7138991\n",
            " 1.7142116 1.7138991 1.7138991 2.4137073 1.7138991 1.7138991 1.7138991\n",
            " 2.4137902 1.7139837 1.7199048 1.7138991 2.4006567 2.3811078 1.7138991\n",
            " 1.7138991 2.4137106 2.4138002 1.7275515 2.412467  1.7138991 1.80412\n",
            " 2.4039888 2.389607  1.7142601 1.7138991 1.7138991 2.4138148 2.3935485\n",
            " 2.413899  1.7138991 1.7138991 2.0836477 1.7138991 2.413899  1.7485629\n",
            " 1.7138994 2.413899  1.7138991 1.7139008 1.7138991 1.7138991 1.7138991\n",
            " 1.7138991 1.7138991 1.7138993 1.7138991 2.1658497 2.413899  1.7138991\n",
            " 1.7138991 2.4137447 2.413899  2.413899  2.3376882 1.7138991 2.4132829\n",
            " 1.7138991 1.7138991 1.7141957 1.7138991 2.3920646 1.7138991 1.7138991\n",
            " 2.413899  1.7138991]\n",
            "Step 100, Loss: [1.7138784 1.713887  2.4138782 1.71399   1.7138784 1.7138784 1.7138784\n",
            " 1.8708131 1.7138784 1.7138784 1.7138784 1.7678268 2.4092119 1.7138784\n",
            " 2.4138718 2.139908  1.7138784 1.7138784 1.8204284 1.7138784 1.714536\n",
            " 2.3709505 1.7138784 2.4009037 1.7138784 2.4138782 2.413871  1.7138784\n",
            " 2.4138782 1.7732556 1.7138784 1.7138784 2.4138782 1.7138784 1.7138784\n",
            " 2.4138782 1.912085  2.4074414 1.7138784 1.7138784 1.7138784 1.7138784\n",
            " 1.7138784 1.7138784 1.7138784 1.7138784 1.7138784 2.4138763 1.7138784\n",
            " 1.7138784 1.7138784 1.7138784 1.7222347 2.4134076 1.7138784 2.366225\n",
            " 2.4138782 2.4138782 1.7138784 1.7138784 2.3853822 1.7138784 1.7145321\n",
            " 1.7139251 1.7138798 2.4138763 1.7138784 2.0541801 1.7138784 2.4138162\n",
            " 1.7138784 1.7138791 1.7138789 1.7138784 2.4077806 1.7138858 1.7138784\n",
            " 1.7139599 2.4138782 1.7142241 1.7138784 1.7138793 1.7141185 1.7138784\n",
            " 2.4138782 1.7167845 1.713901  1.7138784 1.7138784 1.7138784 2.4132504\n",
            " 1.7139995 1.7138784 2.4138749 1.7138784 1.7138784 1.7138784 2.233433\n",
            " 2.413877  2.4138145 1.7138784 2.4138024 1.7138991 1.7138784 2.4138777\n",
            " 1.7138784 1.7161553 1.7138784 2.4138782 2.4084363 2.3876057 2.413878\n",
            " 2.3954642 1.7138784 1.7138784 2.4138782 1.7138784 1.7138784 1.7138784\n",
            " 2.4138782 1.7138784 1.7138784 2.4138782 1.7138784 1.7138784 1.714191\n",
            " 1.7138829 2.385036 ]\n",
            "Step 200, Loss: [1.713897  1.713897  2.413897  2.413897  2.413897  2.413894  2.413843\n",
            " 1.80368   1.713897  1.713897  1.713897  1.713897  1.713897  1.713897\n",
            " 2.413883  1.713897  1.713897  1.7138996 1.713897  2.413897  2.413897\n",
            " 1.713897  1.713897  1.713897  1.713897  2.413897  2.4138575 2.4132347\n",
            " 1.7138972 1.713897  2.4138966 1.713897  1.7221329 1.7139058 2.413897\n",
            " 2.413887  1.713897  2.413897  1.713897  1.7140732 2.4138958 1.7198622\n",
            " 1.713947  2.4084463 1.713897  2.413897  1.7252176 1.713897  1.713897\n",
            " 2.4086633 2.41328   2.413897  1.713897  2.4138968 1.713897  1.713897\n",
            " 2.4138925 2.413897  1.7142909 1.713897  2.4107394 1.7147503 2.4138794\n",
            " 2.413897  1.713901  1.713897  2.4138906 2.413897  1.713897  1.713897\n",
            " 2.4138968 1.715344  1.713897  2.0743663 1.7326293 1.713897  2.413897\n",
            " 2.413897  1.713897  1.713897  1.713897  1.713897  1.713897  2.4133594\n",
            " 1.7299826 2.4138954 2.413897  1.7139728 2.413897  2.3632205 1.713897\n",
            " 1.713897  2.4088547 1.7138984 1.7138982 1.713897  1.713897  1.713897\n",
            " 2.413897  2.41356   1.713897  2.4138825 1.713897  2.413897  1.713897\n",
            " 1.7139034 1.7234037 2.4138966 1.713897  1.713897  1.713897  2.413897\n",
            " 1.713897  1.7177656 2.413897  1.713897  2.413866  1.713897  1.713897\n",
            " 1.713897  1.7139993 1.713897  2.4129221 1.758573  1.7138977 1.713897\n",
            " 2.3644462 2.413887 ]\n",
            "Step 300, Loss: [1.7138923 1.7138923 1.7138923 2.4134655 2.4131618 1.7138923 2.4138923\n",
            " 1.7247926 1.7138923 1.7138923 1.7138923 1.8892237 1.7138923 1.7138923\n",
            " 1.7138923 1.7138923 1.7138923 1.7138923 1.7143728 1.7138923 1.7138923\n",
            " 1.7138923 2.413889  1.7138925 2.402995  2.4138923 1.7138923 1.7139064\n",
            " 1.7138925 2.4138792 2.4138923 2.4138923 2.4138887 2.4138923 2.4138923\n",
            " 1.7138923 1.7138923 2.4138894 1.7138923 2.3664994 1.7406552 2.411883\n",
            " 1.7138923 1.7138923 1.7138923 2.0485787 2.4138892 1.7138923 2.4138265\n",
            " 1.7138923 1.7138923 1.7138923 1.7138923 1.7138923 2.4138923 2.4039035\n",
            " 1.7138923 2.413892  1.7147243 2.4138923 1.713894  1.7138923 1.7138923\n",
            " 1.7138923 1.7138923 1.9455435 1.7138923 1.7138923 1.7182546 2.4137747\n",
            " 1.7138923 1.7138923 1.7391844 2.412944  1.7138923 1.7138923 1.713906\n",
            " 1.7138923 1.7138923 2.41389   2.2215714 1.7138923 1.7138923 1.7138923\n",
            " 1.7138923 2.4138923 1.7138923 2.4138923 1.7140639 1.7138923 2.4138923\n",
            " 1.7138923 2.4138923 1.7138923 1.7138923 1.7138923 2.412554  2.4138472\n",
            " 1.7813913 1.7138923 1.7138923 1.7138925 1.7138925 1.7140604 2.1021943\n",
            " 1.7138923 2.4138923 1.7138923 1.7138923 2.4138684 1.7138923 2.4138923\n",
            " 1.7138923 1.7139071 1.7138923 2.4138923 1.8158249 2.4138908 2.4138875\n",
            " 2.4138923 2.410627  2.4134505 1.7138923 1.7138929 2.4039407 2.3736262\n",
            " 1.7138923 1.7138925]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5912 - loss: 8.2533\n",
            "Validation loss: 8.42670726776123, Validation accuracy: 0.5831000208854675\n",
            "Epoch 3/5\n",
            "Step 0, Loss: [2.4139023 1.7139025 1.7139025 1.7139026 1.7139025 2.4139023 1.7139025\n",
            " 1.7139025 1.7139025 2.3753924 1.7139025 1.7139025 2.4139023 2.4137554\n",
            " 1.7139025 2.4139023 1.7139025 1.7139051 2.413199  1.7139025 2.39598\n",
            " 1.879313  1.7139025 1.7139025 1.7139109 1.714053  1.7142227 2.413849\n",
            " 2.4139023 2.3744264 1.7139025 1.7139025 1.7139025 1.7139025 1.7139025\n",
            " 2.4139023 1.7139028 2.3906446 2.41369   2.4124813 1.7140684 1.7139025\n",
            " 1.7139087 1.7139025 1.7140961 2.4139023 1.7139025 2.4139023 1.7139025\n",
            " 1.7139027 2.4139023 1.7156707 2.4097562 1.7139896 1.7139025 2.412737\n",
            " 2.3625755 2.4139023 2.3986096 2.4138947 1.7139025 1.7139025 1.7139025\n",
            " 1.7139072 1.7139025 1.7139025 1.7139025 1.7139025 1.7139025 1.7139025\n",
            " 2.403336  2.413875  2.2559805 1.7139031 2.4138882 2.4108477 1.7139025\n",
            " 1.7139025 2.405881  2.4139023 1.7230221 2.4139023 1.7139025 1.7139072\n",
            " 2.413845  2.4139023 1.7139025 1.7139025 1.7139025 2.3920827 2.394106\n",
            " 2.4139023 1.7139218 1.7139025 2.403627  1.7139025 1.7139025 2.4138901\n",
            " 1.7139025 2.4139018 2.4139023 1.7139025 1.7139025 1.7139025 1.7139025\n",
            " 1.7139025 2.2909088 1.8067793 1.7151016 1.7139025 2.4024825 2.4139023\n",
            " 1.7139025 2.4017324 2.4139023 1.7139025 2.3924398 1.7139025 1.7139025\n",
            " 1.7139025 1.7139025 1.7139025 2.4139023 2.4138975 1.7139025 1.7139025\n",
            " 2.4139023 1.7150599]\n",
            "Step 100, Loss: [1.7139103 1.7139103 2.4139104 1.714067  1.7139103 1.7139103 1.7139103\n",
            " 1.7139274 1.7139103 1.7139103 2.4137235 1.717229  2.4055443 1.7139114\n",
            " 2.4139104 1.7139999 2.4139104 1.7394382 1.7139103 1.7139103 2.4104881\n",
            " 1.879517  1.7139103 2.4087522 1.7139103 2.41391   2.4139104 2.2761517\n",
            " 1.7139103 1.7139103 2.4139104 2.41265   2.4139104 1.7139103 1.7139103\n",
            " 1.7139103 1.7139518 1.7150456 1.7139103 1.7139103 2.4139104 1.7139103\n",
            " 1.7139103 1.7139103 1.7139112 1.7139103 1.7139103 2.41391   1.713911\n",
            " 1.7139103 1.7139103 1.7139103 1.7139103 1.713917  2.4105158 2.4138937\n",
            " 1.7139103 2.4139104 1.7139103 1.7139103 1.7139115 1.7139103 1.7139103\n",
            " 1.7139103 1.7139103 2.3600616 1.7139103 2.385676  1.7139103 2.3381522\n",
            " 1.7139535 2.4123015 1.7156608 2.4139075 2.368359  2.4138823 1.7139103\n",
            " 1.7139103 2.4139104 2.4139104 1.7139117 2.4139092 1.7139286 1.7139103\n",
            " 2.3976357 2.4139104 1.713924  1.7139103 1.7139103 1.7139103 2.4139104\n",
            " 2.4139104 1.7139103 1.7139103 1.7139103 1.7139103 1.7139108 1.7139708\n",
            " 2.4139037 2.4138846 1.7139103 1.7139105 2.4139104 1.7139103 1.7140044\n",
            " 1.7139103 1.7142398 1.7139103 2.413909  2.413789  2.4139087 1.7139103\n",
            " 1.7161268 1.7139105 1.7139103 2.4139104 1.7139103 1.7139103 1.7139103\n",
            " 1.7139107 1.7139103 1.7139581 1.7139105 2.4079823 1.7139103 2.3869393\n",
            " 1.7139103 2.3861399]\n",
            "Step 200, Loss: [1.7138771 1.7138771 2.3965852 2.413877  2.4138741 2.4138684 2.413876\n",
            " 2.2990746 1.7138771 1.7138771 1.7138789 1.7138771 1.7138771 1.7138771\n",
            " 2.413877  1.7138771 1.7138771 1.7138771 1.7138771 1.7138771 2.413877\n",
            " 1.7138771 1.7138802 1.7138771 1.7138771 1.7138771 2.4138713 2.413877\n",
            " 1.714175  1.7138771 2.413877  1.7138771 1.7138771 1.7138774 2.413877\n",
            " 2.4112558 1.7138771 1.7138785 1.7138771 1.714379  2.4138684 1.7138886\n",
            " 1.7138916 2.4138746 1.7138771 1.7138771 1.7138771 1.7138771 1.7138771\n",
            " 2.413877  2.4138765 2.3926015 1.7138771 1.7138771 1.7138771 1.7138771\n",
            " 2.403246  2.4138765 1.7138797 1.7138771 1.7138771 1.7156314 2.4137094\n",
            " 2.413877  1.7138776 1.7138771 2.4138708 2.413877  1.7138771 1.7138771\n",
            " 2.413877  2.4097161 1.7138771 1.7138791 1.7138771 1.7138771 2.4137182\n",
            " 2.413877  1.7138771 1.7138771 1.7138771 1.7138771 1.7138771 2.4138732\n",
            " 2.3754368 2.4138145 2.4138038 1.8235506 2.413877  2.4138734 1.7138771\n",
            " 1.7138771 2.4133997 1.7138771 1.7138771 1.7138773 1.7138771 1.7138771\n",
            " 2.412777  1.8580538 1.7138771 2.4138765 1.714409  2.413877  1.7138771\n",
            " 1.7140216 1.7138771 2.413877  1.7138771 1.7138771 1.7138771 2.413877\n",
            " 1.7138771 2.3193498 2.413877  1.7138771 2.4138396 1.7138771 1.7138771\n",
            " 1.7147272 1.7138956 1.7138771 2.3937569 1.7321389 2.413877  2.4123468\n",
            " 1.9796551 2.413877 ]\n",
            "Step 300, Loss: [1.7139499 1.7138765 1.7138765 2.389529  2.413611  1.7138765 2.4138765\n",
            " 1.7138765 1.7179363 1.7138765 1.7138765 1.7142944 1.7138765 1.7138765\n",
            " 2.4138765 1.7138765 1.7138765 1.7138765 1.7138765 1.7138765 2.4133132\n",
            " 1.7138765 2.4138765 1.7146959 2.3814886 2.4119532 1.7138765 1.713877\n",
            " 1.7138853 2.4138746 1.7138765 2.4130332 2.130693  1.7138765 2.413855\n",
            " 1.7138765 1.7138765 2.4138765 1.7138767 2.1545365 1.9764016 1.7138765\n",
            " 1.7138765 1.7138765 1.7154145 1.7139015 1.822639  1.7138765 1.7139981\n",
            " 1.7139778 1.7138765 1.7138765 1.7138765 1.7138765 2.4138765 2.3877525\n",
            " 1.7138765 2.4138765 1.7138765 2.413733  1.7138765 1.7138765 1.7138765\n",
            " 1.7138765 1.7138765 1.7138796 1.7138765 1.7138765 2.4121644 2.4138641\n",
            " 1.7138765 1.7138765 1.7245247 1.7138765 1.7138765 1.7138765 1.7138765\n",
            " 1.7138765 1.7138765 2.4138765 2.4137473 1.7138765 1.7138765 1.7138765\n",
            " 2.4138765 2.4138765 1.7138765 2.4138765 1.7138765 1.7138765 2.4138765\n",
            " 1.7138765 1.7138782 1.7138765 1.7138765 1.7138765 1.7138929 2.4137602\n",
            " 1.8798192 1.7138765 1.7138765 1.7138765 1.7138765 2.4138763 1.7139251\n",
            " 1.7138765 1.7138765 1.7138772 1.7138765 2.4090986 1.7138765 2.4138758\n",
            " 1.7138765 1.7139854 1.7138765 2.4138718 1.7138765 2.4138765 2.4138699\n",
            " 2.4138758 1.7138765 2.413355  1.7139158 1.7138765 2.0152829 1.7138765\n",
            " 1.7138765 1.7914464]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5905 - loss: 13.8832\n",
            "Validation loss: 13.991849899291992, Validation accuracy: 0.5885999798774719\n",
            "Epoch 4/5\n",
            "Step 0, Loss: [2.4138975 1.7138989 1.7138989 1.7138989 1.7138989 2.4138987 1.7138989\n",
            " 1.7138989 1.7138989 2.3596375 1.7138989 1.7138989 2.4138987 2.4138987\n",
            " 1.7138989 2.4136593 2.4138987 2.3842103 2.4138985 1.7138989 2.321643\n",
            " 2.4138987 1.7138989 1.7138989 1.7379436 2.4138846 1.7153873 2.3558693\n",
            " 2.4138987 2.4138987 1.7138989 1.7138989 1.7138989 1.7138989 1.7138989\n",
            " 2.4138923 1.8022134 2.413823  2.413326  2.412772  1.7139189 1.7138989\n",
            " 2.413875  1.7138989 1.7138989 1.7138989 1.7138989 2.4138987 1.7138989\n",
            " 1.7138989 2.4138987 2.4138982 2.3848872 2.4138987 1.7138989 2.413598\n",
            " 2.058908  2.4127479 1.7138989 2.4138987 1.7138989 2.4138987 1.7138989\n",
            " 2.3949144 1.7138989 1.7138989 1.714047  2.4138987 1.7138989 1.7138989\n",
            " 1.8918788 1.7138989 1.7138989 2.4138987 2.390926  1.998724  1.7138989\n",
            " 1.7138989 2.413094  2.3708146 2.4131162 2.4138985 1.7138989 1.7168889\n",
            " 2.4138772 2.4138978 1.7138989 1.7383084 2.4138987 2.40968   2.4138987\n",
            " 2.4138987 1.7139108 1.7138989 1.7267025 1.7138991 1.7138989 2.4129333\n",
            " 1.7138989 1.7138989 1.7138989 1.714037  1.7138989 1.7138989 1.7138989\n",
            " 1.7138989 1.7138989 1.7138989 1.7138989 2.4138987 2.4138987 1.7138989\n",
            " 1.7138989 2.4138987 1.7138989 1.7138989 1.7140005 1.7138989 1.7138989\n",
            " 1.7138989 1.7138989 1.7139904 1.7138989 2.4018238 1.7138989 1.7138989\n",
            " 2.4138987 1.7147706]\n",
            "Step 100, Loss: [1.7139053 1.7139053 2.4139051 2.413575  1.7139053 1.7139087 1.7139053\n",
            " 1.7139256 1.7139053 1.7139053 2.4139044 2.4112175 2.4136891 1.7139053\n",
            " 2.4138923 1.7139059 1.7139053 1.7139053 1.7139053 2.4088817 1.7139053\n",
            " 1.7139056 1.7139053 2.396985  1.7139053 2.4139051 2.4131835 1.7139053\n",
            " 2.4139051 1.7139053 1.8498738 1.7139057 2.413901  1.7139053 1.7139053\n",
            " 1.7139053 1.7139053 2.4087248 1.7139053 1.7139053 1.7139053 2.4139051\n",
            " 1.7139053 1.7139053 1.7139053 1.7139053 1.7139053 2.41263   1.7139053\n",
            " 1.7139053 1.7139053 1.7139053 1.7139053 1.7139053 2.4132943 2.39638\n",
            " 2.4139051 2.4139051 1.7139053 1.7139053 1.7154069 1.7139053 1.7147504\n",
            " 1.7139053 1.7139053 1.930309  1.7139053 2.3956485 1.7139053 1.7139053\n",
            " 1.7139101 2.397477  1.7139363 1.7139053 2.413892  1.7139053 1.7139053\n",
            " 1.7145894 2.4139051 1.7139053 2.413865  2.4137635 1.7282907 1.7139053\n",
            " 2.4139051 2.2421784 1.713919  1.7139053 1.7139053 1.7139053 2.4139051\n",
            " 2.4139051 1.7139053 1.7139053 2.4137368 2.413798  1.7139055 2.4139051\n",
            " 2.4139042 2.3836546 1.7139053 2.3973725 1.7139053 2.4139051 2.4121385\n",
            " 1.7139053 2.405101  1.7139053 2.4138482 2.4138875 2.4139051 1.7139053\n",
            " 1.7162309 1.714355  2.4139051 2.4121146 1.7139053 1.7139053 1.7139053\n",
            " 2.4139051 1.7139053 1.7139053 1.7139053 2.4139051 1.7139053 1.7139053\n",
            " 1.7139053 2.4139051]\n",
            "Step 200, Loss: [1.7141463 1.7138835 2.4138834 2.4138832 2.4138832 2.4138834 2.4138656\n",
            " 2.3971314 1.7138835 1.7138835 1.7138861 1.7138835 1.7138835 1.7138835\n",
            " 2.4138834 1.7138835 1.7138835 1.7138835 1.7138835 2.4138722 2.4138834\n",
            " 1.7138835 1.7138835 1.7138835 1.7138835 1.7138835 2.4138598 1.7186309\n",
            " 1.7224897 1.7138835 2.4138834 1.7138835 1.7138835 1.7138835 2.4138834\n",
            " 2.4138834 1.7138835 1.7138835 1.7138835 1.7138835 2.4138527 1.7138847\n",
            " 2.4134693 2.4138832 1.7138835 1.7138835 1.7138835 2.191154  1.7138835\n",
            " 2.2442021 2.4138834 2.4138834 1.7138835 1.7366124 1.7138835 1.7138835\n",
            " 2.4081564 2.4137125 1.7800783 1.7138839 1.7138835 1.7138835 2.4032702\n",
            " 2.4138834 1.7138835 1.7138835 2.4138834 2.4138834 2.4138834 1.7138835\n",
            " 2.4138834 2.4056199 1.7138835 1.7138838 1.8919833 1.7138835 2.413821\n",
            " 2.4138834 1.7138835 1.7138835 1.7314624 1.7138835 1.7138835 2.4138808\n",
            " 2.4032843 2.4138832 2.4138827 1.7138836 2.4138834 1.7138835 2.4120922\n",
            " 1.7138835 2.4114451 1.7810699 2.38291   1.7138835 1.7138835 1.7138835\n",
            " 2.4138834 2.4135773 1.7138835 2.4138834 2.4138827 2.4138834 1.7138835\n",
            " 1.7138885 1.7138835 2.4138834 1.7138835 1.7138835 1.7138835 2.4138834\n",
            " 1.7138835 1.7236716 1.7138835 1.7140148 2.4133377 1.7138835 1.7138835\n",
            " 1.7138836 1.7206564 1.7138835 2.4136581 2.394343  2.4134762 2.301619\n",
            " 1.7365596 2.4138834]\n",
            "Step 300, Loss: [2.4136796 1.7138766 1.7138766 2.4134686 2.3827894 1.7138766 2.4138765\n",
            " 2.4138765 1.7138766 1.7138766 1.7138766 1.714018  1.7138766 1.7138766\n",
            " 2.4095905 1.7138766 1.7138766 1.7138766 1.7138766 1.7138766 2.4138765\n",
            " 2.410966  2.4138765 2.4065964 2.4138765 2.4125404 1.7141972 1.7138766\n",
            " 2.4138756 2.4138765 2.4138765 2.3548145 1.7165544 1.7138766 2.4138765\n",
            " 1.7138766 1.7138766 2.4098191 1.7138766 2.413875  2.3475637 1.7138766\n",
            " 1.7138766 1.7138823 1.713877  1.9494253 1.7138766 1.7140107 1.7138766\n",
            " 1.7138766 1.7138766 1.7138766 1.7138766 2.4138765 2.4138765 2.407878\n",
            " 1.7138778 2.4138765 1.7138766 2.4135938 2.4138765 1.7138766 1.7138766\n",
            " 1.7138766 1.7138766 2.4138765 1.7138766 1.7138766 2.4138765 2.4138765\n",
            " 1.7138779 1.7138766 1.7169361 1.7138766 1.7138766 1.7138766 1.7138766\n",
            " 1.7138766 1.7138766 2.3592496 1.8370138 1.7138766 1.7138766 1.7138766\n",
            " 1.7138766 2.408865  1.7138766 2.4138765 1.7138766 1.7138766 2.4138765\n",
            " 1.7138766 1.7139022 1.7138766 1.7138766 1.7138766 1.7139769 1.7139415\n",
            " 1.7140049 1.7138766 1.7138766 1.7138917 1.7138766 2.4138765 1.7141153\n",
            " 1.7138766 1.7138766 1.7138766 1.7138766 2.4138765 1.7138766 2.4138765\n",
            " 1.7138766 1.725744  2.4138765 1.7138766 1.7138766 2.413865  2.4099054\n",
            " 2.4138765 1.7139227 1.7157896 2.4138765 1.7138766 1.7138766 1.7138776\n",
            " 1.7138766 2.361424 ]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5644 - loss: 14.6954\n",
            "Validation loss: 14.698841094970703, Validation accuracy: 0.5654000043869019\n",
            "Epoch 5/5\n",
            "Step 0, Loss: [2.4138944 1.7138944 1.7138944 1.7138944 1.7138944 1.7138944 1.7138944\n",
            " 1.7138944 1.7138944 2.2361956 2.4138944 1.7138944 2.4138944 2.413564\n",
            " 1.7138944 2.4138944 1.7138948 2.4130104 2.4138944 1.7140541 1.7174149\n",
            " 2.4135003 1.7138944 1.7138944 1.7336173 1.7607303 1.7141058 2.3704507\n",
            " 2.4138944 2.4138944 1.7138944 1.7138944 1.7138944 2.1819708 1.7138944\n",
            " 2.4138944 1.7139461 1.7138944 2.3764913 2.4138925 1.7138944 1.7138944\n",
            " 1.7139032 1.7138944 1.7138944 1.7138944 1.7138944 2.4138944 1.7139823\n",
            " 1.7138944 2.4138944 2.4138944 1.7138951 2.4138944 1.8688042 2.3886588\n",
            " 2.3991816 2.2992666 2.4050844 2.4138944 1.7138944 1.7138944 1.7138944\n",
            " 1.8122954 1.7138944 1.7138944 1.7383652 2.408106  1.7138944 2.413862\n",
            " 2.3563743 1.7138944 2.3233554 2.4138944 2.3836567 1.7138944 1.7138944\n",
            " 1.7138944 2.3926642 2.4138355 2.3789494 2.4138877 1.7138944 2.4138534\n",
            " 2.4138944 2.412943  1.7138944 1.7138944 2.4138944 2.3966022 2.4138944\n",
            " 2.4119112 1.7138944 1.7138944 2.4138527 1.7138944 1.7138944 1.7138944\n",
            " 1.7138944 1.7138944 1.7138944 1.7140534 2.4138944 1.7138946 1.7138944\n",
            " 1.7138944 1.7138944 1.7138944 1.7138944 1.7139034 2.4138944 1.7138944\n",
            " 1.7138944 2.4138944 2.4138944 1.7138944 2.413634  1.7138944 1.7139044\n",
            " 1.7138944 1.7138944 1.7138975 1.7141073 2.3682137 1.7138944 1.7408261\n",
            " 1.7138944 2.4135456]\n",
            "Step 100, Loss: [1.7138834 1.7138834 2.4138808 1.7140033 1.7138834 1.7138841 1.7138834\n",
            " 1.7174621 1.7138834 1.7138834 2.4138832 1.7163754 2.4109387 1.7138834\n",
            " 1.7139702 1.7139435 2.4138832 1.7138834 2.4138832 2.3957179 1.7138834\n",
            " 1.7138839 1.7138834 2.3956344 1.7138834 2.4075375 2.3930686 1.7138834\n",
            " 1.7138834 1.7138834 1.7138834 1.7138834 2.3913157 1.7138834 1.7138834\n",
            " 1.7138884 1.7138858 2.147275  1.7138834 1.7138834 1.7138834 1.7138834\n",
            " 1.7138834 1.7138834 1.7138963 1.7138834 1.7138834 2.4138832 1.7138834\n",
            " 1.7138834 1.7138834 1.7138834 1.7138834 2.402541  2.356418  2.413883\n",
            " 2.4138832 2.4138832 1.7138834 1.7138836 2.4112277 1.7138834 1.7138834\n",
            " 1.7138834 1.7141263 2.4134665 1.7138834 2.2096367 1.7138834 1.7207854\n",
            " 2.0344453 2.4136057 1.7153387 2.375117  2.4088786 1.7405968 1.7138834\n",
            " 2.162545  2.413883  2.3133435 2.4138832 2.413882  1.7138884 1.848331\n",
            " 2.4138832 1.7139571 2.2674675 1.7138834 1.7138834 1.7138834 2.4138832\n",
            " 2.4138832 1.7138834 1.7138834 2.4138832 1.7138834 2.411867  1.7138982\n",
            " 2.4138832 2.4138634 1.7138834 2.4138832 1.7138834 2.4138832 1.963206\n",
            " 1.7138834 2.413883  1.7138834 2.4138832 2.413883  2.2001884 2.4137235\n",
            " 2.301358  1.7138834 1.7138834 2.3871028 1.7138834 1.7138834 1.7138834\n",
            " 1.7138834 1.7138834 1.7138834 1.7138834 1.7138834 1.7138834 2.0385492\n",
            " 1.7138834 2.4138832]\n",
            "Step 200, Loss: [1.7138948 2.4132612 2.4106805 2.413895  2.413895  2.413895  1.7454097\n",
            " 1.7142572 1.7138948 1.7138948 1.7138994 1.7138948 1.7138948 1.7138948\n",
            " 2.413895  1.7138948 1.7138948 2.413895  1.7138948 1.7138948 2.413895\n",
            " 1.7138948 1.7138948 1.7138948 1.7138948 1.8049262 1.7181194 1.744884\n",
            " 2.4138722 1.7138948 2.413895  1.7138948 1.7138948 1.7138948 2.413895\n",
            " 2.3879876 1.7138948 1.7138948 1.7138948 1.7138951 2.4131866 2.1152716\n",
            " 2.413893  2.4127698 2.413895  1.7138948 2.413895  1.7138948 1.7138948\n",
            " 1.7143354 2.4136322 2.413895  1.7138948 1.7138948 1.7138948 1.7138948\n",
            " 1.7138948 2.391538  1.8458431 1.7138948 1.7138948 1.713911  1.7748423\n",
            " 2.413895  1.7138953 1.7138948 2.053606  2.410683  1.7383981 1.7138948\n",
            " 2.413463  1.7141953 1.7138948 1.7139018 1.7138948 1.7138948 2.4132621\n",
            " 2.413895  1.7138948 1.7138948 1.7138948 1.7138948 1.7138948 2.413895\n",
            " 2.1831486 2.413895  2.4138942 1.7140896 2.4138365 1.7141309 2.4138944\n",
            " 1.7138948 2.4138947 1.7138963 1.7138948 1.7138948 1.7138948 1.7138948\n",
            " 2.413895  1.7359779 1.7138948 2.4124653 1.714047  2.412199  1.7138948\n",
            " 1.7138948 1.7138963 2.4138393 1.7138948 1.7138948 1.7138948 2.413895\n",
            " 1.7138948 1.7219777 1.7138948 1.7150037 2.413715  1.7138948 1.7138948\n",
            " 1.7138948 2.385394  1.7138948 2.4138858 2.413895  2.2823174 2.4088697\n",
            " 2.0847971 2.413895 ]\n",
            "Step 300, Loss: [1.7140375 1.7138845 1.7138845 2.4138825 1.7146183 1.7237334 2.4138844\n",
            " 2.4138746 1.7138845 1.7138845 1.7138845 2.2442014 1.7138845 1.7138845\n",
            " 2.4138818 1.7138845 2.4138844 1.7138845 1.7138845 2.4138823 1.7138845\n",
            " 1.7138845 2.4138842 1.7300156 2.3978708 1.7138845 1.713885  1.7138845\n",
            " 2.4138844 2.4138844 1.7138846 1.7138845 2.361319  1.7138851 2.4138844\n",
            " 1.7138845 1.7138845 2.405346  1.7138845 1.7138851 2.3847692 1.7138845\n",
            " 1.7138845 1.7138845 1.7458998 1.7143141 2.2354455 1.7138845 1.7269626\n",
            " 1.7138845 1.7138845 1.7138845 1.7138845 1.8479375 2.4138844 1.7509133\n",
            " 1.7138845 2.4138844 1.7138845 2.3960867 2.4138844 1.7138845 1.7138845\n",
            " 1.7138845 1.7138845 1.7138845 1.7138845 2.4138844 1.7138845 2.388506\n",
            " 2.4124436 1.7138845 2.011527  1.7138845 1.7138845 1.7138845 1.713887\n",
            " 1.7138845 1.7138845 2.4138844 1.7809386 1.7138845 1.7138845 1.7138845\n",
            " 1.7138845 2.4124327 1.7138845 2.4138844 1.7138845 1.7138845 2.4132717\n",
            " 1.7138845 2.4093666 1.7138845 1.7138845 1.7138845 2.4138477 2.4138486\n",
            " 1.7138898 1.7138845 1.7138845 1.7139078 1.7138846 2.4073253 2.4078302\n",
            " 1.7138845 2.4138844 1.7138845 1.7203366 1.7138845 1.7138845 2.3892543\n",
            " 1.7138845 1.7138921 1.7138845 2.4138844 2.4138844 2.4138844 2.4138842\n",
            " 2.366184  1.7138845 2.2950048 1.7138853 1.7138845 2.4136386 1.7139904\n",
            " 1.7138845 1.7138845]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6179 - loss: 8.9648\n",
            "Validation loss: 9.089384078979492, Validation accuracy: 0.6194000244140625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = student_model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtjhYaf7_kcY",
        "outputId": "6f6f773a-59ee-4a8e-b798-59a85387418a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 8.9683\n",
            "Test accuracy: 0.6194000244140625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for step in range(len(x_train) // batch_size):\n",
        "        x_batch = x_train[step * batch_size:(step + 1) * batch_size]\n",
        "        y_batch = y_train[step * batch_size:(step + 1) * batch_size]\n",
        "        soft_batch = soft_targets[step * batch_size:(step + 1) * batch_size]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = student_model(x_batch, training=True)\n",
        "            loss_value = distillation_loss(y_batch, logits, soft_batch, alpha=0.3, temperature=6.0)\n",
        "\n",
        "\n",
        "        grads = tape.gradient(loss_value, student_model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss_value.numpy()}\")\n",
        "\n",
        "\n",
        "    val_loss, val_acc = student_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqK267hW_uNq",
        "outputId": "f9485af6-f16e-4262-9ab5-2707dcec3b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Step 0, Loss: [1.7138011 1.7137997 1.713975  1.7137997 1.7137997 2.4134297 2.4137998\n",
            " 1.7137997 1.7137997 1.7155585 1.7137997 1.7137997 2.4137998 2.4057455\n",
            " 1.7137997 1.9038618 1.7137997 1.9363012 2.410472  1.7137997 2.4137995\n",
            " 2.3601055 1.7137997 1.7137997 1.7197807 1.7137997 1.7138042 2.4136899\n",
            " 1.7138045 2.4056163 1.7137997 1.7138011 1.7137997 2.230451  1.7137997\n",
            " 2.4137998 1.7138002 2.3761055 1.7832091 2.4137998 1.7138    1.7137997\n",
            " 1.7137997 1.7137997 1.7137997 2.4137998 1.7137997 2.4137998 1.7137997\n",
            " 2.4084609 2.4137998 2.4137897 1.7137997 2.4137998 1.7137997 2.4124749\n",
            " 2.412869  2.4031992 1.7138023 2.40006   1.7137997 1.7137997 1.7137997\n",
            " 1.7138014 1.7137997 1.7137997 1.7137997 1.7138    1.7137997 1.7137997\n",
            " 1.7330227 1.7138112 1.7138002 1.7139363 2.4137998 1.7137997 1.7137997\n",
            " 1.7137997 2.4137998 2.413714  2.400677  2.4137998 1.7137997 1.7151034\n",
            " 2.4134486 2.413682  1.7137997 1.7137997 1.7137997 1.7318316 2.4137998\n",
            " 2.4137998 1.7137997 1.7137997 1.7137997 1.7137997 2.4137998 2.4093363\n",
            " 1.7137997 1.7137997 1.7137997 1.7137997 1.7137997 1.7137997 1.7137997\n",
            " 1.7137997 1.7137997 1.7138    1.7137997 2.4137998 2.4137998 1.7137997\n",
            " 1.7137997 2.4137998 2.4137998 1.7137997 2.0405247 1.7137997 1.7138002\n",
            " 1.7137997 1.7137997 1.7137997 1.7137997 2.4137998 1.7137997 1.7137997\n",
            " 1.7137997 2.402994 ]\n",
            "Step 100, Loss: [1.7139486 1.7137938 2.4137936 1.7137958 1.7137938 1.7137938 1.7137938\n",
            " 1.8800876 1.7137938 1.7137938 1.715169  2.010139  2.4137135 1.7137938\n",
            " 2.4137921 1.7138929 2.4137936 1.7137938 1.7137938 2.3746715 1.7163726\n",
            " 1.7199277 1.724586  1.7285126 1.7137938 1.7166418 2.413753  1.7137938\n",
            " 1.7137948 1.7137938 1.7137938 1.7137938 2.4137936 1.7137938 1.7137938\n",
            " 1.7137938 1.7137938 1.7218486 1.7137938 1.7137938 1.7137938 2.4137936\n",
            " 1.7137938 1.7137938 1.7137938 1.7137938 1.7137938 2.4137936 1.7137938\n",
            " 1.7137938 1.7137938 1.7137938 1.7137938 1.7138524 1.7137938 2.4137936\n",
            " 2.4137936 2.4137936 1.7137938 1.7137938 1.7137942 1.7137938 1.7137938\n",
            " 1.7137938 1.7137938 2.3811266 1.7137938 1.7137938 1.7137938 1.7140831\n",
            " 1.7137938 2.3975809 2.4074655 1.7137938 2.4121745 2.408346  1.7137938\n",
            " 1.7137938 2.4137936 2.413793  1.7137938 2.4137936 1.7554902 1.7303864\n",
            " 2.4137936 1.7137938 1.7219527 1.7137938 1.7137938 1.7137938 2.4137936\n",
            " 1.7137938 1.7137938 1.7137938 2.4137936 1.7138864 2.094493  2.400008\n",
            " 2.4137936 2.410511  1.7137938 1.7138934 1.7137938 1.7137938 1.713991\n",
            " 1.7137938 1.7899712 1.7137938 2.4137862 2.3928993 2.4095268 2.4137936\n",
            " 2.4137928 1.7137938 2.0477524 2.4137936 1.7137938 1.7137938 1.7137938\n",
            " 1.7137938 1.7137938 1.7137938 1.7137938 1.713794  1.7137938 1.7147514\n",
            " 2.4048493 2.4137936]\n",
            "Step 200, Loss: [1.7137973 2.4137974 2.4137974 2.4126265 2.4129944 2.4137974 1.7137975\n",
            " 2.4137912 1.7137973 1.7137973 1.7137973 1.7137973 1.7137973 1.7137973\n",
            " 2.413797  1.7137973 1.7137973 1.7137973 1.7137973 1.7137973 2.4137974\n",
            " 1.7137973 1.7139634 2.4137402 1.7137973 1.7137973 1.716079  2.3946943\n",
            " 2.4137962 1.7137973 2.4137974 1.7137973 2.4120965 1.7138046 2.4137974\n",
            " 2.4137974 2.4137678 1.7137973 1.7137973 1.7138269 2.413764  2.4135075\n",
            " 1.7141393 2.4134264 2.4137974 1.7137973 2.413797  1.7137973 1.7137973\n",
            " 1.718314  2.413745  2.4137974 1.7137973 1.7137973 1.7137973 1.7137973\n",
            " 1.7140718 2.4137316 1.7152658 1.7137973 1.7137973 1.713822  2.4137836\n",
            " 2.4137974 1.7138048 1.7137973 1.7142333 2.4137948 1.7137973 1.7137973\n",
            " 2.412372  2.4137974 1.7137973 1.7202021 1.7137973 1.7137973 2.410129\n",
            " 2.4137974 1.7137973 1.7137973 1.7142012 1.7137973 1.7137973 2.4037933\n",
            " 2.4137974 1.7137973 2.4108996 2.3871863 2.413796  1.7137973 1.8154625\n",
            " 1.7137973 2.4137974 1.713798  1.7137973 1.7137973 1.7137973 1.7137973\n",
            " 2.4137974 2.413787  1.7137973 2.412856  2.4115868 2.4137974 1.7137973\n",
            " 1.7137979 1.7137973 2.3952389 1.7137973 1.7137973 1.7137973 2.4137974\n",
            " 1.7137973 2.4137833 1.7137973 2.413797  2.4136934 1.7137973 1.7137973\n",
            " 1.7137973 1.7137973 1.7137973 2.4137907 1.7138808 1.7137976 1.7137977\n",
            " 2.1062949 2.4135518]\n",
            "Step 300, Loss: [1.7137908 1.7137908 1.7137908 2.409084  2.3670232 1.7137908 2.4137907\n",
            " 1.713793  1.7137908 1.7137908 1.7137908 1.7138484 2.0773726 1.7137908\n",
            " 2.4115882 1.7137908 1.7137908 1.7137908 2.4116282 1.7137908 2.4137907\n",
            " 1.7137908 2.4137907 1.7137909 2.4137907 1.7262418 1.7137908 1.7137908\n",
            " 2.1143517 2.4137907 1.7137908 2.405033  2.3854218 1.7137908 2.4137907\n",
            " 1.7137908 1.7137908 2.4137864 1.7137908 1.7137909 1.7162027 2.4137254\n",
            " 1.7137908 1.7137908 1.7137908 2.4137902 1.7137908 1.7137908 2.4086292\n",
            " 1.7137908 1.7137908 1.7137908 1.7137908 1.7137908 2.4137907 2.4137897\n",
            " 1.7137908 2.4137907 1.7137908 2.4137902 1.7137908 1.7137908 1.7137908\n",
            " 1.7137908 1.7137908 1.7144208 1.7137908 1.7137908 1.7137917 2.4135585\n",
            " 2.4127862 1.7137908 1.7138109 1.7137908 2.4137907 1.7138267 1.7137908\n",
            " 1.7137908 1.7137908 2.4127128 2.4137795 1.7137908 1.7137908 1.7137908\n",
            " 1.7137908 2.4137907 1.7137908 2.4137907 1.7137908 1.7137908 2.4137907\n",
            " 1.7195398 1.7616401 1.7137908 1.7137908 1.7137908 1.7137924 2.4137907\n",
            " 1.7475477 1.7137908 1.7137908 1.7137908 1.7137908 2.4092743 1.7199996\n",
            " 1.7137908 2.4137907 1.7137908 1.7137908 1.7137908 1.7137908 2.4137907\n",
            " 1.7137908 1.7137908 1.7137908 2.4137907 1.7137908 2.4137907 2.4137902\n",
            " 2.4137676 1.7137965 2.1046443 2.3840861 1.7137908 2.4137902 1.7137908\n",
            " 1.7137908 2.3917356]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 10.0473\n",
            "Validation loss: 10.313328742980957, Validation accuracy: 0.6064000129699707\n",
            "Epoch 2/5\n",
            "Step 0, Loss: [2.4137952 1.7137954 1.7137954 1.7137954 1.7137954 1.7137954 2.4135234\n",
            " 1.7137954 1.7137954 2.180048  1.7137954 1.7137954 2.4137952 1.9922214\n",
            " 2.4137824 1.7137969 1.7137954 1.7137954 1.7137954 2.341242  2.413777\n",
            " 1.7137954 1.7137954 1.7137954 2.4137952 2.4137952 1.7137954 2.2118344\n",
            " 2.1528494 2.4137952 1.7137954 1.7137954 1.7137954 1.7137954 1.7137954\n",
            " 2.4137952 1.7137954 1.7138741 2.4117022 2.41306   1.7137954 1.7137954\n",
            " 2.4137952 1.7137954 2.0360262 1.7137954 1.7137954 2.4137952 1.7138062\n",
            " 1.7137954 2.4137952 2.4137952 2.4136167 1.7137954 1.7137954 2.4137928\n",
            " 2.4124813 1.7138023 1.7149708 2.4137545 1.7137954 1.7137954 1.7137954\n",
            " 1.7138019 1.7137954 1.7137954 1.8498356 1.7137954 1.7137954 1.7137954\n",
            " 2.4137578 1.7371426 2.2255235 2.4137912 2.413794  1.7137954 1.7137954\n",
            " 1.7137954 2.413506  1.7179945 1.7160292 2.4137826 1.7137954 1.7138023\n",
            " 2.4131324 2.4137952 1.7137954 1.7137954 1.7137954 2.384086  2.4137952\n",
            " 2.3935173 1.7137954 1.7137954 1.7162678 1.7137954 2.4137952 1.7139938\n",
            " 1.7137954 2.4137952 1.7137954 1.7138    1.7137954 1.7137954 1.7137954\n",
            " 1.7137954 1.7137954 1.7137957 1.7137954 1.7137954 2.4137952 1.7137954\n",
            " 1.7137954 2.4137952 2.4137952 1.7137954 1.7137954 1.7137954 1.7137954\n",
            " 1.7137954 1.7137954 1.7624476 1.7137959 2.4035072 1.7137954 1.7137954\n",
            " 2.4137952 1.7137954]\n",
            "Step 100, Loss: [1.7137942 1.7137942 2.413794  1.7137942 1.7137942 1.7139958 1.7137942\n",
            " 1.7137942 1.7137942 1.7137942 2.413794  2.2945123 2.413794  1.7137942\n",
            " 2.413794  1.7139046 2.413794  1.7137942 1.7137942 1.7146627 1.7137946\n",
            " 2.4120276 1.7137942 2.1026764 1.7137942 2.4137938 2.413794  1.7137942\n",
            " 1.7137942 1.7137942 1.7137942 1.7137942 2.20021   1.7137942 1.7137942\n",
            " 1.7137942 1.7137942 2.0909815 1.7137942 1.7137942 1.7137942 1.7137942\n",
            " 1.7137942 1.7137942 1.7137942 1.7137942 1.7137942 2.413794  1.7137942\n",
            " 1.7137942 1.7137942 1.7137942 1.7137942 1.7150223 1.713802  2.413794\n",
            " 2.413794  2.413794  1.7137942 1.7137942 1.7145002 1.7137942 1.7137942\n",
            " 1.7137942 1.7137942 2.413794  1.7137942 2.413794  1.7137942 1.7137942\n",
            " 1.7137942 2.4136992 1.7319053 1.7137942 2.3701692 2.4137938 1.7137942\n",
            " 1.7137942 2.413794  1.7137942 1.7137942 2.413794  1.7385683 1.7137942\n",
            " 2.1511345 1.7137942 1.7239437 1.7137942 1.7137942 1.7137942 2.413794\n",
            " 2.413794  1.7137942 1.7137942 2.413794  1.7137942 2.413794  2.3471985\n",
            " 2.4137564 2.406442  1.7137942 1.7138007 1.7137942 1.7137942 2.413794\n",
            " 1.7137942 2.4137359 1.7137942 2.413794  1.7171458 1.7786589 2.413794\n",
            " 1.7137951 1.7137942 1.7137942 2.413794  1.7137942 1.7137942 1.7137942\n",
            " 1.7137942 1.7137942 2.412833  1.7137942 1.7137942 1.7137942 1.7138909\n",
            " 1.7137942 2.4137917]\n",
            "Step 200, Loss: [1.7137952 1.7139363 2.413795  2.413795  2.413795  2.413795  1.7139745\n",
            " 1.7262151 1.713795  1.713795  1.713795  2.413795  1.713795  1.713795\n",
            " 2.413795  1.713795  1.713795  2.4137878 1.713795  1.713795  2.413795\n",
            " 1.713795  1.713795  1.714469  1.713795  1.713795  1.7142668 2.4137945\n",
            " 2.4137943 1.713795  2.413795  1.713795  1.713795  1.713795  2.4137948\n",
            " 2.4137938 1.713795  2.413795  1.713795  1.7137954 1.7818594 1.713795\n",
            " 1.7138939 2.413786  1.721611  1.713795  1.713795  2.413795  1.713795\n",
            " 2.4137895 2.4137354 2.413795  1.713795  1.713795  1.713795  1.713795\n",
            " 1.7197566 2.3681474 1.713795  1.7138047 1.713795  2.0187898 2.3553984\n",
            " 2.413795  1.713932  1.713795  2.2466726 2.413795  2.413795  1.713795\n",
            " 2.413787  1.7318871 1.713795  1.713795  1.713795  1.713795  2.290659\n",
            " 2.413795  1.713795  1.713795  1.7138407 1.713795  1.713795  2.3405442\n",
            " 2.4137933 1.713795  2.413795  2.2727087 2.413795  2.413795  1.713803\n",
            " 1.713795  2.413795  1.713795  1.713795  1.713795  1.713795  1.713795\n",
            " 2.413795  1.7611444 1.713795  2.4137928 1.7138016 2.4064336 1.713795\n",
            " 1.7139175 1.713795  2.3762472 1.713795  1.713795  1.767549  2.413795\n",
            " 1.713795  1.7146456 1.713795  1.7138765 2.413795  1.713795  1.713795\n",
            " 1.7137957 1.7138097 1.713795  2.413795  2.413795  2.413795  1.713795\n",
            " 1.7140377 2.2945065]\n",
            "Step 300, Loss: [1.7137964 1.7137964 1.7137964 2.4127643 1.7138169 1.7137964 2.4137964\n",
            " 1.7137964 1.7137997 1.7138019 1.7137964 1.7137971 2.345156  1.7137964\n",
            " 2.4137964 1.7137964 1.7137964 1.7137964 1.7222302 1.7137964 1.7137964\n",
            " 1.7137964 2.4108167 1.7137964 2.4136791 2.4137952 1.7137964 1.7137964\n",
            " 2.1229477 2.4137964 2.4137964 2.4137964 2.4049015 1.7137964 2.4137964\n",
            " 1.7137964 1.7137964 2.4137952 1.7137964 1.7190421 1.7137964 2.3745031\n",
            " 1.7137964 1.7137964 1.7143326 2.1506743 1.7137964 1.7137964 2.4137964\n",
            " 1.7137973 1.7137964 2.1420639 1.7137964 1.7137964 2.4137964 2.406927\n",
            " 1.7137964 2.4137964 2.4137957 2.413777  1.7137964 1.7137973 1.7137964\n",
            " 1.7137964 1.7137964 1.7156043 1.7137964 2.4137917 1.7137964 2.3644323\n",
            " 1.7137969 1.7137964 2.3466816 1.7137964 1.7137964 1.7137964 1.7137964\n",
            " 1.7137964 1.7137964 2.4137964 2.4137964 1.7137964 1.7137964 1.7137964\n",
            " 2.4137964 2.4137964 1.7137964 2.4137964 1.7137964 1.7137964 2.4137964\n",
            " 1.7137964 2.4137964 1.7137964 2.4137964 1.8229733 1.7137964 2.4137948\n",
            " 1.7138021 1.7137964 1.7137964 1.7137964 1.7137964 1.713799  1.7182148\n",
            " 1.7137964 2.413733  1.7137964 1.7137964 2.4119568 1.7137964 2.4137356\n",
            " 1.7137964 1.7137964 1.7137964 1.7137964 1.7137964 2.413796  2.4137964\n",
            " 2.4137964 1.7137964 2.4137964 1.7137964 1.7137964 1.7137964 2.3993382\n",
            " 1.7137964 1.7137964]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6116 - loss: 10.5021\n",
            "Validation loss: 10.73898696899414, Validation accuracy: 0.6062999963760376\n",
            "Epoch 3/5\n",
            "Step 0, Loss: [2.4138002 1.7138004 1.7138004 1.7138004 2.4044957 1.8436704 1.7138007\n",
            " 1.7138004 1.7138004 1.88153   1.7138004 1.7138004 2.4138002 2.4137993\n",
            " 1.7138004 2.3917217 1.7138004 1.7138005 2.4138002 1.7138004 1.7138015\n",
            " 2.4103293 1.7138004 1.7138004 2.413673  2.3197587 2.4137955 2.4137776\n",
            " 1.7138004 2.41371   1.7138004 1.7138004 1.7138004 1.7138004 1.7138004\n",
            " 2.4137874 1.7139448 2.4137795 2.41218   2.4138002 1.7138007 1.7138004\n",
            " 1.714546  1.7138004 1.7138004 2.4138002 2.4138002 2.4138002 1.7138861\n",
            " 1.7138004 2.4138002 2.4114437 1.71381   1.7138004 1.7138004 2.4125009\n",
            " 2.4137788 2.4102252 1.7138004 2.3734548 1.7138004 2.4138002 1.7138004\n",
            " 1.7140753 1.7138004 1.7138004 1.7138121 1.7138004 1.7138004 1.7138004\n",
            " 2.4137993 1.7138004 1.7138013 1.7138163 2.4138    1.7138004 1.7138004\n",
            " 1.7138004 2.4138002 2.4138002 1.7142178 2.4137044 1.7138004 1.7138011\n",
            " 2.4138002 2.1410997 1.7138004 1.7138004 1.7138004 2.3411708 2.4138002\n",
            " 2.4137993 1.7138004 1.7138004 2.4138002 1.7138004 2.4138002 1.7138004\n",
            " 1.7138004 2.4138002 1.7138004 1.7138039 1.7138004 1.7138004 1.7138004\n",
            " 1.7138004 1.7138004 1.7138004 1.7138004 2.4138002 2.4138002 1.7138004\n",
            " 2.4138002 1.9632875 2.4138002 1.7138004 1.7138004 1.7138212 1.7138004\n",
            " 1.7138004 1.7138004 1.7138022 1.7138004 2.4137883 1.7138004 1.7138004\n",
            " 1.7138004 2.411673 ]\n",
            "Step 100, Loss: [1.7138011 1.7138011 2.4137878 2.4031541 1.7138011 1.7138011 1.7138011\n",
            " 1.9454455 1.7138011 1.7138011 2.413791  1.714395  2.4135904 1.7138011\n",
            " 2.4137933 1.7139957 2.413801  1.7138011 1.7138011 1.7138171 1.7143059\n",
            " 1.7138011 1.7138011 1.7138145 1.7138011 2.4132469 2.4136026 1.7138011\n",
            " 1.7138011 1.7138011 1.7138011 1.7138011 2.4137874 1.7138011 1.7138011\n",
            " 1.7138011 2.3868518 1.7139473 1.7138011 1.7138011 1.7138011 1.7138011\n",
            " 1.7138011 1.7138011 1.9552922 1.7138011 1.7138011 2.413801  2.4137278\n",
            " 1.7138011 1.7138011 1.7138011 1.7138011 1.7138045 1.7138035 2.4138007\n",
            " 2.413801  2.4138    1.7138011 1.7138011 1.7155435 1.7138011 1.7138011\n",
            " 1.7138011 1.7138011 2.4115698 1.7138011 1.7138011 1.7138011 1.7903869\n",
            " 1.7138011 2.4136279 1.7168207 1.7138011 2.4133706 1.7796171 2.4130013\n",
            " 1.7138011 2.413801  1.7138011 1.7138011 2.413801  1.7138011 1.7138011\n",
            " 2.4104917 2.4094315 2.375336  1.7138011 1.7138011 1.7138011 2.4093597\n",
            " 1.7138011 1.7138011 1.7138011 2.413801  1.7138045 2.413801  2.36905\n",
            " 2.3948689 2.3951783 1.8757703 2.4023485 1.7138011 1.7138011 1.7145283\n",
            " 1.7138011 1.7138011 1.7138011 2.413801  2.4137702 2.4138002 1.7138069\n",
            " 1.7138336 1.7138011 1.7138011 2.413801  1.7138011 1.7138011 1.7138011\n",
            " 1.7138011 1.7138011 1.713804  2.1322794 1.7138011 1.7138011 1.7138011\n",
            " 1.7138011 2.413801 ]\n",
            "Step 200, Loss: [1.713795  1.9254923 2.413795  2.4098916 2.41317   2.4137917 1.7217554\n",
            " 2.4137795 1.713795  1.713795  2.3874078 1.713795  1.713795  1.713795\n",
            " 2.413795  1.713795  1.713795  2.413795  1.713795  1.713795  2.413795\n",
            " 1.713795  1.7137958 1.713795  1.713795  1.713795  1.713795  2.003478\n",
            " 1.748629  1.713795  2.413795  1.713795  1.713795  1.713795  2.413795\n",
            " 2.4066408 1.713795  1.713795  1.713795  1.7139244 2.4137945 2.413795\n",
            " 1.714144  2.4137907 1.713795  1.713795  1.713795  2.413795  1.713795\n",
            " 2.413794  2.2808614 2.413795  1.713795  1.713795  1.713795  1.7138058\n",
            " 1.713795  2.413795  1.713795  1.713795  1.713795  1.7137955 2.4136577\n",
            " 2.413795  1.7138013 1.713795  2.413795  2.413795  1.713795  1.713795\n",
            " 2.413795  1.8183131 2.352997  2.4015968 1.713795  1.7176598 2.398572\n",
            " 2.413795  1.713795  1.713795  1.720511  1.713795  1.713795  2.4127688\n",
            " 2.413795  2.413795  2.4137928 2.3397942 2.4137907 2.413795  2.413386\n",
            " 1.713795  2.4137943 1.719367  1.713795  1.713795  1.713795  1.713795\n",
            " 2.4094758 2.085908  1.713795  2.4135795 1.7137952 2.413795  1.713795\n",
            " 2.4137855 1.713795  2.413795  1.713795  1.713795  1.713795  2.413795\n",
            " 1.713795  1.7138016 1.713795  2.4133353 2.413757  1.713795  1.713795\n",
            " 1.713795  1.7137951 1.713795  2.4009655 2.413795  1.7137972 1.7156783\n",
            " 1.7535012 1.713805 ]\n",
            "Step 300, Loss: [1.7137868 1.7137868 1.7137868 2.3934116 1.7155523 1.7137868 2.4137866\n",
            " 1.7137868 1.7137868 1.7137868 1.7137868 1.7138741 1.7137868 1.7137868\n",
            " 2.4137866 1.7137868 1.7137868 2.4137866 1.7137868 1.7137868 1.7137868\n",
            " 1.7137868 2.4135945 1.7137878 2.4137866 1.7137868 2.4137866 2.4121897\n",
            " 2.4137864 1.7137868 2.4137866 2.4137866 2.374394  1.7137868 2.4137866\n",
            " 1.7137868 1.7137868 2.413783  1.807514  2.4137862 2.3931785 1.7137868\n",
            " 1.7137871 1.7137868 1.7137933 1.7140543 1.7137868 1.7137868 1.7137926\n",
            " 1.7138026 1.7137868 1.7137868 1.7137868 2.4137866 2.4137866 2.4137845\n",
            " 1.7137868 2.4137866 1.7137868 2.4137602 1.7137868 1.7137868 1.7137868\n",
            " 1.7137868 1.7137868 1.7137868 1.7137868 1.7137868 1.7137868 2.406674\n",
            " 1.7137868 1.7137868 1.7140212 1.7137868 1.7137868 1.7137868 1.7137868\n",
            " 1.7137868 1.7137868 2.4137866 1.7159314 1.7137868 1.7137868 1.7137868\n",
            " 2.4137866 2.4090462 1.7939773 2.4137866 1.7137868 1.7137868 2.4137866\n",
            " 1.7137868 1.9652517 1.7137868 2.4137866 1.7137868 2.4137866 2.3557868\n",
            " 1.7148719 1.7137868 1.7137868 1.7137868 1.7137878 1.7222366 2.413701\n",
            " 1.7137868 1.7137868 1.7137868 1.7137868 2.4137866 1.7137868 2.4137866\n",
            " 1.7137868 1.7137868 1.7137868 1.7137868 1.7137868 2.4137866 2.413782\n",
            " 2.4135122 1.7137868 1.9508357 2.4136937 1.7137868 2.4137866 1.7138693\n",
            " 1.7137868 2.3480864]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6149 - loss: 11.5332\n",
            "Validation loss: 11.66383171081543, Validation accuracy: 0.6079999804496765\n",
            "Epoch 4/5\n",
            "Step 0, Loss: [2.4138098 1.7138121 1.7138121 1.7138121 1.7138121 2.4134884 2.4138117\n",
            " 1.7138121 1.7138121 1.7452471 1.7138121 1.7138121 2.4138122 2.4097483\n",
            " 2.413807  2.4138122 1.7138121 1.7138133 1.715611  1.7138121 2.3796859\n",
            " 1.7138121 1.7138121 1.7138121 1.7789308 1.7209702 1.7138642 1.7138634\n",
            " 1.7144822 1.7147646 1.7138121 1.7138121 1.7138121 1.7138121 1.7138121\n",
            " 2.4137967 2.3044004 1.7171351 2.4138122 2.413794  1.7138885 1.7138121\n",
            " 1.7138667 1.7138121 2.3848002 2.4138122 1.7138121 2.4138122 1.7138121\n",
            " 2.4137325 2.4138122 2.4138122 2.4106212 1.7197568 1.7138121 2.4138122\n",
            " 1.71384   1.7198795 2.4138122 2.413662  1.7138121 2.4138122 1.7138121\n",
            " 1.745546  1.7138121 1.7138121 1.7138121 1.7138121 1.7138121 1.7138121\n",
            " 2.4138122 1.713813  1.7138121 1.7138133 2.4138122 2.4116504 1.7138121\n",
            " 1.7138121 2.3990197 1.7138121 1.714834  2.4107676 1.7138121 1.7145756\n",
            " 2.4136333 2.0759487 2.4138122 1.7138121 1.7138121 1.7138149 2.4137943\n",
            " 1.7163113 1.7138121 1.7138121 2.4113235 1.7138133 2.4138122 2.4067433\n",
            " 1.7138121 2.4138122 1.7138121 1.7138122 1.7138121 1.7138121 1.7138121\n",
            " 1.7138121 1.7138121 1.7138122 1.7138121 1.7138121 2.4080021 2.4138122\n",
            " 1.7138121 1.8291878 2.4138122 1.7138121 1.713813  1.7138121 1.7138121\n",
            " 1.7138121 1.7138121 2.4132903 1.7138121 2.4138122 1.7138121 1.7138121\n",
            " 1.7138121 1.7138121]\n",
            "Step 100, Loss: [1.7138026 1.7138026 2.4138021 1.7139235 1.7138026 1.713803  1.7138026\n",
            " 1.7138093 1.7138026 1.7138026 2.4138024 1.7152281 2.3125641 1.8077974\n",
            " 2.4138024 1.7226954 1.7138026 1.7321799 1.7138026 1.7138033 1.7170024\n",
            " 1.713804  1.7138026 1.7138393 1.7138026 1.757122  2.4137907 1.7138026\n",
            " 2.4138024 1.7138026 1.7138026 1.7138026 2.4137511 1.7138026 1.7138026\n",
            " 1.7138026 2.4112542 1.7170131 1.7138026 1.7138026 1.7138026 1.7138026\n",
            " 1.7138026 1.7138026 1.7138026 1.7138026 2.4127724 2.4138024 1.7138026\n",
            " 1.7138026 1.7138026 1.7138026 2.4097471 1.7138038 2.3821905 2.4138024\n",
            " 2.4138024 2.4138024 1.7138026 1.7138026 2.4136803 1.7138026 1.7138026\n",
            " 1.7138026 1.7138026 2.4136467 2.4138024 1.7139027 1.7138026 1.7138026\n",
            " 1.7138026 2.413286  1.7138355 1.7138026 2.4138021 1.7138026 2.1993957\n",
            " 1.7138026 2.4138021 2.2120357 1.7138026 2.4138024 1.7783535 2.3497322\n",
            " 1.7162371 1.7140551 1.7138026 1.7138026 1.7138026 1.7138026 2.413737\n",
            " 2.413776  1.7138026 1.7138026 1.7138026 1.7138026 2.4133575 1.7182126\n",
            " 2.4135492 2.4138021 1.7138026 1.7150054 1.7138026 1.7138026 2.2598944\n",
            " 1.7138026 2.4138024 2.4107764 2.4138021 2.4138024 2.411125  2.4138024\n",
            " 1.7138026 1.7138026 1.7138026 2.4138024 1.7138026 1.7138076 1.7138026\n",
            " 1.7138026 1.7138026 1.7138026 1.7138026 1.7138026 1.7138026 1.7161303\n",
            " 1.7138026 2.3977137]\n",
            "Step 200, Loss: [1.7138126 1.7138126 2.4138126 1.7150075 2.4137745 2.4136913 2.4138124\n",
            " 2.4138126 1.7138126 1.7138126 1.7138126 1.7138126 1.7138126 1.7138126\n",
            " 1.7138126 1.7138126 1.7138126 1.7138126 1.7138126 1.7138126 2.4138126\n",
            " 1.7138126 2.4138122 1.7138126 1.7138126 1.7138126 1.7138126 2.4138083\n",
            " 2.3873022 1.7138126 2.4138124 1.7138126 2.413811  2.413786  2.4138126\n",
            " 2.4138122 1.7138126 1.7138126 1.7138126 1.7138126 2.4137948 2.4130025\n",
            " 1.7138126 2.4138122 1.7138126 1.7138126 2.4138126 1.7138126 1.7138126\n",
            " 1.7138126 2.4138126 2.4138126 1.7138126 1.7138126 1.7138126 1.7138126\n",
            " 2.4091036 2.4138117 2.4137373 1.7138126 1.7138126 1.713862  1.71648\n",
            " 2.4138126 1.7138126 1.7138126 1.9346571 2.4138126 1.7138126 1.7138126\n",
            " 2.4138126 2.3925455 2.4138126 2.2997773 2.4095807 1.7138131 2.4138126\n",
            " 2.4138126 1.7138126 1.7138126 1.7138126 1.7138126 1.7138126 2.4138126\n",
            " 2.4137018 2.4138126 2.4138126 1.7138152 2.4138126 1.7138126 2.4138126\n",
            " 1.7138126 2.4138126 2.4137444 1.7138126 2.4137998 1.7138126 1.7138126\n",
            " 2.4138126 1.7138126 1.7138126 2.413428  1.7138786 2.4137936 1.7138126\n",
            " 2.413812  1.7138126 2.4138126 1.7138126 1.7138126 1.7138126 2.4138126\n",
            " 1.7138126 1.7138133 2.038813  2.4138126 2.3942528 1.7138126 1.7138126\n",
            " 2.3474581 2.4138126 1.7138126 2.4133437 2.4136627 1.7138126 1.8931963\n",
            " 2.3925874 2.4138126]\n",
            "Step 300, Loss: [1.713795  1.713795  1.713795  2.413189  1.7138169 1.713795  1.713795\n",
            " 1.713795  1.713795  2.413795  1.713795  1.7138245 1.713795  1.713795\n",
            " 2.413795  1.713795  2.413795  1.713795  1.713795  1.713795  2.413795\n",
            " 1.713795  2.4137936 1.713795  2.4137948 2.3874767 1.713795  1.713795\n",
            " 1.713795  2.413795  2.413795  1.713795  2.413735  2.4137638 2.413795\n",
            " 1.713795  1.713795  2.413795  1.713795  2.4137738 2.3874753 1.713795\n",
            " 1.713795  2.4137883 1.9771991 2.413795  1.713795  1.713795  2.413795\n",
            " 2.4135337 1.713795  1.713795  1.713795  2.413795  2.413795  2.3971713\n",
            " 1.713795  2.413795  1.713795  2.413794  1.713795  1.713795  1.713795\n",
            " 1.713795  1.713795  1.713795  1.713795  2.413795  2.413795  2.4115677\n",
            " 1.713795  1.713795  2.0181527 1.713795  1.713795  1.713795  1.7137952\n",
            " 1.713795  1.713795  2.413795  2.3686345 1.713795  1.713795  1.713795\n",
            " 1.713795  2.413795  1.713795  2.413795  1.713795  1.713795  2.4137936\n",
            " 1.713795  1.713795  1.713795  1.713795  1.713795  1.713795  1.7142589\n",
            " 1.72192   1.713795  1.713795  2.4137945 1.7140946 1.713795  1.713795\n",
            " 2.413795  2.4137783 1.713795  1.713795  1.7137973 1.713795  2.4137945\n",
            " 1.713795  1.7137964 1.713795  1.713795  1.713795  2.413795  2.4128647\n",
            " 2.413795  1.714067  2.3775058 2.413795  1.7145221 1.7137957 2.4137948\n",
            " 1.713795  2.4137883]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6087 - loss: 11.5579\n",
            "Validation loss: 11.70421314239502, Validation accuracy: 0.6116999983787537\n",
            "Epoch 5/5\n",
            "Step 0, Loss: [1.713793  1.7137911 1.7137911 1.7137911 1.7137911 1.7137911 1.7273343\n",
            " 1.7137911 1.7137911 2.3968272 1.7137911 1.7137911 1.7137911 2.4137912\n",
            " 1.7137911 2.4137912 1.7137911 1.7226257 2.4137878 2.3199883 2.4137862\n",
            " 2.4137912 1.7137911 1.7137911 2.4137907 1.7137911 1.7137911 2.4137912\n",
            " 2.3257585 2.4137912 1.7137911 1.7137911 1.7137911 1.7137911 1.7137911\n",
            " 2.4137862 2.355733  1.7137911 2.294066  2.41379   1.7137911 1.7137911\n",
            " 2.4136956 1.7137911 1.7137926 1.7137911 1.7137911 2.4137912 1.7164929\n",
            " 2.4135652 2.4137912 2.4137912 1.7137911 2.4137912 1.7137911 2.410777\n",
            " 1.7173522 2.3977933 1.7137911 2.4137912 1.7137911 1.7137911 1.7137911\n",
            " 2.3843458 1.7137911 1.7137911 1.7137923 1.7137911 1.7137911 1.7137911\n",
            " 2.4137907 1.7137911 1.713792  1.713794  2.4137912 2.148438  1.7137911\n",
            " 1.7137911 2.413785  1.7467961 1.7140338 2.4137912 1.7137911 1.7137913\n",
            " 2.4137912 1.7137911 2.4118676 1.7137911 1.7137911 1.9077398 2.4137912\n",
            " 2.4137833 1.7137911 1.7137911 2.3054566 2.4085324 1.7137911 1.7137911\n",
            " 1.7137911 1.7137911 1.7137911 1.7827567 1.7137911 1.7137911 1.7137911\n",
            " 1.7137911 1.7137911 2.4137883 1.7137911 1.7137911 2.4137912 1.7137911\n",
            " 1.7137911 2.4137816 2.4137912 1.7137911 1.7137911 1.7137911 2.410543\n",
            " 1.7137911 1.7137911 2.33035   1.7137911 2.4137888 1.7137911 1.7137911\n",
            " 2.4137852 1.7137911]\n",
            "Step 100, Loss: [1.7137961 1.7137961 2.413796  1.7138358 1.7137961 1.7137961 1.7137961\n",
            " 1.7137961 1.7137961 1.7137961 2.413796  1.7288021 2.3751004 1.7137961\n",
            " 2.413796  2.3513312 2.413796  1.7137961 1.7137961 2.413796  1.7137961\n",
            " 1.7137961 1.7137961 1.7137961 1.7137961 2.412971  1.7142851 2.413796\n",
            " 1.7137961 1.8438147 1.7137961 1.7137961 2.4136467 1.7137961 1.7137961\n",
            " 1.7138752 2.356913  1.7145028 1.7137961 1.7137961 1.7137961 1.7137961\n",
            " 1.7137961 1.7137961 1.7159065 1.7137961 1.7137961 2.413796  1.7137961\n",
            " 1.7137961 1.7137961 1.7137961 1.7137961 1.7137961 1.7137963 2.413796\n",
            " 2.413796  2.413796  1.7137961 1.7137961 2.413796  1.7137961 1.7137961\n",
            " 1.7137961 1.7137961 1.7137961 1.7137961 2.4137423 1.7137961 1.7137961\n",
            " 1.7137961 1.7137965 1.7138493 1.7137961 2.410533  2.4060247 1.7137961\n",
            " 1.7137961 1.7189178 1.7139249 1.7137961 2.4137456 1.7137961 1.7137961\n",
            " 2.3878741 1.7137961 1.7137961 1.7137961 1.7137961 1.7137961 2.3897076\n",
            " 2.4137378 1.7137961 1.7137961 2.413796  1.7137961 1.7149692 1.7137961\n",
            " 2.413794  2.4101067 1.7137961 1.7140568 2.413796  1.7137961 1.7137961\n",
            " 1.7137961 1.7137961 1.7137961 2.4137816 2.4137952 1.7239102 2.413796\n",
            " 1.7509373 1.7137961 1.7137961 2.413796  1.7137961 1.7137961 1.7137961\n",
            " 2.413796  1.7137961 2.4137154 1.7137961 1.7138737 1.7137961 2.0397434\n",
            " 1.7137961 2.413796 ]\n",
            "Step 200, Loss: [1.713791  1.713791  2.413791  1.7138038 2.4137073 2.413791  2.4136794\n",
            " 2.4134393 1.713791  1.713791  1.713791  1.713791  1.713791  1.713791\n",
            " 2.413791  1.713791  1.713791  2.4137723 1.713791  1.713791  2.413791\n",
            " 1.713791  1.713791  1.713791  1.713791  1.713791  2.3107338 1.8069065\n",
            " 2.2304459 1.713791  2.413791  1.713791  1.713791  1.713791  2.413791\n",
            " 2.413791  1.816473  2.413791  1.713791  1.713791  2.3913088 2.413791\n",
            " 1.713791  2.4137828 1.713791  1.713791  1.713791  1.713791  1.713791\n",
            " 1.7137966 2.4131813 2.4137785 1.713791  1.713791  1.713791  1.713791\n",
            " 2.413784  2.413791  2.413791  1.713791  2.413791  1.7139212 2.4136326\n",
            " 2.4137907 1.713791  1.713791  1.713791  2.413791  2.413791  1.713791\n",
            " 2.413791  2.4137907 1.713844  2.413791  1.7411234 2.4133756 2.4137735\n",
            " 2.413791  1.713791  1.713791  1.7141525 1.713791  1.713791  2.4134572\n",
            " 1.7150391 2.413791  2.4137893 1.7466226 2.413791  2.3445354 1.713791\n",
            " 1.713791  2.4135933 1.7138227 1.713791  1.713791  1.713791  1.713791\n",
            " 2.413791  2.413791  1.713791  2.4137855 1.7137988 2.413789  1.713791\n",
            " 1.713791  1.7151462 2.3878675 1.713791  1.713791  1.713791  2.3233366\n",
            " 1.713791  1.713791  1.713791  1.713791  2.1843977 1.713791  1.713791\n",
            " 1.7137914 1.7175254 1.713791  2.4137468 2.397665  1.713791  1.714546\n",
            " 1.7446839 2.413791 ]\n",
            "Step 300, Loss: [1.7137899 1.7137899 1.7137899 2.3276563 2.408064  1.7137899 2.4137897\n",
            " 1.7137899 1.7137899 1.7138197 1.7137899 1.7148759 1.7137899 1.7137899\n",
            " 2.4137864 1.7137899 1.7137899 1.7137899 1.7137899 1.7137902 1.7137899\n",
            " 1.7137899 2.4135873 1.7137899 2.4137897 1.9088784 1.7137899 1.7137899\n",
            " 2.4136972 2.4137897 2.4137897 2.4137897 1.7137902 1.7137899 2.4137897\n",
            " 1.7137899 1.7137899 2.4137897 1.7137899 2.4134445 2.4135885 1.7137899\n",
            " 1.7137899 2.391937  1.7137899 2.4137702 2.3986144 1.7137899 1.8049333\n",
            " 1.7137976 1.7137899 1.7137899 1.7137899 2.4137368 2.4137897 2.4136164\n",
            " 1.7137899 2.4137897 1.7137899 2.4137864 1.7137899 1.7137899 1.7137899\n",
            " 1.7137899 1.7137899 1.714351  1.7137899 1.7137899 2.4137876 2.4137897\n",
            " 1.7137899 1.7137899 1.7407593 1.7137899 1.7137899 1.7137899 1.7137899\n",
            " 1.7137899 1.7137899 2.4137897 2.4137897 1.7137899 1.7137899 1.7137899\n",
            " 2.4137897 2.4137897 1.7137899 2.4137897 1.7137899 1.7137899 2.4137897\n",
            " 1.7137899 1.7137899 1.7137899 1.7137899 1.7137899 2.4048538 2.4136622\n",
            " 1.9580728 1.7137899 1.7137899 1.7137899 1.7137903 1.7376035 1.7137915\n",
            " 1.9044968 1.7137899 1.7137899 1.7137899 2.4137897 1.7137899 2.4137897\n",
            " 1.7137899 1.7137914 1.7137899 1.7137899 1.7137903 2.3953867 2.4137893\n",
            " 2.4061813 1.7139246 2.4137897 1.7137899 1.7137899 2.4118478 1.7137899\n",
            " 1.7137899 1.714608 ]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5936 - loss: 10.5580\n",
            "Validation loss: 10.587228775024414, Validation accuracy: 0.5978000164031982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = student_model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhDezdkXDnie",
        "outputId": "c3f59ace-aaae-4307-e971-de88086c5ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5935 - loss: 10.5727\n",
            "Test accuracy: 0.5978000164031982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for step in range(len(x_train) // batch_size):\n",
        "        x_batch = x_train[step * batch_size:(step + 1) * batch_size]\n",
        "        y_batch = y_train[step * batch_size:(step + 1) * batch_size]\n",
        "        soft_batch = soft_targets[step * batch_size:(step + 1) * batch_size]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = student_model(x_batch, training=True)\n",
        "            loss_value = distillation_loss(y_batch, logits, soft_batch, alpha=0.3, temperature=4.0)\n",
        "\n",
        "\n",
        "        grads = tape.gradient(loss_value, student_model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss_value.numpy()}\")\n",
        "\n",
        "\n",
        "    val_loss, val_acc = student_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwBMncalD4D4",
        "outputId": "bebf83d2-f20a-407b-c5f1-caa9fa168653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Step 0, Loss: [2.4088206 1.7140993 1.7140993 1.7140993 1.7140993 1.7140993 1.7140993\n",
            " 1.7140993 1.7140993 2.2779646 1.7140993 1.7140993 2.4140992 2.4134998\n",
            " 1.7140993 2.4140992 1.7140993 1.7140998 2.4140992 1.7140993 2.4140375\n",
            " 2.4096417 1.7140993 1.7140993 1.7140993 1.7140993 1.7140993 2.4140577\n",
            " 1.7140993 2.4140992 1.7140993 1.7140993 1.7140993 1.7187226 1.7141179\n",
            " 2.4140868 1.7140993 1.7140993 1.8482829 2.4140992 1.7140993 1.7141109\n",
            " 1.7161999 1.7140993 1.7140993 1.7140993 1.7140993 2.4140992 2.4138803\n",
            " 1.7812616 2.4140992 2.4140992 2.2095802 2.4140992 1.7140993 2.4124918\n",
            " 1.7140993 1.7140996 2.4140992 2.4140973 1.7140993 2.4140992 1.7140993\n",
            " 2.4140987 1.7140993 1.7140993 1.714603  1.7140993 1.7140993 1.7140993\n",
            " 2.4140992 1.7140993 1.7140995 1.7144701 2.4140992 1.7140993 1.7140993\n",
            " 1.7140993 2.4140167 2.4107099 1.7148895 2.4140992 1.7140993 1.7140993\n",
            " 2.4140325 1.7140993 1.7140996 1.7140993 1.7140993 2.4140396 2.4140968\n",
            " 2.4047642 1.7140993 1.7140993 2.4136152 1.7140993 1.7140993 2.4140992\n",
            " 1.7140993 1.7140993 1.7140993 1.7140993 1.7140993 1.7140993 1.7140993\n",
            " 1.7140993 1.7140993 1.7140994 1.8244512 1.714349  2.4140987 1.7140993\n",
            " 1.7140993 2.4140992 2.4140992 1.7140993 1.7140993 1.7140993 1.7140993\n",
            " 1.7140993 1.7140993 1.7143365 1.7140993 2.39647   1.7140993 1.7140993\n",
            " 2.41396   1.7140993]\n",
            "Step 100, Loss: [1.7141092 1.7141092 2.414105  2.4139931 1.7141092 1.7141092 1.7141092\n",
            " 1.7141092 1.7141092 1.7141104 2.4141066 2.4140096 2.4138253 1.7141092\n",
            " 2.414109  1.7141092 2.414109  1.7141092 2.414109  2.414109  1.7208796\n",
            " 1.7141092 1.7141092 1.7141092 1.7141092 2.3935213 2.3792248 1.7141092\n",
            " 1.7141092 1.7141092 1.7141092 1.7141092 2.414109  1.7141092 1.7141092\n",
            " 1.7141092 1.7141092 1.7141092 1.7141092 1.7141092 1.7141092 1.7141092\n",
            " 1.7141092 1.7141092 1.7141092 1.7141092 1.7141092 2.414109  1.7141092\n",
            " 1.7141092 1.7141092 1.7141092 1.7141092 1.7141092 1.7141092 2.414109\n",
            " 2.414109  2.414109  1.7141092 1.7141092 2.414109  1.7141092 1.7141092\n",
            " 1.7141092 1.7141092 2.414109  1.7141092 2.414109  1.7141092 1.7141092\n",
            " 1.7141092 2.4096384 1.7141244 1.7141092 2.414019  2.414109  1.7141092\n",
            " 1.7141092 2.414109  1.7141092 1.7141092 2.414109  1.7141092 1.7141092\n",
            " 1.7141097 1.7141092 2.4138517 1.7141092 1.7141092 1.7141092 2.4141033\n",
            " 2.414109  1.7141092 1.7141092 2.129764  1.7141092 1.7141092 1.7141092\n",
            " 2.4140987 2.4141083 1.7141092 2.4136965 1.7141092 1.7141092 1.7141092\n",
            " 1.7141092 1.7141092 1.7141092 2.414109  2.4082527 2.414109  2.3750253\n",
            " 2.414103  1.7141538 1.7141092 2.414109  1.7141092 1.7141092 1.7141092\n",
            " 1.7141092 1.7141092 1.7141092 1.7141092 2.4134374 1.7141092 1.7141092\n",
            " 1.7141092 2.414109 ]\n",
            "Step 200, Loss: [1.7141055 1.7141055 2.4141054 2.4141054 2.4141052 2.4085937 2.4141018\n",
            " 2.4141054 1.7141055 1.7141055 1.7141055 1.7141055 1.7141055 1.7141055\n",
            " 1.7141055 1.7141055 1.7141055 2.4141054 1.7141055 1.7141055 2.4141054\n",
            " 2.4137769 1.9094226 1.7141055 1.7141055 1.7141055 2.4141054 1.7141085\n",
            " 1.785912  1.7141055 2.4141054 1.7141055 1.7141055 1.7141055 2.4141054\n",
            " 2.4141054 1.7141055 2.401525  1.7141055 1.7141055 2.407898  2.4141054\n",
            " 1.7141055 2.4135895 1.7141055 1.7141055 1.7141055 1.7141055 1.7141055\n",
            " 1.7141055 2.414105  2.4141054 1.7141055 1.7141055 1.7141055 1.7141055\n",
            " 2.4141054 2.4141054 2.4141054 1.7141055 1.7141055 1.7162081 2.4139657\n",
            " 2.4141054 1.7141055 1.7141055 1.7141055 2.4140341 1.7141055 1.7141055\n",
            " 2.4141054 1.9617832 1.7141055 1.7141355 1.7141055 1.7141055 2.4141002\n",
            " 2.4141054 1.7141055 1.7141055 2.403121  1.7141055 1.7141055 2.414098\n",
            " 1.9145101 1.7141055 2.4141054 1.813035  2.4141054 1.7141055 2.4139032\n",
            " 1.7141055 2.4141054 2.4139802 1.7141055 1.7141055 1.7141055 1.7141055\n",
            " 2.4140944 2.413774  1.7141055 2.409904  1.7141055 2.4141002 1.7141055\n",
            " 1.7141055 1.7141055 2.414105  1.7141055 1.7141055 1.7141055 2.4141054\n",
            " 1.7141055 1.7141055 1.7141055 1.7141064 2.414105  1.7141055 1.7141055\n",
            " 1.7141055 1.7157265 1.7141055 2.4141054 1.7141055 1.7141055 1.7141055\n",
            " 2.4133725 2.4141054]\n",
            "Step 300, Loss: [1.7140813 1.7140813 1.7140813 1.7185725 2.4132452 1.7140813 2.414081\n",
            " 1.7140814 1.7140813 1.7140813 1.7140813 1.7140824 2.414081  1.7140813\n",
            " 2.4118156 1.7140814 1.7140813 1.7140813 1.7140813 1.7140856 1.7140813\n",
            " 1.7140813 2.414081  1.7140816 2.4114976 2.414081  1.7140813 1.7140813\n",
            " 2.414081  2.414081  2.414081  2.4140801 2.2690136 1.7140813 2.414081\n",
            " 1.7140813 1.7140813 2.414081  1.7140813 2.4079494 2.3314564 1.7140813\n",
            " 1.7140813 1.7140813 1.7140813 1.7140814 1.7140813 1.7140813 1.7140813\n",
            " 1.7140813 1.7140813 1.7140813 1.7140813 2.414081  2.414081  2.414081\n",
            " 1.7140813 2.414081  1.7140813 2.414081  1.7140813 1.7140813 1.7140813\n",
            " 1.7140813 1.7140813 1.7140813 1.7140813 1.7140813 1.7141857 2.414081\n",
            " 2.3711395 1.7140813 2.0774817 1.7140813 1.7140813 1.7140813 1.7140813\n",
            " 1.7140813 1.7140813 2.4140778 2.4140801 1.7140813 1.7140813 1.7140813\n",
            " 1.7140813 2.414081  1.7140813 2.414081  1.7140813 1.7140813 2.414081\n",
            " 1.7140813 1.7140813 1.7140813 1.7262274 1.7140813 1.7140813 2.4140801\n",
            " 2.414081  1.7140813 1.7140813 1.7140813 1.7140813 2.4139194 1.7140813\n",
            " 2.4134443 1.7140813 1.7140813 1.7140813 2.414081  1.7140813 2.414081\n",
            " 1.7140813 1.7140816 1.7140813 1.7140813 1.7140813 2.414081  2.4130855\n",
            " 2.4139628 1.7140813 2.414081  2.4140744 1.7140813 1.7140813 1.7140813\n",
            " 1.7140813 2.1036696]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6531 - loss: 9.7132\n",
            "Validation loss: 9.69802188873291, Validation accuracy: 0.6542999744415283\n",
            "Epoch 2/5\n",
            "Step 0, Loss: [2.4140835 1.7140834 1.7140834 1.7140834 1.7140834 2.4140835 2.4140835\n",
            " 1.7140834 1.7140834 2.4139767 1.7140834 1.7140834 2.4140835 2.414083\n",
            " 1.7140834 2.4140835 1.7140834 1.7141808 2.3884816 1.7140834 2.4140706\n",
            " 2.4139683 1.7140834 1.7140834 1.7140834 1.7140834 1.719669  1.969916\n",
            " 1.7140834 2.4140835 1.7140834 1.7140834 1.7140834 1.7140834 1.9136813\n",
            " 2.4140835 2.0339522 1.7140834 1.7140945 2.4140835 1.7140834 1.7140834\n",
            " 1.7140834 1.7140834 1.7140834 2.4140835 1.7140834 2.4140835 1.7140834\n",
            " 1.7140834 2.4140835 2.4140835 1.7140834 2.4140835 1.7140834 2.414078\n",
            " 1.7140834 1.7141005 1.7140834 2.4140835 1.7140834 2.4140835 1.7140834\n",
            " 1.7140976 1.7140834 1.7140834 1.7140834 1.7140834 1.7140834 1.7140834\n",
            " 2.4140835 1.7140834 1.7141633 1.7140834 2.4140782 1.7140834 1.7140834\n",
            " 1.7140834 2.4140563 2.4140835 1.714095  2.2332683 1.7140834 1.7140843\n",
            " 2.4140835 1.7631382 1.7140834 1.7140834 1.7140834 1.7140838 2.4140835\n",
            " 2.4140835 1.7140834 1.7140834 2.4140706 1.7140837 1.7140834 1.7140834\n",
            " 1.7140834 1.7208937 1.7140834 1.7140836 1.7140834 2.4140835 1.7140834\n",
            " 1.7140834 1.7140834 2.4140835 1.7140834 2.4140835 2.4140835 1.7183471\n",
            " 1.7140834 2.4140835 2.4140835 1.7140834 1.7140838 1.7140834 1.7140834\n",
            " 1.7140834 1.7140834 1.7140834 1.7140834 2.4140835 1.7140834 1.7140834\n",
            " 1.7161025 1.7140834]\n",
            "Step 100, Loss: [1.7140796 1.7140796 2.3885088 1.7140796 1.7140796 1.7140797 1.7140796\n",
            " 1.7140796 1.7140796 1.7140796 2.4140797 1.7465802 2.3016138 1.7140796\n",
            " 2.4140797 2.40619   2.4140797 1.7140796 1.7140796 2.4140797 1.7140796\n",
            " 1.7140796 1.7140796 1.7545927 1.7140796 2.398371  2.4140778 1.7140796\n",
            " 1.7140796 1.7140796 1.7140796 1.7140796 2.4140797 1.7140796 1.7140796\n",
            " 1.7140796 1.7343392 2.4140763 2.4140797 1.7140796 1.7140796 1.7140796\n",
            " 1.7140796 1.7140796 1.7140796 1.7140796 1.7140796 2.4140792 1.7140888\n",
            " 1.7140796 1.7140796 1.7140796 2.4136214 1.7141445 2.1631498 2.4140797\n",
            " 1.7140796 2.4140797 1.7140796 1.7140796 2.4100914 1.7140796 1.7140796\n",
            " 1.7140796 1.7140796 1.7470797 1.7140796 2.4140792 1.7140796 1.7170868\n",
            " 1.7140796 2.4140754 2.3691626 1.7140796 2.4139578 2.3915248 1.7140796\n",
            " 1.7140796 2.4140797 1.7140796 1.7140796 2.4140797 1.7140796 1.7140796\n",
            " 1.7140796 1.7140797 2.4140797 1.7140796 1.7140796 1.7140796 2.4140778\n",
            " 2.4140797 1.7140796 1.7140796 1.7140796 1.7140796 1.7140796 2.3319297\n",
            " 2.4140797 2.4140615 1.7140796 2.41401   1.7140796 1.7140796 2.4140792\n",
            " 1.7140796 2.3270273 1.7140796 2.4140797 2.4140797 2.4140797 1.7140796\n",
            " 1.7140802 1.7140796 1.7140796 2.4140797 1.7140796 1.7140796 1.7140796\n",
            " 2.4140797 1.7140796 1.7140796 1.7140797 2.4140797 1.7140796 1.7140796\n",
            " 1.7140796 2.4140797]\n",
            "Step 200, Loss: [1.7140973 1.7140973 2.414094  2.0250864 2.4140973 2.4140973 1.7141378\n",
            " 1.7144089 1.7140973 1.7140973 1.7140973 1.7140973 1.7140973 1.7140973\n",
            " 2.4140973 1.7140973 1.7140973 2.4140973 1.7140973 1.7140973 2.4140973\n",
            " 1.7140973 1.7189801 1.7140973 1.7140973 1.7140973 1.7140973 2.4030037\n",
            " 1.7163813 1.7140973 1.7140973 1.7140973 2.4138334 1.7141097 2.4096384\n",
            " 2.4140134 2.4140973 2.4140973 1.7140973 1.7140973 2.4140973 2.3987694\n",
            " 2.2179554 2.4140894 1.7140973 1.7140973 2.4132953 1.7140973 1.7140973\n",
            " 2.3798923 2.4140904 2.4140973 1.7140973 1.7140973 1.7140973 1.7140973\n",
            " 2.4140973 2.4140973 1.7140973 1.7140973 2.4140973 1.7140989 2.4140315\n",
            " 2.4140973 1.7140973 1.7140973 2.4140973 2.4140973 1.7140973 1.7140973\n",
            " 2.4140973 1.7140973 1.7140973 1.7140973 1.7140973 1.7140973 2.4139123\n",
            " 2.4140973 1.7140973 2.413225  1.7279611 1.7140973 1.7140973 1.7153978\n",
            " 2.3161082 2.4140973 2.3966937 1.7140973 2.4139855 1.7140973 1.7140975\n",
            " 1.7140973 2.4136784 1.7140973 1.7140973 1.7140973 1.7140973 1.7140973\n",
            " 2.4138    2.4140973 2.4140973 2.4140897 2.4140973 2.4140973 1.7140973\n",
            " 2.3652556 1.7140973 2.414081  1.7140973 1.7140973 2.4140973 2.4140973\n",
            " 1.7140973 1.7140973 1.7140973 2.4140973 2.4140973 1.7140973 1.7140973\n",
            " 1.7140973 2.2132215 1.7140973 2.414096  2.4140973 1.7140973 1.7140973\n",
            " 1.714109  2.4139614]\n",
            "Step 300, Loss: [1.9635288 1.7141765 1.7140738 2.406541  2.41303   1.7140738 2.4140737\n",
            " 1.7140738 1.7140738 1.7140738 1.7140738 1.714074  1.7759248 1.7140738\n",
            " 2.4139433 1.7140738 1.7140738 1.7140738 1.7140738 2.4140737 1.7140738\n",
            " 2.3594856 2.4140718 1.7141172 2.4140587 2.4140737 1.7140738 1.7140738\n",
            " 1.7140738 2.4138148 1.7140738 1.7140738 1.7140739 2.3966851 2.4140737\n",
            " 1.7140738 1.7140738 2.1128044 1.7140738 1.8372247 2.3678625 1.7140738\n",
            " 1.7140738 1.7140738 1.7160163 2.413968  1.7140738 1.7140738 2.403041\n",
            " 1.7140738 1.7140738 1.7140738 1.7140738 1.7140738 2.4140737 2.411199\n",
            " 1.7140738 2.4140737 1.7140738 2.4140444 2.4140737 1.7140738 1.7140738\n",
            " 1.7140738 1.7140738 1.7140738 1.7140738 1.7140738 1.7165737 2.4140737\n",
            " 1.7140738 1.7140738 1.7145169 1.7140738 1.7140738 1.7140738 1.7140738\n",
            " 1.7140738 1.7140738 2.4139066 2.4140737 1.7140738 1.7140738 1.7140738\n",
            " 2.4140737 2.4140737 1.7140744 2.4140737 1.7140745 1.7140738 2.4140544\n",
            " 1.7140738 1.7140738 1.7140738 1.7140738 1.7140738 1.7140747 1.7140738\n",
            " 2.4140701 1.7140738 1.7140738 1.7140738 1.7140738 1.7140738 1.7140738\n",
            " 1.7140738 1.7140738 1.7140738 1.7140738 2.4140735 1.7140738 2.4140737\n",
            " 1.7140738 1.7140741 1.7140738 1.7140738 1.7140738 2.414021  2.2471943\n",
            " 2.4140737 1.7140738 2.4140737 2.4140737 1.7140738 1.714075  1.8907367\n",
            " 1.7140738 1.7140738]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6465 - loss: 10.4507\n",
            "Validation loss: 10.633200645446777, Validation accuracy: 0.6445000171661377\n",
            "Epoch 3/5\n",
            "Step 0, Loss: [2.3694906 1.7140647 1.7140647 1.7140647 1.7140647 2.4140646 1.7140648\n",
            " 1.7140647 1.7140647 1.7152797 1.7140647 1.7140647 2.4140646 1.7161199\n",
            " 2.4114063 2.4140646 1.7140647 1.7140651 2.4140646 1.7140647 1.7140648\n",
            " 1.7143624 1.7140647 1.7140647 1.7140651 1.7140647 1.7140647 2.3876348\n",
            " 1.7140647 2.4140646 1.7140647 1.7140647 1.7140647 1.7475165 1.7140647\n",
            " 2.4140646 1.919554  1.7140647 2.411677  2.4140646 1.7140647 1.7140647\n",
            " 1.7189479 1.7140647 1.7962885 1.7140647 1.7140647 2.4140646 1.7140647\n",
            " 1.7140647 2.3972735 2.4140646 1.7140647 2.4140646 1.7140647 2.4140646\n",
            " 2.2005134 1.7140664 2.414063  1.7354616 1.7140647 1.7140647 1.7140647\n",
            " 1.7140647 1.7140647 1.7140647 1.7140647 1.7140647 1.7140647 1.7140647\n",
            " 2.4140646 1.7140647 2.4132154 2.2231174 2.4140153 1.8043125 1.7140647\n",
            " 1.7140647 2.4140646 1.9075652 1.9122107 2.4140646 1.7140647 1.7152144\n",
            " 2.4069138 2.4140615 1.7140647 1.7140647 1.7140647 1.7162833 2.413197\n",
            " 2.4140646 1.7140647 1.7140647 2.4140644 1.7140647 1.7140647 1.7140647\n",
            " 1.7140647 1.7140647 1.7140647 1.7154305 2.4139872 1.7140647 1.7140647\n",
            " 1.7140647 1.7140647 2.4117723 1.7140647 1.7140647 2.4134958 1.7140647\n",
            " 1.7140647 2.4140646 2.4140646 1.7140647 2.4134686 1.7140647 1.7140647\n",
            " 1.7140647 1.7140647 1.7140797 1.7140647 2.4140646 1.7140647 1.7140647\n",
            " 2.4140646 1.7140647]\n",
            "Step 100, Loss: [1.7140883 1.7140949 2.4140882 1.7140883 1.7140883 1.7140883 1.7140883\n",
            " 1.7140883 1.7140883 1.7140883 1.7145041 2.4140859 2.3949454 1.7140883\n",
            " 2.4140882 2.4140882 2.4140882 1.7140883 2.411461  2.4140882 1.7142458\n",
            " 2.407744  1.7140883 1.7140883 1.7140883 2.4074585 2.4140882 1.7140883\n",
            " 1.7140883 1.7140883 1.7140883 1.7140883 2.4140882 1.7140883 1.7140883\n",
            " 2.4140882 1.7153996 2.4140816 1.7140896 1.7140883 1.7140883 1.7140883\n",
            " 1.7140883 1.7140883 1.7140956 1.7140883 1.7140883 2.4140882 1.7140883\n",
            " 1.7140883 1.7140883 1.7140883 1.7140883 1.7140883 1.7141517 2.4140882\n",
            " 2.4140882 2.4140882 1.7140883 1.7140883 1.7140883 1.7140883 1.7140883\n",
            " 1.7140883 1.7140883 1.7140883 1.7140883 2.4134827 1.7140883 1.7140883\n",
            " 1.7140883 2.4140882 1.7140883 1.7140883 2.4140882 2.3849475 1.7140883\n",
            " 1.7140883 2.4140878 1.7140883 1.7140883 2.4140882 1.892532  1.7140883\n",
            " 1.7141112 1.7140883 1.7141453 1.7140883 1.7140883 1.7140883 2.413021\n",
            " 2.4090033 1.7140883 1.7140883 1.7140883 1.7140883 1.7140883 1.7140883\n",
            " 2.4140882 2.4140344 1.7140883 2.4140658 1.7140883 1.7140883 2.4140882\n",
            " 1.7140883 1.7140883 1.7140883 2.4140882 2.4140882 2.4140882 2.02386\n",
            " 1.7141056 1.7140883 1.7140883 2.4134107 1.7140883 1.7140883 1.7140883\n",
            " 2.4140882 1.7140883 1.7140883 1.7140883 2.4140882 1.7140883 1.7140883\n",
            " 1.7140883 2.414088 ]\n",
            "Step 200, Loss: [1.7140843 1.7140797 2.4140797 1.7140806 2.4140759 2.4140797 1.7155037\n",
            " 2.4140797 1.7140797 1.7140797 1.7140797 2.4140797 1.7140797 1.7140797\n",
            " 2.4140797 1.7140797 1.7140797 2.4140797 1.7140797 2.4140797 2.4140797\n",
            " 1.7140797 2.2041166 1.7140797 1.7140797 1.7140797 1.7140797 2.4140794\n",
            " 2.4140797 1.7140797 2.4140797 1.7140797 1.7140797 1.7140797 2.4140797\n",
            " 2.4140797 1.7140797 2.4140797 1.7140797 1.7140797 2.4100206 2.0481884\n",
            " 1.7140797 2.4140544 1.7212687 2.4133353 1.7140797 1.7140797 1.7140797\n",
            " 1.7140803 2.368216  2.4140797 1.7140797 1.7140797 1.7140797 1.7140797\n",
            " 2.4099636 2.4133587 1.7143968 1.7140797 2.3915896 1.7147287 2.4140797\n",
            " 2.4140797 2.4140046 1.7140797 1.7140797 2.4140472 2.4140797 1.7140797\n",
            " 2.4139464 1.7140797 1.7140797 1.7140797 2.41309   1.7140797 2.4140787\n",
            " 2.4140797 1.7140797 1.7140797 1.7140797 1.7140797 1.7140797 2.4140797\n",
            " 2.414068  2.4140797 2.4065137 1.7140797 2.4140797 2.1735866 2.412809\n",
            " 1.7140797 2.4140773 2.4140797 1.7140797 1.7140797 1.7140797 1.7140797\n",
            " 2.3872218 1.7141651 1.7140797 2.4140782 1.7149166 2.4140797 1.7140797\n",
            " 1.7140797 2.4140797 2.4140677 1.7140797 1.7140797 1.7162197 2.4140792\n",
            " 1.7140797 1.7140797 1.7140797 1.7140799 2.4140797 1.7140797 1.7140797\n",
            " 1.7140797 2.4140797 1.7140797 2.4140797 1.7140797 1.7140797 1.7140797\n",
            " 2.338784  2.379457 ]\n",
            "Step 300, Loss: [1.714076  1.714076  1.714076  2.4089315 2.414076  2.361817  2.414076\n",
            " 1.714076  1.714076  1.7146211 1.714076  1.7146766 1.714076  1.714076\n",
            " 2.414076  2.4140427 1.714076  1.714076  1.714076  1.714076  2.414076\n",
            " 1.714076  2.414076  1.7140772 2.4140756 2.414076  1.714076  1.714076\n",
            " 2.4140754 2.414072  1.714076  2.414076  2.4139888 1.714076  2.414076\n",
            " 1.714076  1.714076  1.7334013 1.7140803 1.7194691 2.3960192 2.4055834\n",
            " 1.714076  1.714076  1.714076  2.4140759 1.714076  1.714076  2.414076\n",
            " 1.714076  1.714076  1.714076  1.714076  2.414076  2.414076  2.4136343\n",
            " 1.714076  2.3862092 1.714076  2.414075  1.714076  1.714076  1.714076\n",
            " 1.714076  1.714076  1.714076  1.714076  2.414076  1.787627  2.4138062\n",
            " 1.714076  1.714076  1.7141998 1.714076  1.714076  1.714076  1.714076\n",
            " 1.714076  1.714076  2.4140754 2.4031842 1.714076  1.714076  1.714076\n",
            " 1.714076  2.4136877 1.714076  2.414076  1.714076  1.714076  2.414076\n",
            " 1.714076  1.714076  1.714076  2.414076  1.714076  1.7178869 2.1225333\n",
            " 2.3919437 1.714076  1.714076  1.714076  1.714076  2.40637   1.7191179\n",
            " 2.4140704 2.414076  1.714076  1.714076  1.714076  1.714076  2.414076\n",
            " 1.714076  1.714076  1.714076  2.414076  1.714076  2.414076  1.7362232\n",
            " 2.4008179 1.7142262 1.7140794 1.8821442 1.714076  1.714076  1.714076\n",
            " 1.714076  2.061619 ]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6546 - loss: 9.5012\n",
            "Validation loss: 9.642521858215332, Validation accuracy: 0.6514999866485596\n",
            "Epoch 4/5\n",
            "Step 0, Loss: [1.7140636 1.7140636 1.7140636 1.7140636 1.7140636 1.7140636 2.4140635\n",
            " 1.7140636 1.7140636 2.4140637 1.7140636 1.7140636 2.414063  2.3365738\n",
            " 1.7140636 2.4140637 1.7140636 1.7140636 2.4140582 1.7140636 2.4139569\n",
            " 1.7160087 1.7140636 1.7140636 2.414001  1.7140636 1.7140636 1.7140639\n",
            " 2.4140637 1.7431369 1.7140636 1.7140636 1.7140636 1.7140636 1.7140636\n",
            " 2.4140637 1.7140636 1.7140636 1.7559767 2.4140637 1.7140636 1.7140636\n",
            " 1.7140636 1.7140636 1.7140768 1.7140636 1.7140636 2.4140637 1.7140636\n",
            " 1.7140636 2.414057  2.4140637 1.7140636 2.4140637 1.7140636 2.4140637\n",
            " 1.714143  2.2684283 1.7140636 1.8043404 1.7140636 2.4140637 1.7140636\n",
            " 1.7420375 1.7140636 1.7140636 2.3866057 1.7140636 1.7140636 1.7140636\n",
            " 2.4140637 1.7140636 1.7140813 1.7140636 2.4135036 1.7143462 1.7140636\n",
            " 1.7140636 2.4140635 2.4140623 1.7140639 2.4140637 1.7140636 2.3003216\n",
            " 2.4140637 1.7140636 1.7140636 1.7140636 1.7140636 1.715518  2.3888278\n",
            " 1.7140636 1.7140636 1.7140636 1.7148001 1.7140636 1.7140636 1.7218919\n",
            " 1.7140636 2.4105628 1.7140636 1.7140691 1.7140636 1.7140636 1.7140636\n",
            " 1.7140636 1.7140636 1.7144353 1.7140636 2.4140637 2.4140637 1.7140636\n",
            " 1.7140636 2.4140637 2.4140637 1.7140636 1.7140799 1.7140636 1.7140636\n",
            " 1.7140636 1.7140636 2.3419862 1.7140636 2.4140637 1.7140636 1.7140636\n",
            " 1.7140636 1.7140639]\n",
            "Step 100, Loss: [1.714061  1.714061  2.4140606 1.714061  1.714061  1.714061  1.714061\n",
            " 2.3107405 1.714061  1.714061  2.414061  2.414061  1.7140613 1.714061\n",
            " 2.414061  1.9804796 2.414061  2.414061  1.714061  1.714061  1.714061\n",
            " 1.714061  1.714061  2.414061  1.714061  2.414061  2.414061  2.414061\n",
            " 2.414061  1.714061  1.714061  2.3801599 2.414061  1.714061  1.714061\n",
            " 1.714061  1.714061  1.714061  2.414061  1.714061  2.414061  1.714061\n",
            " 1.714061  1.7145501 1.7141932 1.714061  1.714061  2.4140606 1.714061\n",
            " 1.714061  1.714061  1.714061  1.714061  1.714061  1.714061  2.414061\n",
            " 2.414061  2.414061  1.714061  1.714061  2.414061  1.714061  1.714061\n",
            " 1.7512785 1.714061  2.414061  1.714061  2.414052  1.714061  1.714061\n",
            " 1.714061  2.40058   1.7142191 2.4130843 2.4140334 2.4132795 1.714061\n",
            " 1.714061  2.4068265 1.714061  1.714061  1.8262115 1.714061  1.714061\n",
            " 2.414061  2.253675  1.7449032 1.714061  1.714061  1.714061  2.4140587\n",
            " 2.0562017 1.714061  1.714061  1.714061  1.714061  1.7140627 1.714061\n",
            " 2.4138298 2.4095402 1.714061  2.3832402 2.414061  2.414061  2.4140606\n",
            " 1.714061  2.41406   1.714061  2.414061  2.4140606 2.414061  2.4034343\n",
            " 1.7148371 1.714061  1.714061  2.414061  1.714061  1.714061  1.714061\n",
            " 1.714061  1.714061  2.41406   2.4140604 1.714061  1.714061  1.714061\n",
            " 1.714061  2.414061 ]\n",
            "Step 200, Loss: [1.7140881 1.7140881 2.414088  2.3897219 2.4140878 2.414088  2.414088\n",
            " 2.4139404 1.7140881 1.7140881 1.7140881 1.7140881 1.7140881 1.7140881\n",
            " 2.414088  1.7140881 1.7140881 2.414088  1.7140881 1.7140881 2.414088\n",
            " 1.7140881 1.7141429 1.7140881 1.7140881 1.7140881 1.7140881 1.7140881\n",
            " 2.414088  1.7140881 1.7141148 1.7140881 1.7140881 1.7140881 2.414084\n",
            " 2.4140291 1.7140881 1.7140881 1.7140881 1.7140881 2.414088  2.3845987\n",
            " 1.7140881 2.414088  1.7140881 1.7140881 2.414088  2.4140878 1.7140881\n",
            " 1.7159157 2.414088  2.414088  1.7140881 1.7140881 1.7140881 1.7140881\n",
            " 2.3884964 2.414088  1.7141312 1.7140881 2.414088  1.722064  2.4140286\n",
            " 2.4140878 1.7140881 1.7140881 1.7140881 2.4139924 1.7140881 1.7140881\n",
            " 2.4140873 1.7140881 1.7140881 1.7224503 1.7140881 1.7140881 2.414088\n",
            " 2.414088  1.7140881 1.7140881 2.4082236 1.7140881 1.7140881 1.7140956\n",
            " 2.4140553 1.7140881 2.414088  2.375093  2.414088  1.7140881 2.2822278\n",
            " 1.7140881 2.408205  2.414088  1.7140881 1.7140881 1.7140881 1.7140881\n",
            " 2.414088  1.7140926 1.7140881 2.4140854 1.7140881 2.414088  1.7140881\n",
            " 1.7140913 1.7140881 2.414088  1.7140881 1.7140881 1.7140881 2.414088\n",
            " 1.7140881 1.7140881 1.7140881 1.7141602 2.4140878 1.7140881 1.7140881\n",
            " 2.414088  1.7141023 1.7140881 2.414088  2.414088  1.7140881 2.4140735\n",
            " 1.7141577 2.4129412]\n",
            "Step 300, Loss: [1.7140822 2.4135697 1.7140822 2.414079  1.7166512 1.7140822 2.4140422\n",
            " 1.7140822 1.7140822 2.414082  1.7140822 1.7140822 1.7140822 1.7140822\n",
            " 2.414082  1.7140822 1.7140822 1.7140822 1.7140822 1.7140822 1.7156751\n",
            " 1.7141633 2.414082  1.7140822 2.4140818 1.7140822 1.7140822 1.7140822\n",
            " 1.7147102 1.7440128 1.7140822 1.7140822 1.7140822 1.7140822 2.414082\n",
            " 1.7140822 1.7140822 2.3952773 1.7140822 1.7140822 1.7364564 1.7140822\n",
            " 1.7140822 1.7140822 1.7140822 1.7143586 1.7140822 1.7140822 2.414082\n",
            " 1.7140822 1.7140822 1.7140822 1.7140822 2.414082  2.414082  2.414082\n",
            " 1.7140822 2.414082  1.7140822 2.4140818 1.7140822 1.7140822 1.7140822\n",
            " 1.7140822 1.7140822 1.7140822 1.7140822 1.7140822 1.7140822 2.4136531\n",
            " 1.7140822 1.7140822 1.7154963 1.7140822 1.7140822 1.7140822 1.7140822\n",
            " 1.7140822 1.7140822 2.3854928 2.4047554 1.7140822 1.7140822 1.7140822\n",
            " 1.7140822 2.414082  1.7140822 2.414082  1.7140822 1.7140822 2.414082\n",
            " 1.7140822 1.7140822 1.7140822 1.7140822 1.7140822 2.4135377 1.7141318\n",
            " 2.4140818 1.7140822 1.7140822 1.7140822 1.7140822 1.7140822 1.7140822\n",
            " 1.7140822 1.7140822 1.7140822 1.7140822 1.7140822 1.7140822 2.414082\n",
            " 1.7140822 1.7140822 1.7140822 1.7189562 1.7140822 2.414082  2.409396\n",
            " 2.414082  1.7147484 2.4140332 1.7140822 1.7140822 1.7140822 2.4137306\n",
            " 1.7140822 1.7140822]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6391 - loss: 10.9417\n",
            "Validation loss: 11.090731620788574, Validation accuracy: 0.6370999813079834\n",
            "Epoch 5/5\n",
            "Step 0, Loss: [2.414107  1.7141073 1.7141073 1.7141073 1.7141073 2.414107  1.7224684\n",
            " 1.7141073 1.7141073 2.414107  1.7141073 1.7141073 2.414107  1.7143142\n",
            " 2.4141064 2.414107  2.412298  1.7159541 2.414107  1.7141073 2.4140515\n",
            " 1.7141073 1.7141073 1.7141073 2.414107  1.7229838 1.7141073 2.4139745\n",
            " 1.7141073 2.414107  1.7141073 1.7141073 1.7141073 1.7141073 1.7141073\n",
            " 2.414107  1.7141073 1.7141073 1.7141073 2.414107  1.7141073 1.7141073\n",
            " 1.7141075 1.7141073 2.4140906 2.414107  1.7141073 2.414107  1.7141073\n",
            " 1.7141073 2.414107  2.414107  1.7178314 2.414107  1.7141073 2.414107\n",
            " 1.7141073 1.7232957 1.7141926 2.412992  1.7141073 1.7141073 1.7141073\n",
            " 1.7141073 1.7141073 1.7141073 1.7141075 1.7141073 1.7141073 1.7141073\n",
            " 1.7173424 1.7141073 1.7141802 1.7141073 2.413659  1.7141075 1.7141073\n",
            " 1.7141073 2.414107  1.7141073 1.7143161 2.414107  1.7141073 1.7141073\n",
            " 2.3997529 1.7141073 1.7141073 1.7141073 1.7141073 1.714133  2.4140954\n",
            " 1.7141118 1.7141073 1.7141073 2.4057248 2.4141068 1.7141073 1.7163115\n",
            " 1.7141073 2.414107  1.7141073 1.7220776 1.7141073 1.7141073 1.7141073\n",
            " 1.7141073 1.7141073 1.7141073 2.4073844 2.414107  2.414107  1.7141073\n",
            " 1.7141073 2.414107  1.7141073 1.7141073 1.7141073 1.7141073 2.414107\n",
            " 1.7141073 1.7141073 2.408753  1.7141073 2.414107  1.7141073 1.7141073\n",
            " 1.7141073 1.7141073]\n",
            "Step 100, Loss: [1.7140529 1.7140529 2.4140527 1.7140529 1.7140529 1.7140529 1.7140529\n",
            " 2.414052  1.7140529 1.7140529 2.4140527 1.7140532 2.4049094 1.7140529\n",
            " 1.714076  1.7152679 2.4140527 2.4140527 1.7140529 2.4140084 1.7140529\n",
            " 1.7140529 1.7140529 1.7140529 1.7140529 2.4140527 2.4140527 1.7140529\n",
            " 1.7140529 1.7140529 1.7140529 1.7140539 2.4140527 1.7140529 1.7140529\n",
            " 1.7140529 2.413534  2.4140527 1.7140529 1.7140529 1.7140529 1.7140529\n",
            " 1.7140529 1.7140529 1.7140529 1.7140529 1.7140529 2.4140527 1.7140529\n",
            " 1.7140529 1.7140529 1.7140529 2.4140527 2.4140508 1.7331102 2.4140527\n",
            " 1.7140529 2.4140527 1.7140529 1.7140529 2.4140527 1.7140529 1.7140529\n",
            " 1.7140529 1.7140529 1.7142608 1.7140529 2.4140403 1.7140529 2.3829591\n",
            " 1.7140532 2.4115078 1.9954717 1.7140529 2.4140525 2.4047158 1.7140529\n",
            " 1.7140529 2.4140527 1.7140529 1.7140529 2.4140527 1.7140529 1.7140529\n",
            " 2.4083397 2.412763  1.7141747 1.7140529 1.7140529 1.7140529 2.4140527\n",
            " 1.7140529 1.7140529 1.7140529 1.7140529 1.7140529 1.7140529 1.7140529\n",
            " 2.4140527 2.396622  1.7140529 2.372109  2.4140527 1.7140529 2.4140525\n",
            " 1.7140529 1.7142217 1.7140529 2.4140527 2.3939548 2.4140527 1.7140529\n",
            " 2.397335  1.7140529 1.7140529 2.3886485 1.7140529 1.7140529 1.7140529\n",
            " 2.4140527 1.7140529 1.7140529 2.4140527 1.7141008 1.7140529 1.7140529\n",
            " 1.7140529 2.4140527]\n",
            "Step 200, Loss: [1.714056  1.714056  2.4140558 2.413509  2.349001  2.4014215 1.7144173\n",
            " 1.7140565 1.714056  1.714056  1.714056  1.714056  1.714056  1.714056\n",
            " 1.7140886 1.714056  1.714056  2.4140558 1.714056  1.714056  2.4140558\n",
            " 1.714056  1.7181755 1.7140676 1.714056  1.714056  1.7305768 1.714056\n",
            " 1.714056  1.714056  2.4140558 1.714056  1.714056  1.714056  2.4140558\n",
            " 2.4140558 1.714056  1.830155  1.714056  1.7140585 2.2788944 1.7140566\n",
            " 1.714056  2.4131298 1.714056  1.714056  1.7481453 1.714056  1.714056\n",
            " 1.7141434 2.4140558 2.4140558 1.714056  1.714056  1.714056  1.714056\n",
            " 2.2751985 2.385043  1.714056  1.714056  1.714056  1.714056  1.7508527\n",
            " 2.4140558 1.7140611 1.714056  1.714056  2.4140558 1.714056  1.714056\n",
            " 2.4140558 1.7140763 1.714056  1.714056  1.714056  1.714056  2.4140525\n",
            " 2.4140558 1.714056  1.714056  1.714056  1.714056  1.714056  1.7180084\n",
            " 2.4140553 2.4140558 2.4140558 1.7140691 2.4140558 1.714056  1.714056\n",
            " 1.714056  2.4140449 1.7229418 1.714056  1.714056  1.714056  1.714056\n",
            " 2.4132986 2.4140077 1.714056  2.4140558 1.714056  2.4086788 1.714056\n",
            " 2.4134412 1.714056  2.4140558 1.714056  1.714056  1.714056  2.4140558\n",
            " 1.714056  1.7140821 1.714056  2.1910098 2.410266  1.714056  1.714056\n",
            " 1.714056  1.7140658 2.4140558 2.410602  1.7154825 1.714056  1.8289444\n",
            " 1.7156311 2.4140558]\n",
            "Step 300, Loss: [1.7140758 1.7140758 1.7140758 2.4140499 2.4065092 1.7140758 1.7140758\n",
            " 1.7140758 1.7140758 1.7140758 1.7140758 1.7140758 1.714076  1.7140758\n",
            " 2.4140754 1.7140758 1.7140758 1.7140758 1.7140758 2.4140756 2.4140756\n",
            " 1.7140763 2.4140756 1.7140758 2.4140756 2.4105706 1.7140789 1.7140758\n",
            " 1.7140758 2.4140663 1.7140758 2.414073  1.8006845 1.7140758 2.4140756\n",
            " 1.7140758 1.7140758 2.4139354 1.7140758 2.4140756 2.2910397 1.7145071\n",
            " 1.7140758 1.7140758 1.7140758 2.4140756 1.7140758 1.7140758 2.4140756\n",
            " 1.7140758 1.7140758 1.7140758 1.7140758 1.7140758 2.4140756 2.4140713\n",
            " 1.7140758 1.8671863 1.7140758 2.4140751 2.4140756 1.7140758 1.7140758\n",
            " 1.7140758 1.7140758 1.7140758 1.7140758 1.7140758 1.7140758 1.718857\n",
            " 1.7140758 1.7140758 1.7140815 1.7140758 1.7140758 1.7140758 1.7140758\n",
            " 1.7140758 1.7140758 2.4108531 2.3946447 1.7140758 1.7140758 1.7140758\n",
            " 1.7140758 2.4140756 1.7140758 2.4140756 1.7140758 1.7140758 2.4140756\n",
            " 1.7140758 1.7140758 1.7140758 2.4132347 1.7140758 1.7140758 1.7140758\n",
            " 2.4137719 1.7140758 1.7140758 1.7140758 1.7140758 1.7140758 1.7140784\n",
            " 1.7140758 1.7140758 1.7140758 1.7140758 2.4140735 1.7140758 2.4140756\n",
            " 1.7140758 1.7140758 1.7140758 1.7140758 2.4140754 2.4140756 2.4102972\n",
            " 2.411787  1.7141147 1.7142274 1.7140758 1.7140758 1.7337127 1.7140808\n",
            " 1.7140758 1.7141869]\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6210 - loss: 14.5974\n",
            "Validation loss: 15.06688404083252, Validation accuracy: 0.6104000210762024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = student_model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2QQ3QMqHoN5",
        "outputId": "45cf78b7-3a7a-49ff-b7d1-2b99b854507f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6215 - loss: 14.5872\n",
            "Test accuracy: 0.6104000210762024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part C : Training ResNet18 on CIFAR-10 DataSet**"
      ],
      "metadata": {
        "id": "3tKis7kKII0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "BlXPWikVIS0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "resNet_model = ResNet18(input_shape=(32, 32, 3), weights=None, classes=10)\n",
        "resNet_model.compile(optimizer='adam',\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "history = resNet_model.fit(x_train, y_train,\n",
        "                            batch_size=64,\n",
        "                            epochs=10,\n",
        "                            validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjZHlDp4JJQH",
        "outputId": "870883ad-4e6c-40fc-eaff-7f9530a42226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 32ms/step - accuracy: 0.4214 - loss: 1.6140 - val_accuracy: 0.5451 - val_loss: 1.3343\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.6415 - loss: 1.0173 - val_accuracy: 0.5921 - val_loss: 1.2239\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7221 - loss: 0.7992 - val_accuracy: 0.7176 - val_loss: 0.8336\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.7696 - loss: 0.6599 - val_accuracy: 0.7269 - val_loss: 0.7851\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.8162 - loss: 0.5328 - val_accuracy: 0.7238 - val_loss: 0.8297\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8527 - loss: 0.4243 - val_accuracy: 0.7351 - val_loss: 0.8339\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.8805 - loss: 0.3467 - val_accuracy: 0.7456 - val_loss: 0.8353\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9087 - loss: 0.2653 - val_accuracy: 0.7504 - val_loss: 0.8530\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9275 - loss: 0.2111 - val_accuracy: 0.7458 - val_loss: 0.9261\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9379 - loss: 0.1781 - val_accuracy: 0.7585 - val_loss: 0.8948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = resNet_model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFkg1JXcKPr6",
        "outputId": "c18fa4a2-827a-48d8-b64e-07fcb49a37af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.9070\n",
            "Test accuracy: 0.7584999799728394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**because ResNet50 is a deeper model, it might cause overfitting on small datasets like cifar10. in other hand, resNet18 is more suitable for small datasets like cifar10. in the RNN algorithm we used, it is not recommended to use ResNet50 as teacher model because the model itself doesn't have good training results.**"
      ],
      "metadata": {
        "id": "op7QVAdxQlSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part D#\n",
        "**The process of training are same as the last part. The only difference is unfreezing all the layers.\n",
        " If managed well with techniques to combat overfitting (like data augmentation, dropout, etc.), fine-tuning can lead to higher accuracy because the model is more adapted to the specific task but on the other hand With more parameters to train, there’s a higher risk of overfitting, especially since CIFAR-10 is relatively small**"
      ],
      "metadata": {
        "id": "Zrcpwm_vrisg"
      }
    }
  ]
}